[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HAX603X: Modélisation stochastique",
    "section": "",
    "text": "Aspects numériques de la modélisation aléatoire et statistiques (cours de Licence 3). Les sections en haut de page regroupe le contenus pédagogique : les slides seront présentés en cours, et pour aller un peu plus loin le “poly” est disponible en format “html” sur la page Cours.\n\n\n\n\n\n\nAvertissement\n\n\n\nSite en construction…(un peu de patience donc)\n\n\n\n\n\nJoseph Salmon: joseph.salmon@umontpellier.fr,\nBenjamin Charlier: benjamin.charlier@umontpellier.fr\n\nCe cours est issu du travail antérieur de la part de:\n\nNicolas Meyer\nBenoîte de Saporta et de l’aide de François-David Collin.\n\n\n\n\n\nBases de probabilités (en particulier “HAX506X- Théorie des Probabilités”): probabilité, densité, espérance, fonction de répartition, mesure, intégration, analyse numérique élémentaire, etc. (Foata et Fuchs 1996; Barbe et Ledoux 2006; Ouvrard 2007, 2008)\nProgrammation élémentaire (en Python): if … then… else …, for, while, fonctions, etc. HLMA310 - Logiciels scientifiques, (Courant et al. 2013), Cours de Python: Univ. Paris Diderot\n\n\nFoata, D., et A. Fuchs. 1996. Calcul des probabilités: cours et exercices corrigés. Masson.\n\nBarbe, Philippe, et Michel Ledoux. 2006. Probabilités.\n\nOuvrard, J.-Y. 2007. Probabilités : Tome 2, Licence - CAPES. 2ᵉ éd. Enseignement des mathématiques. Cassini.\n\n———. 2008. Probabilités : Tome 1, Licence - CAPES. 2ᵉ éd. Enseignement des mathématiques. Cassini.\n\n\n\n\nGénérer l’aléa\n\ngénérateurs pseudo-aléatoires\nillustrations numériques et visualisation en Python (loi des grands nombres, théorème central limite)\nsimulations de variables aléatoires (méthode de l’inverse, méthode du rejet, cas spécifiques, etc.)\n\nMéthode de Monte-Carlo \n\nméthode de Monte-Carlo pour le calcul approché d’une intégrale\nréduction de la variance : variables antithétiques, variables de contrôle, échantillonnage préférentiel.\n\nCompléments\n\nvecteurs gaussiens et lien avec les lois usuelles de la statistique inférentielle (student, chi2)\nconstruction d’intervalles de confiance.\nmarche aléatoire simple, etc.\n\n\n\n\n\n\nTP notés : Rendu = fichier Python .py unique\n\nTP noté 1 : rendre en fin de session\nTP noté 2 : rendre en fin de session\n\nCC : devoir sur table d’une heure\nCoefficients:\n\nNote Session 1 : (40% CC + 30% TP 1 + 30% TP 2)\nNote Session 2 : (30% CC + 35% TP 1 + 35% TP 2)\n\n\n\n\n\nMoodle: HAX603X Modélisation Stochastique\n\n\n\n\n\n\nIntroduction à Python Cours de Python 🇫🇷\nHLMA310 - Logiciels scientifiques 🇫🇷\nManuel d’algorithmique en Python (Courant et al. 2013) 🇫🇷\nData Science: Python Data Science Handbook, With Application to Understanding Data by J. Van DerPlas, 2016; 🇬🇧  videos: Reproducible Data Analysis in Jupyter\nMath for journalists by Naël Shiab 🇬🇧\n\n\nCourant, J., M. de Falco, S. Gonnord, J.-C. Filliâtre, S. Conchon, G. Dowek, et B. Wack. 2013. Informatique pour tous en classes préparatoires aux grandes écoles: Manuel d’algorithmique et programmation structurée avec Python. Eyrolles.\n\n\n\n\nSoftware Dev. for datascience by J. Salmon and B. Charlier, 🇬🇧\nMonte Carlo Methods and Applications by Keenan Crane 🇬🇧\nChaîne de Markov: Markov Chains by Ethan N. Epperly 🇬🇧\nAdvanced Data Analysis from an Elementary Point of View by Cosma Shalizi; 🇬🇧\nMaximum likelihood by numerical optimization 🇬🇧\nConditionnement, martingales et autres preuves de la loi des grands nombres: (Williams 1991) 🇬🇧\n\n\n\n\nWilliams, D. 1991. Probability with martingales. Cambridge Mathematical Textbooks. Cambridge: Cambridge University Press.",
    "crumbs": [
      "HAX603X: Modélisation stochastique"
    ]
  },
  {
    "objectID": "index.html#enseignants",
    "href": "index.html#enseignants",
    "title": "HAX603X: Modélisation stochastique",
    "section": "",
    "text": "Joseph Salmon: joseph.salmon@umontpellier.fr,\nBenjamin Charlier: benjamin.charlier@umontpellier.fr\n\nCe cours est issu du travail antérieur de la part de:\n\nNicolas Meyer\nBenoîte de Saporta et de l’aide de François-David Collin.",
    "crumbs": [
      "HAX603X: Modélisation stochastique"
    ]
  },
  {
    "objectID": "index.html#prérequis",
    "href": "index.html#prérequis",
    "title": "HAX603X: Modélisation stochastique",
    "section": "",
    "text": "Bases de probabilités (en particulier “HAX506X- Théorie des Probabilités”): probabilité, densité, espérance, fonction de répartition, mesure, intégration, analyse numérique élémentaire, etc. (Foata et Fuchs 1996; Barbe et Ledoux 2006; Ouvrard 2007, 2008)\nProgrammation élémentaire (en Python): if … then… else …, for, while, fonctions, etc. HLMA310 - Logiciels scientifiques, (Courant et al. 2013), Cours de Python: Univ. Paris Diderot\n\n\nFoata, D., et A. Fuchs. 1996. Calcul des probabilités: cours et exercices corrigés. Masson.\n\nBarbe, Philippe, et Michel Ledoux. 2006. Probabilités.\n\nOuvrard, J.-Y. 2007. Probabilités : Tome 2, Licence - CAPES. 2ᵉ éd. Enseignement des mathématiques. Cassini.\n\n———. 2008. Probabilités : Tome 1, Licence - CAPES. 2ᵉ éd. Enseignement des mathématiques. Cassini.",
    "crumbs": [
      "HAX603X: Modélisation stochastique"
    ]
  },
  {
    "objectID": "index.html#description-du-cours",
    "href": "index.html#description-du-cours",
    "title": "HAX603X: Modélisation stochastique",
    "section": "",
    "text": "Générer l’aléa\n\ngénérateurs pseudo-aléatoires\nillustrations numériques et visualisation en Python (loi des grands nombres, théorème central limite)\nsimulations de variables aléatoires (méthode de l’inverse, méthode du rejet, cas spécifiques, etc.)\n\nMéthode de Monte-Carlo \n\nméthode de Monte-Carlo pour le calcul approché d’une intégrale\nréduction de la variance : variables antithétiques, variables de contrôle, échantillonnage préférentiel.\n\nCompléments\n\nvecteurs gaussiens et lien avec les lois usuelles de la statistique inférentielle (student, chi2)\nconstruction d’intervalles de confiance.\nmarche aléatoire simple, etc.",
    "crumbs": [
      "HAX603X: Modélisation stochastique"
    ]
  },
  {
    "objectID": "index.html#modalité-de-contrôle-des-connaissances",
    "href": "index.html#modalité-de-contrôle-des-connaissances",
    "title": "HAX603X: Modélisation stochastique",
    "section": "",
    "text": "TP notés : Rendu = fichier Python .py unique\n\nTP noté 1 : rendre en fin de session\nTP noté 2 : rendre en fin de session\n\nCC : devoir sur table d’une heure\nCoefficients:\n\nNote Session 1 : (40% CC + 30% TP 1 + 30% TP 2)\nNote Session 2 : (30% CC + 35% TP 1 + 35% TP 2)",
    "crumbs": [
      "HAX603X: Modélisation stochastique"
    ]
  },
  {
    "objectID": "index.html#moodle",
    "href": "index.html#moodle",
    "title": "HAX603X: Modélisation stochastique",
    "section": "",
    "text": "Moodle: HAX603X Modélisation Stochastique",
    "crumbs": [
      "HAX603X: Modélisation stochastique"
    ]
  },
  {
    "objectID": "index.html#ressources-supplémentaires",
    "href": "index.html#ressources-supplémentaires",
    "title": "HAX603X: Modélisation stochastique",
    "section": "",
    "text": "Introduction à Python Cours de Python 🇫🇷\nHLMA310 - Logiciels scientifiques 🇫🇷\nManuel d’algorithmique en Python (Courant et al. 2013) 🇫🇷\nData Science: Python Data Science Handbook, With Application to Understanding Data by J. Van DerPlas, 2016; 🇬🇧  videos: Reproducible Data Analysis in Jupyter\nMath for journalists by Naël Shiab 🇬🇧\n\n\nCourant, J., M. de Falco, S. Gonnord, J.-C. Filliâtre, S. Conchon, G. Dowek, et B. Wack. 2013. Informatique pour tous en classes préparatoires aux grandes écoles: Manuel d’algorithmique et programmation structurée avec Python. Eyrolles.\n\n\n\n\nSoftware Dev. for datascience by J. Salmon and B. Charlier, 🇬🇧\nMonte Carlo Methods and Applications by Keenan Crane 🇬🇧\nChaîne de Markov: Markov Chains by Ethan N. Epperly 🇬🇧\nAdvanced Data Analysis from an Elementary Point of View by Cosma Shalizi; 🇬🇧\nMaximum likelihood by numerical optimization 🇬🇧\nConditionnement, martingales et autres preuves de la loi des grands nombres: (Williams 1991) 🇬🇧\n\n\n\n\nWilliams, D. 1991. Probability with martingales. Cambridge Mathematical Textbooks. Cambridge: Cambridge University Press.",
    "crumbs": [
      "HAX603X: Modélisation stochastique"
    ]
  },
  {
    "objectID": "TP/TP3.html",
    "href": "TP/TP3.html",
    "title": "TP3: Simulation de variables aléatoires",
    "section": "",
    "text": "Objectifs de ce TP\n\n\n\n\nUtiliser les générateurs aléatoires en Python et numpy pour générer des échantillons de lois non triviales.\nRédiger un compte-rendu sous Quarto pour présenter ses résultats de TP.",
    "crumbs": [
      "TP",
      "TP3: Simulation de variables aléatoires"
    ]
  },
  {
    "objectID": "TP/TP3.html#méthode-dinversion-loi-exponentielle-et-loi-de-cauchy",
    "href": "TP/TP3.html#méthode-dinversion-loi-exponentielle-et-loi-de-cauchy",
    "title": "TP3: Simulation de variables aléatoires",
    "section": "Méthode d’inversion : loi exponentielle et loi de Cauchy",
    "text": "Méthode d’inversion : loi exponentielle et loi de Cauchy\n\nReprésenter graphiquement la fonction de répartition d’une loi exponentielle (on pourra se restreindre aux réels positifs).\n\n\n\n\n\n\n\n\n\n\n\n\nÉcrire une fonction expo qui prend en argument un entier n et un paramètre \\lambda &gt; 0 et qui donne en sortie un échantillon de taille n de loi \\mathcal{E}(\\lambda). On utilisera la méthode d’inversion vue en cours.\nReprésenter graphiquement l’histogramme d’un tel échantillon pour n=10^2, n=10^3, puis n=10^4, et pour \\lambda = 1/2, 1, 4. Superposer à chaque fois le graphe de la densité de \\mathcal{E}(\\lambda).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAttention! les conventions pour le paramètre de la loi exponentielle ne sont pas les même que dans votre cours…\n\n\n\nIllustrer graphiquement la loi des grands nombres avec \\lambda = 1/2, 1, 4. On tracera en particulier la droite d’équation y=\\mathbb E[X], où X \\sim \\mathcal{E}(\\lambda).\n Même exercice avec la loi de Cauchy. Que remarque-t-on à la question 4 ?",
    "crumbs": [
      "TP",
      "TP3: Simulation de variables aléatoires"
    ]
  },
  {
    "objectID": "TP/TP3.html#lois-discrètes",
    "href": "TP/TP3.html#lois-discrètes",
    "title": "TP3: Simulation de variables aléatoires",
    "section": "Lois discrètes",
    "text": "Lois discrètes\n\nLoi de Bernoulli\n\nÉcrire une fonction bernou qui prend en argument un entier n et un paramètre p \\in ]0,1[ et qui donne en sortie un échantillon de taille n de loi \\mathcal{B}(p).\n\n\n\n\n\n\n\n[1 0 1 1 0 1 1 1 0 0]\n\n\n\n\nIllustrer graphiquement la loi des grands nombres pour un échantillon de taille n=10^3 et différentes valeurs de p (on pourra superposer les graphes).\n\n\n\nLoi géométrique\n\nRappeler les deux méthodes vues en TD pour simuler une loi géométrique.\nÉcrire une fonction geo_bernou qui prend en argument un entier n et un paramètre p \\in ]0,1[ et qui renvoie en sortie un échantillon de taille n de loi \\mathcal{G}(p) en se basant sur la fonction bernou.\n\n# Example usage\nn = 12\np = 0.3\ngeometric_samples = geo_bernou(n, p)\nprint(geometric_samples)\n\n\n\n[ 1.  2.  7.  5.  1.  1.  3.  2. 13.  3.  5.  1.]\n\n\n\n\nÉcrire une fonction geo_expo qui prend en argument un entier n et un paramètre p \\in ]0,1[ et qui renvoie en sortie un échantillon de taille n de loi \\mathcal{G}(p) en se basant sur la fonction expo.\nLe module time contient la fonction process_time() qui permet de mesurer le temps écoulé entre deux appels. Le code suivant affiche le temps passé à évaluer\n\nimport time\n\nt0 = time.process_time()\n\n\"\"\" code chunck to be timed \"\"\"\n\nt1 = time.process_time()\n\nprint(\"Time elaped  when running code chunk:\", t1 - t0)\n\n\n\nUtiliser cette fonction pour comparer la durée de simulation des deux méthodes.\n\n\n\n\n\n\nNote\n\n\n\nEn pratique, les temps d’éxécution peuvent varier suivant la charge d’utilisation de la machine (c’est un phenomène aléatoire). Pour donner une meilleur approximation de tzemps réel d’éxécution, on répète plusieurs fois la mesure et on affiche le temps moyen.",
    "crumbs": [
      "TP",
      "TP3: Simulation de variables aléatoires"
    ]
  },
  {
    "objectID": "TP/TP3.html#méthode-de-rejet-et-loi-beta",
    "href": "TP/TP3.html#méthode-de-rejet-et-loi-beta",
    "title": "TP3: Simulation de variables aléatoires",
    "section": "Méthode de rejet et loi Beta",
    "text": "Méthode de rejet et loi Beta\nOn rappelle que la loi de Beta de paramètres \\alpha, \\beta &gt; 0, notée \\text{Beta}(\\alpha, \\beta), est donnée par la densité \n    f_{\\alpha, \\beta}(x)\n    = \\dfrac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}\\,,\n    \\quad x \\in [0,1]\\,.\n La fonction \\Gamma s’obtient sur avec .\n\nReprésenter la densité pour différentes valeurs de \\alpha et \\beta pour visualiser cette loi. On pourra utiliser la fonction scipy.special.gamma.\n\n\n\n\n\n\n\n\n\n\n\n\nÀ l’aide de la méthode de rejet vue en TD, construire une fonction loi_beta qui génère n variables aléatoires de loi \\text{Beta}(\\alpha,\\beta).\n\n# Example usage\nn = 12\nalpha, beta = 2, 3\n\nbeta_samples = loi_beta(n, alpha, beta)\nprint(beta_samples)\n\n\n\n[0.61582429 0.50112604 0.50748761 0.45232163 0.77487079 0.40568319\n 0.50203394 0.3483966  0.39499544 0.36214897 0.31623463 0.27488559]\n\n\n\n\nIllustrer graphiquement votre résultat en représentant l’histogramme pour n=10^3 et différentes valeurs de \\alpha, \\beta. On superposera à chaque fois la densité adéquate.",
    "crumbs": [
      "TP",
      "TP3: Simulation de variables aléatoires"
    ]
  },
  {
    "objectID": "TP/TP3.html#loi-sur-le-disque",
    "href": "TP/TP3.html#loi-sur-le-disque",
    "title": "TP3: Simulation de variables aléatoires",
    "section": "Loi sur le disque",
    "text": "Loi sur le disque\n\nÉcrire une fonction unif_disque basée sur une méthode de rejet qui génère n uniformes sur le disque unité à partir de variables aléatoires uniformes indépendantes sur [0,1]. Utiliser cette fonction pour représenter graphiquement un échantillon de n=100 uniformes sur le disque.\n\n\n\n\n\n\n\n\n\n\n\n\nÉcrire une fonction unif_disque2, basée sur la fonction précédente, qui donne en sortie à la fois les points dans le disque mais également, dans une matrice séparée, les points rejetés. Représenter graphiquement un échantillon en utilisant une couleur pour les points acceptés (dans le disque) et une autre pour les points rejetés (à l’extérieur).\n\n# Example usage\nx_accepted, x_rejected = unif_disque2(100)\nprint(\"Reject ratio :\", len(x_rejected) / (len(x_rejected) + len(x_accepted)))\n\n\n\nReject ratio : 0.1935483870967742",
    "crumbs": [
      "TP",
      "TP3: Simulation de variables aléatoires"
    ]
  },
  {
    "objectID": "TP/TP1.html",
    "href": "TP/TP1.html",
    "title": "TP1: Prise en main de Python",
    "section": "",
    "text": "Objectifs de ce TP\n\n\n\n\nUtiliser les opérateurs classiques en Python (+,-,*,/,**,@), etc., savoir créer une fonction, générer un graphique clair et lisible\nQu’est-ce que la précision de calcul ? Comment utiliser de une visualisation pour mieux comprendre un théorème ou une fonction ?\nComprendre au mieux comment utiliser les fonctions aléatoires (principalement les générateurs) en numpy.",
    "crumbs": [
      "TP",
      "TP1: Prise en main de Python"
    ]
  },
  {
    "objectID": "TP/TP1.html#prise-en-main-de-python",
    "href": "TP/TP1.html#prise-en-main-de-python",
    "title": "TP1: Prise en main de Python",
    "section": "Prise en main de Python",
    "text": "Prise en main de Python\nPython est un langage ouvert qui permet de manipuler des données, faire des analyses statistiques, tracer des graphes, et bien d’autres choses encore. Il est distribué gratuitement et vous pouvez le télécharger et l’installer sur une machine personnelle. Dans ce premier TP, on présente les bases de Python.\nPour plus de détails on pourra consulter les ouvrages:\n\nIntroduction à Python Cours de Python 🇫🇷\nHLMA310 - Logiciels scientifiques 🇫🇷\nManuel d’algorithmique en Python (Courant et al. 2013) 🇫🇷\n\n\nCourant, J., M. de Falco, S. Gonnord, J.-C. Filliâtre, S. Conchon, G. Dowek, et B. Wack. 2013. Informatique pour tous en classes préparatoires aux grandes écoles: Manuel d’algorithmique et programmation structurée avec Python. Eyrolles.\n\nInstallation de Python\nTout est déjà installé sur les ordinateurs de l’université. Cette section n’est utile que si vous souhaitez utiliser votre propre machine.\nLe conseil principal, est d’installer VSCode et d’utiliser l’extension Python associée. Pour Python, privilégier Conda (ou Mamba) pour installer les packages, voir par exemple: installer-anaconda.\n\n\nL’environnement de travail VSCode / VSCodium\nOn travaillera sous VSCodium (une variante de VSCode) sur les machines de l’Université, un éditeur de texte qui permet de travailler avec Python, mais aussi avec LaTeX, Markdown, R, etc.\n\nLancer l’application VSCodium, par exemple en cliquant sur l’icône “Application Menu” en haut à gauche de votre écran, puis en tapant “VSCodium” dans la barre de recherche. La démarche à suivre est visible dans la vidéo ci-dessous:\n\n\n\n\nSi besoin (à ne faire qu’une fois), il vous faut installer l’extension “https://open-vsx.org/extension/ms-python/python”. Pour cela, il y a plusieurs stratégies. La plus simple consiste à cliquer sur le menu d’installation et chercher l’application Python “Python, extension for Visual Studio Code”, proposée par Microsoft, Intellisense, (attention il y a beaucoup, choisir la bonne, avec plusieurs millions d’étoiles et de téléchargements):\n\n\nRemarque: Une alternative est d’aller dans le menu “View/Command Palette” (accessible avec ctrl + shift + p), et taper “Extensions : install extensions” et installer l’extension “Python, extension for Visual Studio Code” (proposée par Microsoft). Au besoin, il faudra recharger (reload) VSCodium. Si vous avez déjà installé l’extension Python sur votre machine personnelle, vous pouvez passer cette étape.\nLa même opération devra être faite pour installer l’extension “https://open-vsx.org/extension/ms-toolsai/jupyter” (proposée par Microsoft,) qui nous permettra de manipuler des fenêtres interactives:\n\n\n\n\nPremiers pas\n\nCréer un nouveau fichier dans VSCodium intitulé HAX603X_tp1.py, et sauvegarder le dans un dossier HAX603X.\nDans ce fichier, copier-coller le code de la boîte suivante. On pourra alors lancer des cellules de code en tapant sur shift + enter dans une cellule délimitée par les symboles \\# \\%\\%. On peut aussi lancer la cellule en cliquant sur le bouton “run cell” dans VSCodium (ou clique droit puis une option de type “run cell” ou “run all cell”).\n\n\n# %%\n# Début de cellule\nprint(1 + 3)  # commentaire en ligne\n# %%\n# Une autre cellule\nprint(2**3)  # commentaire en ligne\n\n4\n8\n\n\n\n\n\nCliquer dans VSCodium sur la version de “Python” en bas de votre écran et choisir sur les machines de l’école l’environnement ‘datascience’ (version: 3.10.6 au 20/01/2024). Si vous travaillez sur votre machine personnelle, choisissez un environnement de base, ou bien créer un environnement conda qui vous conviendra, par exemple avec Miniconda1.\nVérifier que maintenant vous pouvez lancer une cellule, par exemple en tapant crtl + enter, ou bien en cliquant sur le bouton “run cell”.\n\n1 Installer un environnement de développement Python avec Conda\n\nL’environnement de travail\nVous voyez apparaître plusieurs fenêtres :\n\nla console (à droite), avec les environnement et l’historique (en haut à droite)\nla fenêtre de texte (à gauche)\n\nLa console permet d’exécuter des instructions ou commandes. C’est ici que vous donnez vos instructions et que s’affichent les résultats demandés. La fenêtre d’environnement et d’historique recense l’historique des commandes et les variables qui ont été définies. Enfin, la fenêtre de texte permet d’écrire du texte, des commentaires, bref les fichiers que vous conserverez.\nUne manière simple de garder traces de vos calculs/instructions est de les écrire dans un fichier texte (ici HAX603X_tp1.py), et de les délimiter par des symboles \\# \\%\\% (voir ci-dessus), et de les lancer en tapant shift + enter dans une cellule délimitée par les symboles \\# \\%\\%.\nUne première utilisation basique de Python concerne les calculs. Vous pouvez entrer toutes les opérations classiques : addition +, soustraction -, multiplication *, division /, puissance **, etc. Les fonctions usuelles sont également déjà programmées en Python, mais nécessite le chargement du package numpy : exponentielle, logarithme, fonctions trigonométriques, racine carrée, etc.\nPour cela il suffit de taper import numpy as np dans une cellule de code, puis d’utiliser les fonctions de numpy comme suit par exemple:\nimport numpy as np\n\nprint(np.exp(1))\nprint(np.log(2))\nprint(np.sin(np.pi))\n\n\n\n2.718281828459045\n0.6931471805599453\n1.2246467991473532e-16\n\n\n\n\nQuestion : fonctions mathématiques\nEntrez quelques opérations de base pour vous familiariser avec les instructions sur Python. Faire de même avec les fonctions np.exp, np.log, np.sin, np.cos, np.tan, np.sqrt, np.abs,np.round. Entrer les instructions 1/0 et np.sqrt(-2). Que constatez-vous ?\nOn remarquera qu’on peut utiliser le symbole np.inf pour représenter l’infini. Par ailleurs, si un résultat n’est pas possible (par exemple en tapant np.sqrt(-2) ou np.inf - np.inf), alors on obtient nan qui signifie Not a Number.\nIl faut se souvenir que les calculs numériques ne sont pas toujours exacts du fait de la discrétisation des nombres sur machine. Taper par exemple np.sin(0), np.sin(2*np.pi) et np.sin(np.pi*10**16). Voir aussi les différences entre:\n\nprint(0.6, 0.3 + 0.2 + 0.1)\nprint(0.6, 0.1 + 0.2 + 0.3)\n\n0.6 0.6\n0.6 0.6000000000000001\n\n\n\n\n\n\n\n\nPour aller plus loin\n\n\n\nOn pourra consulter https://0.30000000000000004.com/ pour plus de détails sur les ce type de phénomènes.\n\n\n\n\n\nAide en Python\nOn peut utiliser l’aide de base de python avec les commandes help(la-fonction) ou ?la-fonction. L’aide en ligne est aussi conseillée, surtout pour la création de graphiques avec matplotlib pour avoir plus de détails et des galleries de visualisation.\n\n\nRépertoire de travail\nLe répertoire de travail (🇬🇧: working directory) est le répertoire par défaut, c’est-à-dire le répertoire qui s’ouvre quand vous cliquez sur le bouton pour enregistrer un fichier. La commande pour connaître le répertoire de travail actuel est getcwd du package os:\n\nimport os\nprint(os.getcwd())\n\n/home/jsalmon/Documents/Mes_cours/Montpellier/HAX603X/HAX603X/TP\n\n\nPour changer le répertoire de travail, on pourra utiliser la commande os.chdir avec un nom de répertoire (valide) entre guillemets, par exemple sous Linux la commande suivante permet de remonter d’un cran dans l’arborescence des répertoires:\n\nos.chdir('../')\n\nSi l’on ferme la fenêtre interactive (à droite), alors exécuter une cellule lancera une nouvelle fenêtre interactive dans le répertoire de travail qui correspond au fichier courant que l’on édite (ici le fichier HAX603X_tp1.py).\n\n\nCréation et affectation de variables\nPour créer des objets, il suffit d’utiliser la commande =.\n\nQuestion : variables\nCréer une variable x qui contient la valeur 12. Effectuer des calculs du type x+3, x**4, 4*x pour vérifier que tout se passe comme prévu.\nEn pratique on donnera des noms d’objets pertinents, par exemple\n\ndistance = 105  # en km\ntemps = 2  # en heures\nvitesse = distance/temps  # en km/h\n\nOn remarquera que lorsque l’on crée des objets, ils sont stockées dans l’environnement de travail (chercher l’onglet variables de la fenêtre interactive).",
    "crumbs": [
      "TP",
      "TP1: Prise en main de Python"
    ]
  },
  {
    "objectID": "TP/TP1.html#numpy-et-calcul-scientifique-en-python",
    "href": "TP/TP1.html#numpy-et-calcul-scientifique-en-python",
    "title": "TP1: Prise en main de Python",
    "section": "numpy et calcul scientifique en Python",
    "text": "numpy et calcul scientifique en Python\nnumpy est l’outil de base en Python pour faire du calcul vectoriel et matriciel.\n\nVecteurs en numpy\nPour créer un vecteur, la commande de base est la fonction np.array:\n\nv = np.array([1, 2, 3])\nprint(v)\n\n[1 2 3]\n\n\nEnsuite, on peut concaténer des vecteurs, les multiplier par une constante, leur ajouter une constante, les élever à une certaine puissance, etc. Si on manipule deux vecteurs, on prendra garde à leur taille.\n\nQuestion : Vecteurs\nCréez un vecteur v1 composé des réels 7, 8, 3, un vecteur v2 composé des réels -0.5, 120, -12, et un vecteur v3 composé des réels 0, 1, 0, 1. Testez les commandes suivantes : v1-7, v2**4, 10*v3, v1+v2, v1*v2, v1/v2, v1+v3.\nIl existe un grand nombre de fonctions mathématiques qui s’appliquent directement sur un vecteur : np.sum(), np.prod(), len(), np.min(), np.max(), np.nanmax(), np.argmax(), np.mean(), np.median(), np.var(), np.std().\nEnfin on peut aussi utiliser des fonctions de tri, partiel ou non: np.sort(), np.argsort(), np.partition(), np.argpartition() on pourra consulter l’aide en ligne pour plus de détails: https://numpy.org/doc/stable/reference/routines.sort.html, et les teser sur le vecteur v2 par exemple.\n\n\nQuestion : Opérations sur les vecteurs\nCréez un vecteur de taille 5 et appliquez-lui les fonctions précédentes. Si vous ne comprenez pas la sortie (utiliser l’aide avec ? ou la documentation en ligne).\n\n\n\n\n\n\nPour aller plus loin: vectorisation\n\n\n\nVous pourrez consulter les commandes décrites visuellement ici pour créer des vecteurs et/ou des matrices classiques.\n\n\n\n\n\nSuites régulières\nUne autre manière de créer des vecteurs consiste à créer des suites régulières :\n\nLa commande np.arange(n1, n2) crée un vecteur de réels partant de n1 et croissant d’une unité pour arriver à n2 (exclu). On peut changer le pas en ajoutant un argument optionnel np.arange(n1, n2, step=pas). Ainsi,\n\nnp.arange(0, 10, step=2)\n\narray([0, 2, 4, 6, 8])\n\n\nLa commande np.tile() permet de répéter un vecteur un nombre de fois fixé.\n\n\nQuestion: arange et tile\nExécutez les commandes suivantes et essayer d’analyser les sorties :\n\nnp.arange(9, 13)\nnp.arange(3, -8, step=-1)\nnp.arange(9, 13, step=2)\nnp.arange(9, 13, step=3)\nnp.tile(np.arange(9, 13, step=3), (4, 1))\n\narray([[ 9, 12],\n       [ 9, 12],\n       [ 9, 12],\n       [ 9, 12]])\n\n\nEnfin, pour extraire la valeur d’indice i d’un vecteur x, on tapera x[i] (avec la convention que Python commence à énumérer à 0). Plus généralement, pour extraire les valeurs associées aux indices 3, 4 et 7, on tapera x[[3,4,7]]. Le vérifier sur un vecteur de taille 10. On peut aussi extraire des sous parties de vecteurs, par exemple x[3:7] pour extraire les valeurs d’indice 3, 4, 5 et 6, ou bien x[3:] pour extraire les valeurs d’indice 3, 4, 5, etc. jusqu’à la fin.\n\n\n\nMatrices en numpy\nLa fonction np.shape permet de connaître la taille d’un vecteur ou d’une matrice. On regardera son comportement sur les vecteurs notamment.\n\nQuestion : opérations élémentaires\nManipulez les opérations classiques sur des matrices (arrays) de numpy (si vous êtes déjà habitué à numpy vous pouvez continuer)\nOpérations termes à termes:\n\n# Somme de deux vecteurs\nA = np.array([1.0, 2, 3])\nB = np.array([-1, -2, -3.0])\n\n# Attribuer à la variable C la somme de A et B\nsum_A_B = ...  # XXX TODO\n\nnp.testing.assert_allclose(np.zeros((3,)), sum_A_B)\nprint(\"it worked\")\n\n# Le produit terme à terme avec *\nprod_A_B = ...  # XXX TODO\n\nnp.testing.assert_allclose(np.array([-1.0, -4, -9]), prod_A_B)\nprint(\"it worked\")\n\n# Remarque: la même chose fonctionne terme à terme avec \\, ** (puissance)\nnp.testing.assert_allclose(np.array([1.0, 4, 9]), A ** 2)\nprint(\"it worked: even for powers\")\n\nLe produit scalaire (ou matriciel) est l’opérateur @. Vérifiez que pour la matrice J ci-dessous J^3 = Id de deux façons. Pour cela on pourra aussi utiliser la puissance matricielle avec np.linalg.matrix_power:\n\nJ = np.array([[0, 0, 1.0], [1.0, 0, 0], [0, 1.0, 0]])\n\nI3 = np.eye(3)\n\nnp.testing.assert_allclose(I3, ...)  # XXX TODO\nprint(\"it worked: method 1\")\nnp.testing.assert_allclose(I3, ...)  # XXX TODO\nprint(\"it worked: method 2\")\n\n\n\nQuestion : résolution de systèmes linéaires\nPour résoudre le système de la forme Ax=b en mathématiques, la formule explicite est x=A^{-1}b (dans le cas où A est inversible).\n\n\n\n\n\n\nImportant\n\n\n\nEn pratique vous n’utiliserez (presque) jamais l’inversion de matrice ! En effet, on n’inverse JAMAIS JAMAIS (!) une matrice sans une très bonne raison. La plupart du temps il existe des méthodes plus rapides pour résoudre un système numériquement !\n\n\n\nprint(f\"L'inverse de la matrice: \\n {J} \\n est \\n {np.linalg.inv(J)}\")\n\nn = 20  # XXX TODO: tester avec n=100\nJbig = np.roll(np.eye(n), -1, axis=1)  # matrice de permutation de taille n\nprint(Jbig)\n\nb = np.arange(n)\nprint(b)\n\n# on peut transposer une matrice facilement de 2 manières:\nprint(Jbig)\nprint(Jbig.T)\nprint(np.transpose(Jbig))\n\nComparons niveau temps d’execution l’inversion explicite vs. l’utilisation d’un solveur de système linéaire tel que np.linalg.solve:\n\nimport time\n# Résolution de système par une méthode naive: inversion de matrice\nt0 = time.perf_counter()  # XXX TODO\ny1 = ... @ b\ntiming_naive = time.perf_counter() - t0\nprint(\n    f\"Temps pour résoudre un système avec la formule mathématique: {timing_naive - t0:.4f} s.\"\n)\n\n# Résolution de système par une méthode adaptée: fonctions dédiée de `numpy``\nt0 = time.perf_counter()\ny2 = ...\ntiminig_optimized = time.perf_counter()\nprint(\n    f\"Temps pour résoudre un système avec la formule mathématique: {timing_optimized:.4f} s.\\nC'est donc {timing_naive / timing_optimized} fois plus rapide d'utiliser la seconde formulation\"\n)\n\nnp.testing.assert_allclose(y1, y2)\nprint(\"Les deux méthodes trouvent le même résultat\")\n\n\n\n\n\n\n\nAstuce\n\n\n\nPour des comparaisons d’efficacité temporelle plus poussées on pourra utiliser le package timeit2 ou voir la discussion ici: https://superfastpython.com/time-time-vs-time-perf_counter/.\n\n\n2 lien vers la documentation de timeit\n\nQuestion découpage (🇬🇧: slicing)\nLe découpage permet d’extraire des éléments selon un critère (position, condition, etc.). La notation : signifie “tout le monde”, et l’indexation commence en 0. Pour partir de la fin, il est possible de mettre le signe - devant le nombre: ainsi -1 renvoie donc au dernier élément. Enfin, on peut extraire des sous suites d’indices pair ou impair, par exemple x[::2] pour extraire les valeurs d’indice pair, ou bien x[1::2] pour extraire les valeurs d’indice impair de x. Enfin on peut aussi utiliser le signe - pour partir de la fin, par exemple x[-1] pour extraire la dernière valeur, ou bien x[-2] pour extraire l’avant-dernière valeur.\n\nprint(f\"The first column is {J[:, 0]}\")\n\n# Afficher la deuxième ligne de J\nprint(f\"The second row is {...}\")  # XXX TODO\n\nMettre à zéro une ligne sur 2 de la matrice identité de taille 5\\times 5\n\nC = np.eye(5, 5)\nC[...,...] = 0  # mettre à zéro une ligne sur deux. # XXX TODO",
    "crumbs": [
      "TP",
      "TP1: Prise en main de Python"
    ]
  },
  {
    "objectID": "TP/TP1.html#visualisation-dune-figure",
    "href": "TP/TP1.html#visualisation-dune-figure",
    "title": "TP1: Prise en main de Python",
    "section": "Visualisation d’une figure",
    "text": "Visualisation d’une figure\nPour lancer une figure on peut utiliser la package matplotlib. Un exemple utilisant le package numpy pour créer une figure simple est donné ci-dessous, dans la Figure 1.\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = np.cos(2 * np.pi * r)\n\nfig, ax = plt.subplots()\nax.plot(r,theta)\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 1: Une figure simple.",
    "crumbs": [
      "TP",
      "TP1: Prise en main de Python"
    ]
  },
  {
    "objectID": "TP/TP1.html#aspects-aléatoires",
    "href": "TP/TP1.html#aspects-aléatoires",
    "title": "TP1: Prise en main de Python",
    "section": "Aspects aléatoires",
    "text": "Aspects aléatoires\nLe module random de numpy permet d’utiliser l’aléatoire et des lois usuelles en Python. On crée d’abord un générateur qui nous permettra ensuite d’appeler les lois voulues comme suite:\n\nimport numpy as np  # package de calcul scientifique\nimport matplotlib.pyplot as plt  # package graphique\n\ngenerateur = np.random.default_rng()\ngenerateur.normal()\n\n-0.8369253715602726\n\n\n\nQuestion : Matrices aléatoires\nCréer une matrice de taille 4\\times 5 dont les entrées sont i.i.d de loi de Laplace d’espérance 0 et de variance 2. Lancer plusieurs fois le code et observez les changements. On pourra s’aider de l’aide en ligne si besoin.\n\ngenerateur = np.random.default_rng()\nM = ...  # XXX TODO\nprint(M)\n\n\n\nQuestion : Reproduire des résultats\nPour reproduire des résultats ou débugger un code, il est utile de “figer” l’aléatoire. On utilise pour cela une graine (🇫🇷 seed) dans la création du générateur. Fixez la graine à 0 dans default_rng() et lancez une génération aléatoire. Commenter.\n\nrng = np.random.default_rng(0)\nrng.normal()\nrng2 = np.random.default_rng(...)\nrng.normal()\n\n\n\nQuestion : afficher un histogramme\nAvec plt.subplot, créer 3 histogrammes de 100 tirages aléatoires de distributions suivantes:\n\nloi gaussienne (centrée-réduite)\nloi de Cauchy\nloi de Laplace.\n\nOn utilisera les mêmes paramètres de centrage et d’échelle pour les trois lois.\n\nn_samples = 10000\nX = np.empty([n_samples, 3])\nX[:, 0] = ...\nX[:, 1] = ...\nX[:, 2] = ...\n\nlois = [\"Loi de Gauss\", \"Loi de Laplace\", \"Loi de Cauchy\"]\n\nfig_hist, ax = plt.subplots(3, 1, figsize=(3, 3))\n\nfor i, name in enumerate(lois):\n    ax[i].hist(..., bins=100, density=True)\n    ax[i].set_title(name)\n\nplt.tight_layout()\nplt.show()\n\nDe manière complémentaire le module scipy.stats permet d’utiliser des lois usuelles, et de faire des tests statistiques. On pourra consulter la documentation en ligne pour plus de détails: https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\n\n\n\n\nPour aller plus loin.\n\n\n\nLa plupart des lois usuelles sont disponibles, cf. la documentation; vous pourrez en manipuler avec des widgets ici.",
    "crumbs": [
      "TP",
      "TP1: Prise en main de Python"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#loi-forte-des-grands-nombres",
    "href": "Slides/slides_th_asymptotique.html#loi-forte-des-grands-nombres",
    "title": "Théorèmes asymptotiques",
    "section": "Loi forte des grands nombres",
    "text": "Loi forte des grands nombres\n\nRésultat fondamental: concerne le comportement asymptotique de la moyenne empirique: \\[\n\\bar X_n = \\dfrac{X_1 + \\cdots + X_n}{n} \\enspace.\n\\] quand on observe \\(n\\) variables aléatoires i.i.d \\(X_1,\\dots,X_n\\), ayant une espérance finie.\n\n\nThéorème 1 (Loi forte des grands nombres) \nSoit \\((X_n)_{n \\geq 1}\\) une suite de variables aléatoires indépendantes et identiquement distribuées (i.i.d.) dans \\(L^1(\\Omega, \\mathcal{F}, \\mathbb{P})\\). Notons \\(\\mu = \\mathbb{E}[X_1]\\). Alors \\(\\bar X_n\\) converge vers \\(\\mu\\) presque sûrement : \\[\n\\mathbb{P}\\bigg( \\dfrac{X_1 + \\cdots + X_n}{n} \\underset{n \\to \\infty}{\\longrightarrow} \\mu \\bigg) = 1\\,.\n\\]",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#interprétation",
    "href": "Slides/slides_th_asymptotique.html#interprétation",
    "title": "Théorèmes asymptotiques",
    "section": "Interprétation",
    "text": "Interprétation\nIntuitivement, la probabilité d’un événement \\(A\\) correspond à la fréquence d’apparition de \\(A\\) quand on répète une expérience qui fait intervenir cet événement.\n\nExemple 1 (Cas Bernouilli: pile ou face) La probabilité d’apparition du côté pile (noté \\(p\\)) peut-être estimée en lançant la pièce un grand nombre de fois et en comptant le nombre de pile obtenu.\nLa loi des grands nombres justifie cette intuition : si \\(X_1, \\ldots, X_n\\) sont i.i.d. de loi de Bernoulli de paramètre \\(p\\), alors \\[\n    \\dfrac{X_1 + \\cdots + X_n}{n} \\xrightarrow[n \\to \\infty]{p.s.} p =\\mathbb{E}(X_1)\n\\]\n\nMembre de gauche : la fréquence empirique de piles\nMembre de droite : la fréquence théorique de piles",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#visualisation-de-lexemple-du-pile-ou-face",
    "href": "Slides/slides_th_asymptotique.html#visualisation-de-lexemple-du-pile-ou-face",
    "title": "Théorèmes asymptotiques",
    "section": "Visualisation de l’exemple du pile ou face",
    "text": "Visualisation de l’exemple du pile ou face\n#| echo: false\n#| standalone: true\n#| viewerHeight: 550\nimport numpy as np\nfrom shiny import ui, render, App, reactive\nfrom shinywidgets import output_widget, register_widget\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\n\nn_init = 42\n\n\napp_ui = ui.page_fluid(\n    ui.tags.head(\n        ui.tags.style(\"\"\"\n            .bslib-sidebar-layout &gt; .sidebar &gt; .sidebar-content {\n            display: flex;\n            flex-direction: column;\n            padding: 0.5rem;\n            }\n            .irs--shiny .irs-line {\n            top: 27px;\n            height: 4px;\n            }\n            .irs.irs--shiny .irs-bar {\n            top: 27px;\n            height: 4px;\n            }\n            .irs--shiny .irs-handle {\n            top: 23px;\n            width: 22px;\n            height: 10px;\n        \"\"\")\n    ),\n    ui.panel_title(\"Loi des grands nombres\"),\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_action_button(\"seed\", \"Nouveau tirage\", class_=\"btn-primary\"),\n            ui.input_slider( \"p\", \"Espérance: p\", 0.01, 0.99, value=0.35, step=0.01, ticks=False,\n            ),\n            ui.input_slider( \"n_samples\", \"Échantillons: n\", 2, 1000, value=15, step=1, ticks=False),\n        width=3),\n    ui.panel_main(output_widget(\"my_widget\"), width = 9)\n    )\n)\n\n\n\n\ndef server(input, output, session):\n    seed = reactive.Value(42)\n\n    @reactive.Effect\n    @reactive.event(input.seed)\n    def _():\n        seed.set(np.random.randint(0, 1000))\n\n    subplots = make_subplots(\n        rows=2,\n        cols=1,\n        vertical_spacing=0.45,\n        horizontal_spacing=0.04,\n        row_heights=[5, 1],\n        subplot_titles=(\n            f\"Moyenne empirique: loi de Bernoulli\",\n            \"Tirages aléatoires &lt;span style='color:rgb(66, 139, 202)'&gt;bleu: 0&lt;/span&gt;, &lt;span style='color:rgb(255, 0, 0)'&gt;rouge: 1&lt;/span&gt; (seed=\"\n            + f\"{n_init:03}\"\n            + \")\",\n        ),\n    )\n    fig = go.FigureWidget(subplots)\n    fig.add_trace(\n        go.Scatter(\n            mode=\"lines\",\n            line=dict(color=\"black\", width=3),\n            x=[],\n            y=[],\n            name=r\"Moyenne &lt;br&gt; empirique\",\n        ),\n        row=1,\n        col=1,\n    )\n    fig.add_trace(\n        go.Scatter(\n            mode=\"lines\",\n            line=dict(dash=\"dash\", color=\"black\", width=1),\n            marker={},\n            x=[],\n            y=[],\n            name=r\"p\",\n        ),\n        row=1,\n        col=1,\n    )\n    fig.add_trace(\n        go.Heatmap(\n            x=[],\n            z=[],\n            colorscale=[[0, \"rgb(66, 139, 202)\"], [1, \"rgb(255,0,0)\"]],\n            showscale=False,\n        ),\n        row=2,\n        col=1,\n    )\n\n    fig.update_yaxes(range=[0, 1.1], row=1, col=1)\n    fig.update_xaxes(matches=\"x1\", row=2, col=1)\n    fig.update_yaxes(visible=False, row=2, col=1)\n    fig.update_xaxes(visible=False, row=2, col=1)\n\n    fig.update_layout(\n        template=\"simple_white\",\n        showlegend=True,\n        xaxis_title=\"Échantillons: n\",\n    )\n    fig.update_layout(autosize=True)\n\n    fig.update_layout(\n        legend=dict(\n            yanchor=\"top\",\n            y=1.18,\n            x=0.85,\n            bgcolor=\"rgba(0,0,0,0)\",\n        )\n    )\n    fig.update_layout(\n        margin=dict(l=0, r=0, b=10, t=70),\n    )\n\n    register_widget(\"my_widget\", fig)\n\n    @reactive.Effect\n    def _():\n        p = input.p()\n        n_samples = input.n_samples()\n\n        rng = np.random.default_rng(seed())\n        iterations = np.arange(1, n_samples + 1)\n        samples = rng.binomial(1, p, size=n_samples)\n        means_samples = np.cumsum(samples) / np.arange(1, n_samples + 1)\n\n        # Update data in fig:\n        fig.data[0].x = iterations\n        fig.data[0].y = means_samples\n\n        fig.data[1].x = iterations\n        fig.data[1].y = np.full((n_samples), p)\n\n        fig.data[2].x = iterations\n        fig.data[2].z = [samples]\n\n        fig.update_xaxes(range=[1, n_samples + 1])\n\n        # Update the subplot titles:\n        fig.layout.annotations[1].update(\n            text=f\"Tirages aléatoires (seed=\"\n            + f\"{seed():03}\"\n            + \") &lt;br&gt; &lt;span style='color:rgb(66, 139, 202)'&gt;bleu: 0&lt;/span&gt;, &lt;span style='color:rgb(255, 0, 0)'&gt;rouge: 1&lt;/span&gt; \"\n        )\n\n\napp = App(app_ui, server)\n\nPour aller plus loin:\nQuand \\(p\\) varie (\\(n\\) fixé), les signaux générés sont très très proches, ce qui ne devrait pas être le cas sans structuration particulière de la génération. L’aléa est imparfait (structure sous-jacente)!",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#au-delà-de-la-loi-des-grands-nombres",
    "href": "Slides/slides_th_asymptotique.html#au-delà-de-la-loi-des-grands-nombres",
    "title": "Théorèmes asymptotiques",
    "section": "Au delà de la loi des grands nombres",
    "text": "Au delà de la loi des grands nombres\n\n1er ordre d’approximation de la convergence de \\(\\bar{X}_n\\): loi des grands nombres\n2ème ordre d’approximation: théorème central limite\n\nEnjeu: quantifier les variations de \\(\\bar X_n - \\mu\\)\nRéponse: théorème central limite (TCL), avec la convergence en loi d’une transformation affine de la moyenne empirique",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#théorème-central-limite-1",
    "href": "Slides/slides_th_asymptotique.html#théorème-central-limite-1",
    "title": "Théorèmes asymptotiques",
    "section": "Théorème central limite",
    "text": "Théorème central limite\n\nThéorème 2 (Théorème central limite) Soit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires i.i.d de variance \\(\\sigma^2 = {\\rm var}(X_1) \\in ]0, \\infty[\\). On note \\(\\mu = \\mathbb{E}[X_1]\\) leur espérance. Alors \\[\n\\sqrt n \\left(\\tfrac{\\bar X_n - \\mu}{\\sigma} \\right) \\xrightarrow[n \\to +\\infty]{\\mathcal{L}} N\\enspace,\n\\] où \\(N\\) suit une loi normale centrée réduite : \\(N \\sim\\mathcal{N}(0,1)\\).\n\nInterprétation: la moyenne empirique de v.a. i.i.d de variance \\(\\sigma^2\\) se comporte asymptotiquement comme une loi normale \\(\\mathcal{N}(\\mu, \\tfrac{\\sigma^2}{n})\\): \\(\\quad \\bar X_n \\approx \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n})\\).\n\n\n\n\n\n\nNote\n\n\nHypothèses du théorème plutôt faibles: variance finie uniquement",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#formulation-de-la-convergence",
    "href": "Slides/slides_th_asymptotique.html#formulation-de-la-convergence",
    "title": "Théorèmes asymptotiques",
    "section": "Formulation de la convergence",
    "text": "Formulation de la convergence\nConvergence en loi \\(\\iff\\) convergence des fonctions de répartition (aux pts de continuité)\nNotations:\n\n\\(\\varphi\\) : la densité d’une loi normale centrée réduite \\(\\varphi(x) = \\tfrac{e^{-\\frac{x^2}{2}}}{\\sqrt{2\\pi}}\\)\n\\(\\Phi\\) : la fonction de répartition d’une loi normale centrée réduite \\(\\Phi(x) = \\displaystyle \\int_{-\\infty}^{x}\\varphi(u) du\\)\n\n\nRé-écriture du TCL: pour tout \\(a &lt; b\\) on a alors\n\\[\n\\begin{align}\n    \\mathbb{P} \\left(\\bar X_n \\in [ \\mu + \\tfrac{a \\sigma}{\\sqrt{n}}, \\mu + \\tfrac{ b \\sigma}{\\sqrt{n}}] \\right)\n    & =\n    \\mathbb{P} \\left(\\tfrac{\\bar X_n - \\mu}{\\sigma} \\in [ \\tfrac{a}{\\sqrt{n}},\\tfrac{b}{\\sqrt{n}}]\\right) \\nonumber\\\\\n    & \\class{fragment}{{} = \\mathbb{P} \\bigg( a \\leq \\sqrt n \\left(\\tfrac{\\bar X_n - \\mu}{\\sigma} \\right) \\leq b\\bigg) \\nonumber}\n    \\\\\n    & \\class{fragment}{{} \\underset{n \\to \\infty}{\\longrightarrow}  \\int_a^b \\varphi(x) \\,  dx = \\Phi(b) - \\Phi(a) \\nonumber}\\\\\n\\end{align}\n\\]",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#lien-intervalle-de-confiance-et-tcl",
    "href": "Slides/slides_th_asymptotique.html#lien-intervalle-de-confiance-et-tcl",
    "title": "Théorèmes asymptotiques",
    "section": "Lien intervalle de confiance et TCL",
    "text": "Lien intervalle de confiance et TCL\n\n\nQuestion: comment choisir \\(a\\) et \\(b\\) pour obtenir un intervalle de confiance à 95% pour \\(\\mu\\)?\nNotation: \\(\\alpha_n=\\mathbb{P} \\left(\\bar X_n \\notin [ \\mu + \\tfrac{a \\sigma}{\\sqrt{n}}, \\mu + \\tfrac{ b \\sigma}{\\sqrt{n}}] \\right)\\), on cherche \\(a, b\\) tels que \\(\\alpha_n \\approx 0.05\\).\nSimplification: choix d’un intervalle symétrique autour de \\(\\mu \\implies q=a=-b\\) \\[\n\\begin{align}\n& 1-\\alpha_n \\approx \\int_{-q}^q \\varphi(x) \\,  dx=\\Phi(q)-\\Phi(-q)=2 \\Phi(q)-1 \\\\\n\\implies & \\boxed{q\\approx\\Phi^{-1}(1-\\tfrac{\\alpha_n}{2})}\n\\end{align}\n\\]\nInterpretation: \\(q\\) est (approx.) le quantile de niveau \\(1-\\tfrac{\\alpha_n}{2}\\) de la loi normale centrée réduite\nNumériquement: on peut facilement évaluer \\(q\\) et vérifier que \\(q\\approx 1.96\\) avec scipy\n\n\n\n\nfrom scipy.stats import norm  # import du module \"norm\" de scipy.stats\nq = norm.ppf((1-0.05/2))      # Calcul du quantile (en: Percent point function) de niveau 1-0.05/2\nprint(f\"{q:.2f}\")             # Affichage à 2 décimales\n\n1.96",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#visualization-du-tcl",
    "href": "Slides/slides_th_asymptotique.html#visualization-du-tcl",
    "title": "Théorèmes asymptotiques",
    "section": "Visualization du TCL",
    "text": "Visualization du TCL\n#| standalone: true\n#| viewerHeight: 600\nimport numpy as np\nfrom scipy.stats import norm\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom shiny import ui, render, App, reactive\nfrom shinywidgets import output_widget, render_widget\n\n\napp_ui = ui.page_fluid(\n    ui.tags.head(\n        ui.tags.style(\"\"\"\n            .bslib-sidebar-layout &gt; .sidebar &gt; .sidebar-content {\n            display: flex;\n            flex-direction: column;\n            padding: 0.1rem;\n            }\n            .irs--shiny .irs-line {\n            top: 27px;\n            height: 4px;\n            }\n            .irs.irs.irs--shiny .irs-bar {\n            top: 27px;\n            height: 4px;\n            }\n            .irs--shiny .irs-handle {\n            top: 23px;\n            width: 22px;\n            height: 10px;\n        \"\"\")\n    ),\n    ui.panel_title(\"TCL\"),\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_action_button(\"seed\", \"Nouveau tirage\",class_=\"btn-primary\"),\n            ui.input_slider(\"p\", \"Espérance: p\", 0.01, 0.99, value=0.5, step=0.01, ticks=False),\n            ui.input_slider(\"n_samples\", \"Échantillons: n\", 1, 200, value=100, step=1, ticks=False),\n            ui.input_slider(\"n_repetitions\", \"Répétitions: t\", 1, 300, value=200, step=1, ticks=False),\n        width=3\n        ),\n    ui.panel_main(output_widget(\"my_widget\"), width = 9)\n    )\n)\n\n\n\ndef server(input, output, session):\n    seed = reactive.Value(42)\n\n\n    @reactive.Effect\n    @reactive.event(input.seed)\n    def _():\n        seed.set(np.random.randint(0, 1000))\n\n\n    @output\n    @render_widget\n    def my_widget():\n\n        rng = np.random.default_rng(seed())\n        p = input.p()\n        n_repetitions = input.n_repetitions()\n        n_samples = input.n_samples()\n        iterations = np.arange(1, n_samples + 1)\n        samples = rng.binomial(1, p, size=(n_repetitions, n_samples))\n        means_samples = np.cumsum(samples, axis=1) / np.arange(1, n_samples + 1)\n        x_hist = np.linspace(0, 1, num=300)\n\n        # Create figure\n        fig = make_subplots(\n                    rows=1,\n                    cols=3,\n                    # vertical_spacing=0.5,\n                    horizontal_spacing=0.02,\n                    column_widths=[20, 2, 3],\n                    subplot_titles=(\"t = \" + str(n_repetitions) + \" répétitions\",\"\",\"\")\n                )\n\n\n        for i in range(n_repetitions):\n            fig.add_trace(\n                    go.Scatter(\n                        mode='lines',\n                        line=dict(color=\"rgba(0,0,0,0.05)\", width=1),\n                        x=iterations,\n                        y=means_samples[i,:],\n                        ),\n                        row=1, col=1,\n            )\n        fig.add_trace(\n                go.Scatter(\n                    mode='lines',\n                    line=dict(dash=\"dash\", color=\"blue\", width=1),\n                    marker={},\n                    x=iterations,\n                    y=np.full((n_samples), p),\n                    name='p'),\n                    row=1, col=1,\n        )\n        fig.update_layout(\n            template=\"simple_white\",\n            showlegend=False,\n        )\n        fig.add_trace(\n                go.Scatter(\n                    mode='markers',\n                    marker=dict(color=\"rgba(0,0,0,0.05)\", size=4),\n                    x=np.zeros(n_samples),\n                    y=means_samples[:,-1],\n                ),\n                row=1, col=2,\n\n        )\n        y_hist, bins = np.histogram(means_samples[:,-1], bins=int(np.sqrt(n_repetitions)), density=True)\n        fig.add_trace(\n            go.Bar(x=y_hist, y=bins[:-1] + np.diff(bins)/2,\n                    opacity=0.75,\n                    marker_color = 'black',\n                    orientation='h',\n                    width=np.diff(bins),\n                    name=\"Tirages de moyennes empiriques\",\n                    ),\n                row=1, col=3,\n        )\n        fig.add_trace(\n            go.Scatter(x=norm.pdf(x_hist, p, np.sqrt(p*(1-p) / n_samples)),\n                       y=x_hist,\n                       mode='lines',\n                       line=dict(color=\"red\"),\n                       legendgroup='1',\n                       name=\"TCL\"\n                       ),\n                row=1, col=3,\n        )\n\n        fig.update_xaxes(range=[1, n_samples + 1])\n        fig.update_yaxes(range=[-.05, 1.05], row=1, col=1)\n        fig.update_yaxes(matches=\"y1\",visible = False,  row=1, col=2)\n        fig.update_xaxes(range=[-0.2, 0.2], visible = False, row=1, col=2)\n\n        fig.update_yaxes(matches=\"y1\", row=1, col=3, visible=False)\n        fig.update_xaxes(range=[0, 1.1 / np.sqrt(2*np.pi* p*(1-p) / n_samples)], row=1, col=3)\n        fig.update_xaxes(visible=False, row=1, col=3)\n\n\n\n        for trace in fig['data']:\n            print(trace)\n            if (trace['name'] != 'TCL') and (trace['name'] != 'p'):\n                trace['showlegend'] = False\n        fig.update_layout(\n        margin=dict(l=0, r=0, b=10, t=100),\n        )\n        fig.update_layout(\n            title=dict(text=\"Distribution de la moyenne empirique&lt;br&gt; (cas loi de Bernoulli)\", yanchor=\"top\", y=0.95),\n            title_x=0.5,\n            showlegend=True,\n\n        )\n        fig.update_layout(\n            legend=dict(\n                yanchor=\"top\",\n                y=1.24,\n                xanchor=\"left\",\n                x=0.85,\n                bgcolor=\"rgba(0,0,0,0)\",\n            )\n        )\n        fig['layout']['xaxis']['title']='Échantillons: n'\n\n        fig.update_layout(autosize=True)\n\n        return fig\n\n\napp = App(app_ui, server)",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#pour-aller-plus-loin-vision-des-convolutions",
    "href": "Slides/slides_th_asymptotique.html#pour-aller-plus-loin-vision-des-convolutions",
    "title": "Théorèmes asymptotiques",
    "section": "Pour aller plus loin: vision des convolutions",
    "text": "Pour aller plus loin: vision des convolutions\n\n\nNotation: Soient \\(f\\) et \\(g\\) définies sur \\(\\mathbb{R}\\) (intégrables au sens de Lebesgue).\n\nDéfinition 1 (Convolution) La convolution de \\(f\\) par \\(g\\) est la fonction \\(f*g\\) suivante: \\[\n\\begin{align}\nf*g:\n\\mathbb{R} &\\mapsto \\mathbb{R} \\nonumber\\\\\nx &\\to \\int_{-\\infty}^{+\\infty} f(x-y)g(y) dy \\enspace.\\nonumber\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\nOn peut aussi obtenir \\(f*g(x)\\) en calculant \\(\\int_{\\mathbb{R}^2} f(u)g(v) {1\\hspace{-3.8pt} 1}_{u+v=x} du dv\\).",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#somme-et-convolutions",
    "href": "Slides/slides_th_asymptotique.html#somme-et-convolutions",
    "title": "Théorèmes asymptotiques",
    "section": "Somme et convolutions",
    "text": "Somme et convolutions\n\nThéorème 3 (Loi de la somme et convolutions) Soient \\(X\\) et \\(Y\\) des v.a. indépendantes de densités respectives \\(f\\) et \\(g\\), alors la densité de \\(X+Y\\) est donnée par la convolution \\(f*g\\).\n\nRappel: pour un scalaire \\(\\alpha\\neq 0\\), la densité de \\(\\alpha X\\) est donnée par la fonction \\(x \\mapsto \\frac{1}{|\\alpha|} \\cdot f(\\frac{x}{\\alpha})\\).\n\nCorollaire 1 (Loi de la moyenne) Soient \\(X_1,\\dots,X_n\\) des v.a. i.i.d. de densité \\(f\\), la densité de \\(\\bar{X}_n\\) est donnée par la fonction \\(x \\mapsto n \\cdot [f*\\dots*f](n \\cdot x)\\).",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_th_asymptotique.html#convolution-et-tcl",
    "href": "Slides/slides_th_asymptotique.html#convolution-et-tcl",
    "title": "Théorèmes asymptotiques",
    "section": "Convolution et TCL",
    "text": "Convolution et TCL\nPour \\(X_1, \\dots, X_n\\), i.i.d., de densité \\(f\\), on affiche la loi de \\(\\bar{X}_n\\) (à une constante près)\n#| standalone: true\n#| viewerHeight: 550\nimport numpy as np\nfrom shiny import ui, render, App, reactive\nfrom shinywidgets import output_widget, register_widget\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nfrom scipy import signal\n\n\napp_ui = ui.page_fluid(\n    ui.tags.head(\n        ui.tags.style(\"\"\"\n            .bslib-sidebar-layout &gt; .sidebar &gt; .sidebar-content {\n            display: flex;\n            flex-direction: column;\n            padding: 0.5rem;\n            }\n            .irs--shiny .irs-line {\n            top: 27px;\n            height: 2px;\n            }\n            .irs.irs--shiny .irs-bar {\n            top: 27px;\n            height: 2px;\n            }\n            .irs--shiny .irs-handle {\n            top: 23px;\n            width: 22px;\n            height: 10px;\n        \"\"\")\n    ),\n    ui.panel_title(\"TCL et convolutions\"),\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_select(\n                \"loi\",\n                \"Loi sous-jacente\",\n                {'uniforme': 'Uniforme', 'laplace' : 'Laplace'},\n            ),\n            ui.input_slider(\n                \"n_iter\",\n                \"Échantillons: n\",\n                1,\n                10,\n                value=1,\n                step=1,\n                ticks=False,\n            ), width = 3\n    ),\n    ui.panel_main(\n        output_widget(\"my_widget\"), width = 9\n    )\n)\n)\n\n\nnnzeros = 10001\nx_min = -20\nx_max = 20\n\nx = np.linspace(x_min, x_max, nnzeros)\ny = np.zeros(nnzeros)\nmask = np.where(np.abs(x) &lt;= 0.5, 1, 0)\ny[mask == 1] = 1\ndelta = (x_max - x_min) / nnzeros\nvar = np.sum(y * x**2 *(delta)) - (np.sum(y * x * delta))**2\n\ndef convolve(signal_in, n_convolutions, delta):\n    output = np.zeros(len(signal_in))\n    if n_convolutions == 0:\n        return output\n    elif n_convolutions == 1:\n        return signal_in\n    else:\n        output = signal_in.copy()\n        for i in range(n_convolutions - 1):\n            output = signal.fftconvolve(\n                output * delta, signal_in, mode=\"same\"\n            )\n        return output\n\n\ndef server(input, output, session):\n\n    fig = go.FigureWidget()\n    fig.add_trace(\n        go.Scatter(\n            mode=\"lines\",\n            line=dict(color=\"black\", width=3),\n            x=[],\n            y=[],\n            name=\"loi de de la moyenne empirique&lt;br&gt;(variance adéquate)\",\n        )\n    )\n\n    fig.add_trace(\n        go.Scatter(\n            x=x,\n            y=np.exp(-(x**2) / (2 * var)) / np.sqrt(2 * var * np.pi),\n            mode=\"lines\",\n            line=dict(dash=\"dash\", color=\"red\", width=2),\n            name=f\"Loi normale&lt;br&gt;(variance adéquate)\",\n        )\n    )\n    fig.update_xaxes(range=[-3, 3], position=0.)\n    fig.update_yaxes(range=[0, 2 * np.max(y)], position=0.5, showticklabels=False)\n\n\n    fig.update_layout(\n        template=\"simple_white\",\n        showlegend=True,\n        autosize=True,\n        title=dict(text=\"Densité : &lt;br&gt; moyenne de n variables aléatoires\", yanchor=\"top\", y=0.95),\n        title_x=0.5,\n    )\n    fig.update_layout(legend=dict(\n        yanchor=\"top\",\n        y=0.95,\n        xanchor=\"left\",\n        x=0.8,\n        font=dict(size= 18)\n    ))\n    fig.update_layout(\n    height=250,\n    margin=dict(l=0, r=0, b=10, t=100),\n    )\n\n    register_widget(\"my_widget\", fig)\n\n    @reactive.Effect\n    def _():\n        if str(input.loi()) == 'uniforme':\n            y = np.zeros(nnzeros)\n            mask = np.where(np.abs(x) &lt;= 0.5, 1, 0)\n            y[mask == 1] = 1\n\n        else:\n            y=np.exp(-np.abs(x)) / 2\n            y = y / (np.sum(y) * delta)\n\n        var = np.sum(y * x**2 * delta) - (np.sum(y * x * delta))**2\n\n        y_display = convolve(y, input.n_iter(), delta)\n        # Update data in fig:\n        fig.data[0].x = x / np.sqrt(input.n_iter())\n        fig.data[0].y = y_display * np.sqrt(input.n_iter())\n        fig.data[1].y = np.exp(-(x**2) / (2 * var)) / np.sqrt(2 * var * np.pi)\n        fig.update_yaxes(range=[0, 2 * np.max(y)], position=0.5, showticklabels=False)\n\n\napp = App(app_ui, server)\n\n\n\n\n\n\n\nPour aller plus loin\n\n\nPour plus d’info sur les convolutions, voir la vidéo de 3Blue1Brown : Convolutions | Why X+Y in probability is a beautiful mess, 🇬🇧\n\n\n\n\n\n\nThéorèmes asymptotiques",
    "crumbs": [
      "Slides",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#notation-et-rappels-de-probabilités",
    "href": "Slides/slides_notations_premiers_pas.html#notation-et-rappels-de-probabilités",
    "title": "Notations et premiers pas",
    "section": "Notation et rappels de probabilités",
    "text": "Notation et rappels de probabilités\n\n\nEspace probabilisé: \\((\\Omega, {\\mathcal{F}}, \\mathbb{P})\\)\n\ncomposé d’un ensemble: \\(\\Omega\\)\nd’une tribu: \\(\\mathcal{F}\\)\nd’une mesure de probabilité: \\(\\mathbb{P}\\)\n\n\n\n\n\nDéfinition 1 (Variable aléatoire, v.a.) Soit \\((E, \\mathcal{E})\\) un espace mesurable. Une variable aléatoire est une application mesurable \\[\n    \\begin{array}{ccccc}\n        X & : & \\Omega & \\to     & E            \\\\\n            &   & \\omega & \\mapsto & X(\\omega)\\,.\n    \\end{array}\n\\] Ainsi \\(\\{\\omega \\in \\Omega : X(\\omega) \\in B\\} =  X^{-1}(B) = \\{X \\in B\\} \\in \\mathcal{F}, \\forall B \\in \\mathcal{E}\\)",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#loi-dune-variable-aléatoire-unidimensionnelle",
    "href": "Slides/slides_notations_premiers_pas.html#loi-dune-variable-aléatoire-unidimensionnelle",
    "title": "Notations et premiers pas",
    "section": "Loi d’une variable aléatoire (unidimensionnelle)",
    "text": "Loi d’une variable aléatoire (unidimensionnelle)\n\nDéfinition 2 (Loi d’une variable aléatoire) \nSoit \\(X : (\\Omega, \\mathcal{F}, \\mathbb{P}) \\to (E, \\mathcal{E})\\) une v.a. On appelle loi de \\(X\\) la mesure de probabilité sur \\((E, \\mathcal{E})\\) définie par \\[\n        \\begin{array}{ccccc}\n            \\mathbb{P}_X & : & \\mathcal{E} & \\to     & [0,1]          \\\\\n                 &   & B           & \\mapsto & \\mathbb{P}(X \\in B) \\enspace.\n        \\end{array}\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\nLes propriétés de \\(\\mathbb{P}\\) assurent que \\(\\mathbb{P}_X\\) est bien une mesure de probabilité sur l’espace mesurable \\((E, \\mathcal{E})\\)",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#lois-discrètes",
    "href": "Slides/slides_notations_premiers_pas.html#lois-discrètes",
    "title": "Notations et premiers pas",
    "section": "Lois discrètes",
    "text": "Lois discrètes\nLes variables aléatoires discrètes sont celles à valeurs dans un ensemble \\(E\\) discret, le plus souvent \\(\\mathbb{N}\\), muni de la tribu pleine \\(\\mathcal{F} = \\mathcal{P}(E)\\).\n\nExemple 1 (Loi de Bernoulli) Soit un paramètre \\(p \\in [0,1]\\), et \\(E=\\{0,1\\}\\), alors la loi de Bernouilli est donnée par \\(\\mathbb{P}(X=1)=1-\\mathbb{P}(X=0) = p\\).\nNotation: \\(\\quad\\) \\(X \\sim \\mathcal{B}(p)\\)\n\nExemple physique:  loi d’un tirage de pile ou face, de biais \\(p\\)\n\nExemple 2 (Loi binomiale) Soient \\(p \\in [0,1]\\) (biais) et \\(n \\in \\mathbb{N}^*\\) (nombre de tirages) alors la loi Binomiale est donnée par \\(\\mathbb{P}(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}\\), pour \\(k \\in E=\\{0,\\dots,n\\}\\).\nNotation: \\(\\quad\\) \\(X \\sim \\mathcal{B}(n,p)\\)\n\nExemple physique:      loi du nombre de succès obtenus lors de \\(n\\) répétitions indépendantes d’une expérience aléatoire de Bernoulli de paramètre \\(p\\)",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#lois-discrètes-ii",
    "href": "Slides/slides_notations_premiers_pas.html#lois-discrètes-ii",
    "title": "Notations et premiers pas",
    "section": "Lois discrètes (II)",
    "text": "Lois discrètes (II)\n\nExemple 3 (Loi géométrique) Soient \\(p \\in [0,1]\\) (biais), alors la loi géométrique est donnée par \\(\\mathbb{P}(X=k) = p (1-p)^{k-1}\\), pour \\(k \\in E=\\mathbb{N}^*\\).\nNotation: \\(\\quad\\) \\(X \\sim \\mathcal{G}(p)\\)\n\n\nExemple physique:     \n\nloi du nombre tirage nécessaire avant d’obtenir un succès obtenus en répétant indépendamment des expériences aléatoires de Bernoulli de paramètre \\(p\\)\n\n\n\n\nExemple 4 (Loi de Poisson) Pour \\(\\lambda&gt;0\\), la loi de Poisson de paramètre \\(\\lambda\\) est définie par \\(\\mathbb{P}(X=k) = e^{-\\lambda} \\lambda^k / k!\\), pour tout \\(k \\in E=\\mathbb{N}\\).\nNotation: \\(\\quad\\) \\(X \\sim \\mathcal{P}(\\lambda)\\)\n\nExemple physique: comportement du nombre d’événements se produisant avec une fréquence connue, et indépendamment du temps écoulé depuis l’événement précédent (e.g., nombre de clients dans une file d’attente, nombre de mutations dans un gène, etc.)",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#lois-continues",
    "href": "Slides/slides_notations_premiers_pas.html#lois-continues",
    "title": "Notations et premiers pas",
    "section": "Lois continues",
    "text": "Lois continues\nLoi d’une v.a. admettant une fonction de densité, c’est-à-dire qu’il existe une fonction mesurable \\(f : \\mathbb{R} \\to [0, \\infty[\\) d’intégrale \\(1\\), telle que pour tout \\(A \\in \\mathcal{B}(\\mathbb{R})\\) \\[\n    \\mathbb{P}(X \\in A) = \\int_A f(x) dx \\enspace.\n\\]\n\n\n\n\n\n\nNote\n\n\nLes propriétés de l’intégrale de Lebesgue assurent que cette formule définit bien une loi de probabilité.\n\n\n\n\nEspérance: \\(\\mathbb{E}(X) = \\displaystyle\\int_{\\mathbb{R}} x f(x) dx\\)\nVariance: \\(\\mathbb{V}(X) = \\mathbb{E}((X-\\mathbb{E}(X))^2) = \\displaystyle\\int_{\\mathbb{R}} (x-\\mathbb{E}(X))^2 f(x) dx\\)",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#lois-continues-usuelles",
    "href": "Slides/slides_notations_premiers_pas.html#lois-continues-usuelles",
    "title": "Notations et premiers pas",
    "section": "Lois continues usuelles",
    "text": "Lois continues usuelles\n\nExemple 5 (Loi uniforme) La loi uniforme sur un ensemble \\(B \\in \\mathcal{B}(\\mathbb{R})\\), s’obtient avec la densité définie par \\[\nf(x) = {1\\hspace{-3.8pt} 1}_B(x) / \\lambda (B) \\enspace,\n\\] où \\(\\lambda (B)\\) représente la mesure de Lebesgue de l’ensemble \\(B\\).\n\nCas particulier: pour la loi uniforme sur \\([0,1]\\), on obtient la fonction suivante: \\[\nf(x) = {1\\hspace{-3.8pt} 1}_{[0,1]}(x)\\enspace.\n\\] Notation: \\(\\quad\\) \\(X \\sim \\mathcal{U}([0,1])\\)\n\n\n\n\n\n\nNote\n\n\nUne telle loi est caractérisée ainsi : tous les intervalles de même longueur inclus dans le support de la loi ont la même probabilité.",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#lois-continues-usuelles-ii",
    "href": "Slides/slides_notations_premiers_pas.html#lois-continues-usuelles-ii",
    "title": "Notations et premiers pas",
    "section": "Lois continues usuelles (II)",
    "text": "Lois continues usuelles (II)\n\n\nExemple 6 (Loi exponentielle) La loi exponentielle de paramètre \\(\\gamma &gt; 0\\) est obtenue avec la densité donnée par \\[\nf(x) = \\gamma e^{-\\gamma x} {1\\hspace{-3.8pt} 1}_{\\mathbb{R}_+}(x)\\enspace.\n\\] Notation: \\(\\quad X \\sim \\mathcal{Exp}(\\gamma)\\)\n\n\n\n\nProposition 1 (Absence de mémoire) La loi exponentielle modélise la durée de vie d’un phénomène sans mémoire (ou sans vieillissement), c’est-à-dire que pour tout \\(s,t&gt;0\\), on a \\[\n\\mathbb{P}(X&gt;t+s | X&gt;t)=\\mathbb{P}(X&gt;s) \\enspace.\n\\]",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#lois-continues-usuelles-iii",
    "href": "Slides/slides_notations_premiers_pas.html#lois-continues-usuelles-iii",
    "title": "Notations et premiers pas",
    "section": "Lois continues usuelles (III)",
    "text": "Lois continues usuelles (III)\n\nExemple 7 (Loi normale/gaussienne univariée) Pour des paramètres \\(\\mu \\in \\mathbb{R}\\) (espérance) et \\(\\sigma^2 &gt; 0\\) (variance), la loi normale associée correspond à la fonction de densité : \\[\nf(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{-\\frac{1}{2 \\sigma^2}(x-\\mu)^2} \\enspace.\n\\] Notation: \\(X \\sim \\mathcal{N}(\\mu,\\sigma^2)\\),\n\nOn nomme loi normale centrée réduite le cas canonique: \\(\\mu = 0, \\sigma^2 = 1\\).\nSi \\(X\\sim \\mathcal{N}(\\mu,\\sigma^2)\\), alors l’espérance et la variance de \\(X\\) valent \\(\\mathbb{E}(X) = \\mu\\) et \\(\\mathbb{V}(X) = \\sigma^2\\).\n\n\n\n\n\n\n\nNote\n\n\nLes lois normales sont omniprésente grâce au théorème central limite.",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#enjeu-de-la-fonction-de-répartition",
    "href": "Slides/slides_notations_premiers_pas.html#enjeu-de-la-fonction-de-répartition",
    "title": "Notations et premiers pas",
    "section": "Enjeu de la fonction de répartition",
    "text": "Enjeu de la fonction de répartition\n\nEnjeux: caractériser la loi d’une v.a. en ne considérant que l’espace d’arrivée \\((E, \\mathcal{E})\\)\n\n\nOutils:\n\n\nla fonction de répartition (v.a. réelles),\nla fonction caractéristique (v.a. dans \\(\\mathbb{R}^d\\)), en gros la transformée de Fourier de la loi!\nla fonction génératrice des moments (v.a. discrètes)\netc.",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#fonction-de-répartition",
    "href": "Slides/slides_notations_premiers_pas.html#fonction-de-répartition",
    "title": "Notations et premiers pas",
    "section": "Fonction de répartition",
    "text": "Fonction de répartition\n\nDéfinition 3 (Fonction de répartition 🇬🇧: cumulative distribution function) \nSoit \\(X\\) une variable aléatoire sur \\((\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))\\). La fonction de répartition de \\(X\\) est la fonction \\(F_X\\) définie sur \\(\\mathbb{R}\\) par \\[\n\\begin{align*}\n     F_X(x) & = \\mathbb{P}(X \\leq x)\\\\\n     & \\class{fragment}{{} = \\mathbb{P}(X \\in ]-\\infty, x])}\n\\end{align*}\n\\]",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#propriété-élémentaire-de-la-fonction-de-répartition",
    "href": "Slides/slides_notations_premiers_pas.html#propriété-élémentaire-de-la-fonction-de-répartition",
    "title": "Notations et premiers pas",
    "section": "Propriété élémentaire de la fonction de répartition",
    "text": "Propriété élémentaire de la fonction de répartition\n\nProposition 2 (Propriétés élémentaires) Soit \\(X\\) une v.a. de fonction de répartition \\(F_X\\).\n\n\n\\(F_X\\) est une fonction croissante, de limite \\(0\\) en \\(-\\infty\\) et de limite \\(1\\) en \\(+\\infty\\).\n\\(F_X\\) est continue à droite en tout point.\n\\(\\forall x \\in \\mathbb{R}\\), on a \\(\\mathbb{P}(X=x) = F_X(x) - \\lim_{\\epsilon \\to 0+}F_X(x- \\epsilon)\\).\nSi \\(X\\) a pour densité \\(f\\), alors \\(F_X\\) est dérivable \\(\\lambda\\)-presque partout de dérivée \\(f\\).\n\n\n\n\nDémonstration: voir par exemple (Barbe et Ledoux 2006)\n\n\n\n\n\n\n\n\nNote\n\n\n\nProp. 1. et 2. : \\(F_X\\) est càdlàg (continue à droite, limite à gauche).\nProp 3. (cas discret): les valeurs prises par \\(X\\) correspondent aux discontinuités de \\(F_X\\), les probabilités, à la hauteur du saut.\nProp. 4. (cas continu): le lien entre la fonction de répartition et densité.",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#fonction-de-répartition-et-caractérisation-de-la-loi",
    "href": "Slides/slides_notations_premiers_pas.html#fonction-de-répartition-et-caractérisation-de-la-loi",
    "title": "Notations et premiers pas",
    "section": "Fonction de répartition et caractérisation de la loi",
    "text": "Fonction de répartition et caractérisation de la loi\n\nThéorème 1 (Caractérisation de la loi d’une variable aléatoire réelle) \nLa fonction de répartition d’une variable aléatoire caractérise sa loi : deux variables aléatoires ont même loi si et seulement si elles ont même fonction de répartition.\n\n\n\nDémonstration: voir Wikipedia \nRappel: la tribu des boréliens est engendrée par la famille d’ensembles \\(\\{]-\\infty,x], x \\in \\mathbb{R}\\}\\) \nInterprétation: connaître \\(\\mathbb{P}_X\\) sur cette famille d’ensembles \\(\\implies\\) la connaître partout",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#fonction-de-répartition-cas-discret",
    "href": "Slides/slides_notations_premiers_pas.html#fonction-de-répartition-cas-discret",
    "title": "Notations et premiers pas",
    "section": "Fonction de répartition: cas discret",
    "text": "Fonction de répartition: cas discret\n Dans le cas d’une loi discrète, la fonction de répartition est une fonction en escalier, constante par morceaux, et croissante.   \n\nExemple 8 (Cas discret) Soit \\((x_i)_{i \\in I}\\) une suite ordonnée de réels, avec \\(I \\subset \\mathbb{N}\\). Si \\(X\\) est une variable aléatoire discrète prenant les valeurs \\((x_i)_{i \\in I}\\) et de loi \\((p_i = \\mathbb{P}(X=x_i))_{i \\in I}\\), alors \\[\n\\forall x \\in \\mathbb{R}, \\quad F_X(x) = \\sum_{i \\in I} p_i {1\\hspace{-3.8pt} 1}_{[x_i, \\infty[}(x) \\enspace.\n\\]",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#fonction-de-répartition-cas-continu",
    "href": "Slides/slides_notations_premiers_pas.html#fonction-de-répartition-cas-continu",
    "title": "Notations et premiers pas",
    "section": "Fonction de répartition: cas continu",
    "text": "Fonction de répartition: cas continu\n\n\n\n\nExemple 9 (Cas continu) Si \\(X\\) est une variable aléatoire de densité \\(f\\), alors \\[\n\\forall x \\in \\mathbb{R}, \\quad F_X(x) = \\int_{-\\infty}^x f(t) \\, \\mathrm dt \\enspace.\n\\]\n\nVocabulaire: densité (🇬🇧: probability density function)",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#loi-normale",
    "href": "Slides/slides_notations_premiers_pas.html#loi-normale",
    "title": "Notations et premiers pas",
    "section": "Loi normale",
    "text": "Loi normale\nCas de la loi normale centrée réduite, \\(X \\sim \\mathcal{N}(0,1)\\): \\(F_X=\\Phi\\), avec \\(\\Phi\\) définie par \\[\nF_X(x) \\triangleq \\Phi(x) = \\dfrac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^x e^{-\\frac{t^2}{2}}\\, \\mathrm d t\\enspace,\n\\]\n\n\n\n\n\n\nNote\n\n\nL’intégrale ne peut être obtenue à partir d’une formule fermée1. Autrefois, les valeurs de \\(\\Phi(x)\\) étaient reportées dans des tables2.\n\n\n\n\n\nTransformation affine: si \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) — i.e., \\(X=\\mu + \\sigma Y\\), avec \\(Y\\sim \\mathcal{N}(0,1)\\) — alors \\[\nF_X(x)=\\Phi\\left(\\frac{x-\\mu}{\\sigma}\\right)\n\\]\n\n\nWikipedia: Théorème de LiouvilleWikipedia: loi normale",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#fonction-quantile-inverse-généralisée-à-gauche",
    "href": "Slides/slides_notations_premiers_pas.html#fonction-quantile-inverse-généralisée-à-gauche",
    "title": "Notations et premiers pas",
    "section": "Fonction quantile, inverse généralisée à gauche",
    "text": "Fonction quantile, inverse généralisée à gauche\n\nDéfinition 4 (Fonction quantile/ inverse généralisée 🇬🇧: quantile distribution function) \nSoit \\(X\\) une variable aléatoire sur \\((\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))\\) et \\(F_X\\) sa fonction de répartion. La fonction quantile associée \\(F_X^\\leftarrow: ]0,1[ \\rightarrow \\mathbb{R}\\) est définie par \\[\n  F_X^\\leftarrow(p) = \\inf\\{ x \\in \\mathbb{R} : F_X(x)\\geq p\\} \\enspace.\n\\]\n\n\n\\(F_X\\) est bijective \\(\\implies\\) \\(F^{-1}=F_X^\\leftarrow\\)\n\nVocabulaire:\n\nla fonction quantile s’appelle aussi inverse de Levy ou inverse généralisée (à gauche)\nmédiane : \\(F_X^\\leftarrow(1/2)\\)\npremier/troisième quartile: \\(F_X^\\leftarrow(1/4), F_X^\\leftarrow(3/4)\\)\ndéciles : \\(F_X^\\leftarrow(k/10)\\) pour \\(k=1,\\dots, 9\\)",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#quantiles-cas-continu",
    "href": "Slides/slides_notations_premiers_pas.html#quantiles-cas-continu",
    "title": "Notations et premiers pas",
    "section": "Quantiles: cas continu",
    "text": "Quantiles: cas continu\n\n\n\nPlotly = require('plotly.js-dist');\ndists = require( 'https://cdn.jsdelivr.net/gh/stdlib-js/stats-base-dists@umd/browser.js' );\n// see source here: https://github.com/stdlib-js/stats-base-dists/tree/umd\n// continuous case\njstatPDFs = () =&gt; {\n  const distributions = Object.keys(dists);\n  // Get in continuousDistributions the distributions whose pdf, cdf and quantile are defined\n    const continuousDistributions = distributions.filter(name =&gt; dists[name].pdf && dists[name].cdf && dists[name].quantile);\n  return continuousDistributions\n};\noutput = jstatPDFs();\n\nexcludedPDFs = [];\npdfNames_unsorted = output.filter(name =&gt; !excludedPDFs.includes(name));\npdfNames=pdfNames_unsorted.toSorted();\nviewof inputs = Inputs.form([\n      Inputs.range([-10, 10], {value: 0.1, step: 0.001, label: tex`\\mu`, width: 500}),\n      Inputs.range([0.01, 5], {value: 1.01, step: 0.001, label: tex`\\sigma`, width: 500}),\n      Inputs.range([0.001, 0.999], {value: 0.75, step: 0.001, label:tex`\\alpha`, width: 500}),\n    ]);\n\n\nviewof distrib_name = Inputs.select(pdfNames, {value: \"normal\", label: \"Loi\", width: 500});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const x = d3.range(-5, 5, 0.01);\n  const pdf = x.map(x =&gt; dists[distrib_name].pdf(x, mu, sigma));\n  const cdf = x.map(x =&gt; dists[distrib_name].cdf(x, mu, sigma));\n  const inv = x.map(x =&gt; dists[distrib_name].quantile(x, mu, sigma));\n  const quantile = dists[distrib_name].quantile(alpha, mu, sigma);\n  const filteredX = x.filter(coord =&gt; coord &lt; quantile);\n  const filteredPdf = pdf.filter((_, i) =&gt; x[i] &lt;= quantile);\n  const filteredCdf = cdf.filter(coord =&gt; coord &lt;= quantile);\n\n\n{\nvar trace1 = {\n      type: \"scatter\",\n      name: 'Quantile',\n      x: cdf,\n      y: x,\n      line: {color: 'black'},\n      xaxis: 'x1',\n      yaxis: 'y3',\n\n\n};\n\nvar trace12 = {\n        x : [alpha, alpha],\n        y : [x[0], quantile],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y3',\n\n\n};\n\n\n\nvar trace13 = {\n    x: [0, alpha],\n    y: [quantile, quantile],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x1',\n    yaxis: 'y3'\n}\n\n\nvar trace2 = {\nx: cdf,\ny: cdf,\ntype: 'scatter',\nname: 'identity',\nline: {color: 'black'},\nxaxis: 'x1',\nyaxis: 'y2'\n\n};\n\n\nvar trace21 = {\n        x : [alpha, 1],\n        y : [alpha, alpha],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y2'\n}\n\nvar trace22 = {\n        x : [alpha, alpha],\n        y : [alpha, 1],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y2'\n}\n\n\n\nvar trace23 = {\n    x: [alpha],\n    y: [alpha],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x1',\n    yaxis: 'y2'\n}\n\n\nvar trace31 = {\n      type: \"scatter\",\n      mode: \"lines\",\n      name: 'PDF2',\n      x: x,\n      y: cdf,\n      line: {color: 'black'},\n      xaxis: 'x2',\n      yaxis: 'y2',\n};\n\nvar trace32 = {\n        x: filteredX,\n        y: filteredX.map(x =&gt; alpha),\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n          },\n      xaxis: 'x2',\n      yaxis: 'y2'\n}\n\nvar trace33 = {\n        x : [quantile, quantile],\n        y : [0, alpha],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n          },\n\n      xaxis: 'x2',\n      yaxis: 'y2'\n}\n\nvar trace34 = {\n    x: [quantile],\n    y: [alpha],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x2',\n    yaxis: 'y2'\n}\n\n\nvar trace41 = {\n\n  type: \"scatter\",\n  name: 'Quantile2',\n  fill: 'tozeroy',\n  x: filteredX,\n  y: filteredPdf,\n  opacity: 0.9,\n  line: {color: ' #428BCA'},\n  xaxis: 'x2',\n  yaxis: 'y1'\n\n};\n\n\nvar trace42 = {\n\n  type: \"scatter\",\n  mode: \"lines\",\n  name: 'PDF2',\n  x: x,\n  y: pdf,\n  line: {color: 'black'},\n  xaxis: 'x2',\n  yaxis: 'y1'\n\n};\n\nvar data = [\n  trace1,\n  trace12, trace13,\n  trace2, trace21, trace22, trace23,\n  trace31, trace32, trace33, trace34,\n  trace41, trace42];\n\n\nvar layout = {\n\n  title: 'Distribution et quantile',\n  xaxis: {\n    domain: [0, 0.32],\n    anchor: 'y1'\n  },\n  yaxis: {\n    domain: [0, 0.24],\n    anchor: 'x1'\n\n  },\n  xaxis2: {\n    domain: [0.35, 1],\n    anchor: 'y'\n  },\n\n  yaxis2: {\n    domain: [0.26, 0.49],\n    anchor: 'x1'\n  },\n\n  yaxis3: {\n    domain: [0.5, 1],\n    anchor: 'x1'\n  },\n\n// legend offset\n  showlegend: false,\n  height: 680,\n  annotations: [\n\n    {\n      x: 1/4,\n      y: quantile - (x[0]-x.slice(-1))/20,\n      xref: 'x1',\n      yref: 'y3',\n      text: 'q= ' + quantile.toFixed(2),\n      font: {\n        size: 12,\n        color: '#428BCA',\n\n      },\n      showarrow: false,\n      arrowhead: 0,\n      ax: 25,\n      ay: -10,\n\n    },\n    {\n      x: 1/4,\n      y: alpha,\n      xref: 'x1',\n      yref: 'y2',\n      text: 'alpha= ' + alpha.toFixed(2),\n      font: {\n        size: 12,\n        color: '#428BCA',\n\n      },\n      showarrow: false,\n      arrowhead: 0,\n      ax: 25,\n      ay: -10,\n\n    },\n    {\n        text: \"Fonction quantile\",\n      font: {\n      size: 15,\n      color: 'black',\n    },\n    showarrow: false,\n    align: 'center',\n    x: -0.01,\n    y: 1.05,\n    xref: 'paper',\n    yref: 'paper',\n    },\n    {\n      text: \"Fonction de répartition\",\n      font: {\n      size: 15,\n      color: 'black',\n            },\n    showarrow: false,\n    align: 'center',\n    x: 0.65,\n    y: 0.52,\n    xref: 'paper',\n    yref: 'paper',\n    },\n    {\n      text: \"Fonction de densité\",\n      font: {\n      size: 15,\n      color: 'black',\n            },\n    showarrow: false,\n    align: 'center',\n    x: 0.65,\n    y: 0.225,\n    xref: 'paper',\n    yref: 'paper',\n    },\n  ]\n\n};\n// XXX: TODO: put the xticks labels on the middle plot for x and on the right plot for y\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.newPlot(div, data, layout, config);\n    return div;\n  }\n\n}\n\n\n\n\n\n\n\nmu = inputs[0];\nsigma = inputs[1];\nalpha = inputs[2]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: voir aussi Notations et rappels",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#quantiles-cas-discret",
    "href": "Slides/slides_notations_premiers_pas.html#quantiles-cas-discret",
    "title": "Notations et premiers pas",
    "section": "Quantiles: cas discret",
    "text": "Quantiles: cas discret\n\n\n\ndiscretePDFs = () =&gt; {\n  const distributions = Object.keys(dists);\n  // Get in continuousDistributions the distributions whose pdf, cdf and quantile are defined\n    const continuousDistributions = distributions.filter(name =&gt; dists[name].pmf && dists[name].cdf && dists[name].quantile);\n  return continuousDistributions\n};\noutput_discr = discretePDFs();\n\npmfNames_unsorted = output_discr.filter(name =&gt; !excludedPDFs.includes(name));\npmfNames=pmfNames_unsorted.toSorted();\nviewof inputs_disc = Inputs.form([\n      Inputs.range([-10, 10], {value: 0.1, step: 0.001, label: tex`\\mu `, width: 500}),\n      Inputs.range([0.01, 5], {value: 1.01, step: 0.001, label: tex`\\sigma `, width: 500}),\n      Inputs.range([0.001, 0.999], {value: 0.75, step: 0.001, label: tex`\\alpha`, width: 500}),\n    ]);\n\nviewof distrib_name_discr = Inputs.select(pmfNames, {value: \"normal\", label: \"Loi\", width: 500});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n  const z = d3.range(-5, 5, 0.01);\n  const pmf = z.map(z =&gt; dists[distrib_name_discr].pmf(z, mu_disc, sigma_disc));\n  const cdf = z.map(z =&gt; dists[distrib_name_discr].cdf(z, mu_disc, sigma_disc));\n  const inv = z.map(z =&gt; dists[distrib_name_discr].quantile(z, mu_disc, sigma_disc));\n  const quantile = dists[distrib_name_discr].quantile(alpha_disc, mu_disc, sigma_disc);\n  const filteredX = z.filter(coord =&gt; coord &lt;= quantile);\n  const filteredPmf = pmf.filter((_, i) =&gt; z[i] &lt;= quantile);\n  const filteredCdf = cdf.filter(coord =&gt; coord &lt;= quantile);\n\n\n{\nvar trace1 = {\n      type: \"scatter\",\n      name: 'Quantile',\n      x: cdf,\n      y: z,\n      line: {color: 'black'},\n      xaxis: 'x1',\n      yaxis: 'y3',\n\n\n};\n\nvar trace12 = {\n        x : [alpha_disc, alpha_disc],\n        y : [z[0], quantile],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y3',\n\n\n};\n\n\n\nvar trace13 = {\n    x: [0, alpha_disc],\n    y: [quantile, quantile],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x1',\n    yaxis: 'y3'\n}\n\n\nvar trace2 = {\nx: cdf,\ny: cdf,\ntype: 'scatter',\nname: 'identity',\nline: {color: 'black'},\nxaxis: 'x1',\nyaxis: 'y2'\n\n};\n\n\nvar trace21 = {\n        x : [alpha_disc, 1],\n        y : [alpha_disc, alpha_disc],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y2'\n}\n\nvar trace22 = {\n        x : [alpha_disc, alpha_disc],\n        y : [alpha_disc, 1],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y2'\n}\n\nvar trace23 = {\n    x: [alpha_disc],\n    y: [alpha_disc],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x1',\n    yaxis: 'y2'\n}\n\n\nvar trace31 = {\n      type: \"scatter\",\n      mode: \"lines\",\n      name: 'PDF2',\n      x: z,\n      y: cdf,\n      line: {color: 'black'},\n      xaxis: 'x2',\n      yaxis: 'y2',\n};\n\nvar trace32 = {\n        x: filteredX,\n        y: filteredX.map(z =&gt; alpha_disc),\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n          },\n      xaxis: 'x2',\n      yaxis: 'y2'\n}\n\nvar trace33 = {\n        x : [quantile, quantile],\n        y : [0, alpha_disc],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n          },\n\n      xaxis: 'x2',\n      yaxis: 'y2'\n}\n\nvar trace34 = {\n    x: [quantile],\n    y: [alpha_disc],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x2',\n    yaxis: 'y2'\n}\n\n\nvar trace41 = {\n\n  type: \"scatter\",\n  name: 'Quantile2',\n  fill: 'tozeroy',\n  x : filteredX,\n  y : filteredPmf,\n  opacity: 0.9,\n  line: {color: ' #428BCA'},\n  xaxis: 'x2',\n  yaxis: 'y1'\n\n};\n\n\nvar trace42 = {\n\n  type: \"scatter\",\n  mode: \"lines\",\n  name: 'PDF2',\n  x: z,\n  y: pmf,\n  line: {color: 'black'},\n  xaxis: 'x2',\n  yaxis: 'y1'\n\n};\n\nvar data = [\n  trace1,\n  trace12, trace13,\n  trace2, trace21, trace22, trace23,\n  trace31, trace32, trace33, trace34,\n  trace41, trace42];\n\n\nvar layout = {\n\n  title: 'Distribution et quantile',\n  xaxis: {\n    domain: [0, 0.32],\n    anchor: 'y1'\n  },\n  yaxis: {\n    domain: [0, 0.24],\n    anchor: 'x1'\n\n  },\n  xaxis2: {\n    domain: [0.35, 1],\n    anchor: 'y'\n  },\n\n  yaxis2: {\n    domain: [0.26, 0.49],\n    anchor: 'x1'\n  },\n\n\n\n  yaxis3: {\n    domain: [0.5, 1],\n    anchor: 'x1'\n\n  },\n\n  showlegend: false,\n  height: 680,\n\n\n  annotations: [\n\n    {\n      x: 1/4,\n      y: quantile - (z[0]-z.slice(-1))/20,\n      xref: 'x1',\n      yref: 'y3',\n      text: 'q=' + quantile.toFixed(2),\n      font: {\n        size: 12,\n        color: '#428BCA',\n\n      },\n      showarrow: false,\n      arrowhead: 0,\n      ax: 25,\n      ay: -10,\n\n    },\n    {\n      x: 1/4,\n      y: alpha_disc,\n      xref: 'x1',\n      yref: 'y2',\n      text: 'alpha=' + alpha_disc.toFixed(2),\n      font: {\n        size: 12,\n        color: '#428BCA',\n\n      },\n      showarrow: false,\n      arrowhead: 0,\n      ax: 25,\n      ay: -10,\n\n    },\n    {\n        text: \"Fonction quantile\",\n      font: {\n      size: 15,\n      color: 'black',\n    },\n    showarrow: false,\n    align: 'center',\n    x: -0.01,\n    y: 1.05,\n    xref: 'paper',\n    yref: 'paper',\n    },\n    {\n      text: \"Fonction de répartition\",\n      font: {\n      size: 15,\n      color: 'black',\n            },\n    showarrow: false,\n    align: 'center',\n    x: 0.65,\n    y: 0.52,\n    xref: 'paper',\n    yref: 'paper',\n    },\n    {\n      text: \"Fonction de densité\",\n      font: {\n      size: 15,\n      color: 'black',\n            },\n    showarrow: false,\n    align: 'center',\n    x: 0.65,\n    y: 0.225,\n    xref: 'paper',\n    yref: 'paper',\n    },\n  ]\n\n};\n// XXX: TODO: put the xticks labels on the middle plot for x and on the right plot for y\n\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.newPlot(div, data, layout, config);\n    return div;\n  }\n\n}\n\n\n\n\n\n\n\nmu_disc = inputs_disc[0];\nsigma_disc = inputs_disc[1];\nalpha_disc = inputs_disc[2];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: voir aussi Notations et rappels",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_notations_premiers_pas.html#bibliographie",
    "href": "Slides/slides_notations_premiers_pas.html#bibliographie",
    "title": "Notations et premiers pas",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\nBarbe, Philippe, et Michel Ledoux. 2006. Probabilités.\n\n\n\n\n\nNotations et premiers pas",
    "crumbs": [
      "Slides",
      "Notations et premiers pas"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#rappel-concernant-la-loi-normale",
    "href": "Slides/slides_loi_normale1D.html#rappel-concernant-la-loi-normale",
    "title": "Loi normale: cas univarié",
    "section": "Rappel concernant la loi normale",
    "text": "Rappel concernant la loi normale\n\n\nPour \\(\\mu \\in \\mathbb{R}\\) et \\(\\nu &gt; 0\\), on note \\(X \\sim \\mathcal{N}(\\mu, \\nu)\\), si \\(X\\) est une variable aléatoire ayant pour densité \\(\\varphi_{\\mu, \\nu}\\):\n\\[\n\\forall x \\in \\mathbb{R}, \\quad \\varphi_{\\mu, \\nu}(x)=\\frac{1}{\\sqrt{2 \\pi \\nu}}\\exp\\Big(-\\frac{(x-\\mu)^2}{2\\nu}\\Big)\\enspace.\n\\]\n\n\nEspérance: \\(X\\) a pour espérance \\(\\mu\\), \\(\\mathbb{E}(X)=\\mu\\),\nVariance: \\(X\\) a pour variance \\(\\nu\\), \\(\\mathbb{V}(X)=\\nu\\).\nCas particulier \\(\\mu=0\\) et \\(\\nu=1\\) correspond à une variable aléatoire dite centrée réduite.\n\n\n\n\nOn parle aussi de loi gaussienne, en hommage au mathématicien Carl Friedrich Gauss, le prince des mathématiciens: (1777-1855) mathématicien, astronome et physicien né à Brunswick, directeur de l’observatoire de Göttingen de 1807 jusqu’à sa mort en 1855",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#visualisation-de-la-densité-de-la-loi-normale",
    "href": "Slides/slides_loi_normale1D.html#visualisation-de-la-densité-de-la-loi-normale",
    "title": "Loi normale: cas univarié",
    "section": "Visualisation de la densité de la loi normale",
    "text": "Visualisation de la densité de la loi normale\nvoir https://josephsalmon.github.io/HAX603X/Courses/loi_normale1D.html",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#propriétés-de-la-loi-normale",
    "href": "Slides/slides_loi_normale1D.html#propriétés-de-la-loi-normale",
    "title": "Loi normale: cas univarié",
    "section": "Propriétés de la loi normale",
    "text": "Propriétés de la loi normale\n\n\nstabilité par transformation affine :\nsi \\(X \\sim \\mathcal{N}(\\mu, \\nu)\\) et si \\((\\alpha,\\beta) \\in \\mathbb{R}^* \\times \\mathbb{R}\\), alors \\(\\alpha X + \\beta \\sim \\mathcal{N}(\\alpha\\mu + \\beta, \\alpha^2 \\nu)\\).\n\nsi \\(X \\sim \\mathcal{N}(0,1)\\), alors \\(\\sqrt{\\nu} X + \\mu \\sim \\mathcal{N}(\\mu, \\nu)\\),\nsi \\(X \\sim \\mathcal{N}(\\mu, \\nu)\\), alors \\((X-\\mu)/\\sqrt{\\nu} \\sim \\mathcal{N}(0,1)\\).\n\n\n\n\n\nConséquence: pour simuler selon une loi normale, il suffit de savoir le faire pour le cas centré-réduit, puis d’utiliser la propriété ci-dessus",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#fonction-caractéristique",
    "href": "Slides/slides_loi_normale1D.html#fonction-caractéristique",
    "title": "Loi normale: cas univarié",
    "section": "Fonction caractéristique",
    "text": "Fonction caractéristique\n\nProposition 1 (Fonction caractéristique de la loi normale) La fonction caractéristique d’une variable aléatoire \\(X \\sim \\mathcal{N}(\\mu, \\nu)\\) est donnée pour tout \\(t \\in \\mathbb{R}\\) par \\[\n\\begin{align*}\n\\phi_{\\mu,\\nu}(t) & \\triangleq \\mathbb{E}(e^{i t X}) = \\exp\\Big( i \\mu t - \\frac{\\nu t^2}{2}\\Big)\\enspace.\n\\end{align*}\n\\]\n\nCas particulier: si \\(X \\sim \\mathcal{N}(0,1)\\), alors \\(\\phi_{0,1}(t) = \\exp\\Big( - \\frac{t^2}{2}\\Big)\\)\n\nÉléments de preuve: pour tout \\(z \\in \\mathbb{R}\\), on calcule la transformée de Laplace, puis on l’étend ensuite sur \\(\\mathbb{C}\\), et on l’instancie pour \\(z=it\\).\n\n\n\\[\n\\begin{align*}\n\\class{fragment}{{}\\mathbb{E}[e^{zX}]}&\n\\class{fragment}{{}=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12x^2}e^{zx}\\,dx} \\class{fragment}{{}= \\frac{e^{\\frac12z^2}}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12(x-z)^2}\\,dx}\\\\\n&\\class{fragment}{{}=\\frac{e^{\\frac12z^2}}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12y^2}\\,dy}\\class{fragment}{{}\n=e^{\\frac12z^2}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#idée-naïves-pour-simuler-une-loi-normale",
    "href": "Slides/slides_loi_normale1D.html#idée-naïves-pour-simuler-une-loi-normale",
    "title": "Loi normale: cas univarié",
    "section": "Idée naïves pour simuler une loi normale",
    "text": "Idée naïves pour simuler une loi normale\n\nMéthode de l’inverse: besoin d’un calcul de la fonction de répartition de la loi normale, qui n’a pas de forme analytique simple (analyse numérique, méthode coûteuse).\nTCL: tirer \\(U_1, \\dots, U_n\\) i.i.d. et uniforme sur \\([0,1]\\), puis poser \\[\n  \\sqrt{n}\\frac{(\\bar{U}_n - 1/2)}{\\sqrt{1/12}}\n\\] Limite: seulement une approximation, et convergence relativement lente (coût élevé)\nAlternatives: nécessite opérations de changement de variables",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#changement-de-variables-en-dimension-2",
    "href": "Slides/slides_loi_normale1D.html#changement-de-variables-en-dimension-2",
    "title": "Loi normale: cas univarié",
    "section": "Changement de variables en dimension 2",
    "text": "Changement de variables en dimension 2\nSoit \\(\\phi\\) un \\(C^1\\)-difféomorphisme de \\(\\mathbb{R}^2\\) (bijection dont la réciproque est également de classe \\(C^1\\))\n\nRappel: la jacobienne de \\(\\phi^{-1}\\) correspond à la matrice (application linéaire) des dérivées partielles. Ainsi, si \\(\\phi(x,y) = (u,v) \\iff (x,y) = \\phi^{-1}(u,v)\\), alors \\[\n\\begin{align*}\n{\\rm{J}}_{\\phi^{-1}}: (u,v) & \\mapsto\n\\begin{pmatrix}\n  \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v}    \\\\\n  \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}\n\\end{pmatrix} \\in \\mathbb{R}^{2\\times 2}\n\\end{align*}\n\\]\n\n\n\nThéorème 1 (Caractérisation de la loi d’une variable aléatoire réelle) Soit \\((X,Y)\\) un vecteur aléatoire de densité \\(f_{(X,Y)}\\) définie sur l’ouvert \\(A \\subset \\mathbb{R}^2\\) et \\(\\phi : A \\to B \\subset \\mathbb{R}^2\\) un \\(C^1\\)-difféomorphisme. Le vecteur aléatoire \\((U,V)=\\phi(X,Y)\\) admet alors pour densité \\(f_{(U,V)}\\) définie sur \\(B\\) pour tout \\((u,v) \\in \\mathbb{R}^2\\) par \\[\n\\begin{align*}\n    (u,v) & \\mapsto\n    f_{(X,Y)} (\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| {1\\hspace{-3.8pt} 1}_B(u,v)\n\\end{align*}\n\\]\n\nRemarque: le résultat s’étend facilement en dimension supérieure",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#preuve",
    "href": "Slides/slides_loi_normale1D.html#preuve",
    "title": "Loi normale: cas univarié",
    "section": "Preuve",
    "text": "Preuve\nRappel: la loi de \\((U,V)\\) est caractérisée par \\(\\mathbb{E}[h(U,V)]\\) pour tout \\(h\\) mesurable bornée.\n\nSoit un tel \\(h\\) et on applique la formule de transfert : \\[\n\\begin{align*}\n  \\mathbb{E}[h(U,V)] & = \\mathbb{E}[h(\\phi(X,Y))] = \\int_{\\mathbb{R}^2} h(\\phi(x,y)) f_{(X,Y)}(x,y) \\, dx dy \\\\\n& = \\int_{A} h(\\phi(x,y)) f_{(X,Y)}(x,y) \\, d x d y\\enspace.\n\\end{align*}\n\\]\n\n\nOn applique alors la formule du changement de variables \\((u,v) = \\phi(x,y) \\iff \\phi^{-1}(u,v) = (x,y)\\) : \\[\n\\begin{align*}\n   \\mathbb{E}[h(U,V)] &\n  = \\!\\int_{B}  \\!\\!\\! h(u,v) f_{(X,Y)}(\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| \\, d u d v\\\\\n  & = \\!\\int_{\\mathbb{R}^2} \\!\\!\\!\\! h(u,v) f_{(X,Y)}(\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| {1\\hspace{-3.8pt} 1}_B(u,v)\\, d u d v .\n\\end{align*}\n\\] ce qui donne le résultat voulu.",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#méthode-de-box-müller",
    "href": "Slides/slides_loi_normale1D.html#méthode-de-box-müller",
    "title": "Loi normale: cas univarié",
    "section": "Méthode de Box-Müller",
    "text": "Méthode de Box-Müller\nL’algorithme de Box-Müller est le suivant: si \\(U\\) et \\(V\\) sont des v.a. indépendantes de loi uniforme sur \\([0,1]\\) et qu’on définit \\(X\\) et \\(Y\\) par \\[\n\\begin{cases}\n  X = \\sqrt{-2 \\log(U)} \\cos(2\\pi V)\\\\\n  Y = \\sqrt{-2 \\log(U)} \\sin(2\\pi V)\\,.\n\\end{cases}\n\\] alors \\(X\\) et \\(Y\\) des variables aléatoires gaussiennes centrées réduites indépendantes.",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#preuve-de-la-méthode-de-box-müller",
    "href": "Slides/slides_loi_normale1D.html#preuve-de-la-méthode-de-box-müller",
    "title": "Loi normale: cas univarié",
    "section": "Preuve de la méthode de Box-Müller",
    "text": "Preuve de la méthode de Box-Müller\n\\[\n    \\begin{array}{ccccc}\n        \\phi^{-1} & : & ]0, \\infty[ \\times ]0, 2\\pi[ & \\to     & &\\mathbb{R}^2 \\setminus ([0,\\infty[ \\times \\{0\\})  \\\\\n                  &   & ( r , \\theta)                   & \\mapsto && (r \\cos(\\theta) , r \\sin(\\theta))  \\\\\n        \\phi & : & \\mathbb{R}^2 \\setminus ([0,\\infty[ \\times \\{0\\}) & \\to  && ]0, \\infty[ \\times ]0, 2\\pi[                                                       \\\\\n             &   & ( x, y )                                            & \\mapsto && (\\sqrt{x^2+y^2} , 2 \\arctan \\Big( \\frac{y}{x+\\sqrt{x^2+y^2}} \\Big)\n    \\end{array}\n\\]\n\nThéorème 2 (Méthode de Box-Müller) Soit \\(X\\) et \\(Y\\) deux v.a. indépendantes \\(X,Y \\sim \\mathcal{N}(0,1)\\). Le couple de variables aléatoires polaires \\((R, \\Theta) = \\phi(X,Y)\\) a pour densité \\[\n            f_{R, \\Theta}(r,\\theta)\n            = \\Big( r \\cdot e^{-\\tfrac{r^2}{2}} {1\\hspace{-3.8pt} 1}_{]0, \\infty[}(r) \\Big) \\bigg(\\frac{{1\\hspace{-3.8pt} 1}_{]0, 2 \\pi[}(\\theta)}{2 \\pi} \\bigg)\\,.\n\\] \\(R\\) et \\(\\Theta\\) sont indépendantes, \\(\\Theta \\sim \\mathcal{U}(]0, 2\\pi[)\\), \\(R\\) suit une loi de Rayleigh de densité \\[\n    f_R(r) =  r \\cdot e^{-r^2/2} {1\\hspace{-3.8pt} 1}_{]0, \\infty[}(r)\\,, \\quad r &gt; 0\\,.\n\\]",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#preuve-de-la-méthode-de-box-müller-suite",
    "href": "Slides/slides_loi_normale1D.html#preuve-de-la-méthode-de-box-müller-suite",
    "title": "Loi normale: cas univarié",
    "section": "Preuve de la méthode de Box-Müller (suite)",
    "text": "Preuve de la méthode de Box-Müller (suite)\n\nLemme 1 (Simulation selon la loi de Rayleigh) Si \\(U\\) est une variable aléatoire de loi uniforme sur \\(]0,1[\\), alors \\(\\sqrt{-2 \\log(U)}\\) suit une loi de Rayleigh.\n\n\nPreuve: Pour tout \\(x &gt; 0\\), \\(F_R(x)=\\mathbb{P}(R\\leq x) = 1-\\exp(-\\tfrac{x^2}{2})\\), et donc pour tout \\(q \\in ]0,1[, F_R^{^\\leftarrow}(q)=\\sqrt{-2\\log(1-q)}\\). Ainsi par la méthode de l’inverse, \\(\\sqrt{-2\\log(1-U)}\\) suit est une v.a. distribuée selon la loi de Rayleigh, et donc aussi \\(\\sqrt{-2\\log(U)}\\).\n\n\nEnfin, on prouve le bien fondé de la méthode de Box-Müller en utilisant le lemme ci-dessus, et en notant que \\(~U\\sim\\mathcal{U}[0,1] \\implies 2 \\pi U\\sim\\mathcal{U}[0,2\\pi]\\)",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#alternatives",
    "href": "Slides/slides_loi_normale1D.html#alternatives",
    "title": "Loi normale: cas univarié",
    "section": "Alternatives",
    "text": "Alternatives\n\nl’algorithme de Box-Müller n’est pas utilisé si souvent en pratique (evaluation de fonctions coûteuses: logarithme, cosinus, sinus).\nPour s’affranchir des fonctions trigonométriques, une version modifiée de l’algorithme de Box-Müller a été proposée : la méthode de Marsaglia, qui s’appuie sur des variables aléatoires uniformes sur le disque unité (voir l’exercice dédié en TD).\nUne autre alternative est la méthode de Ziggurat implémentée dans la librairie numpy, notamment.",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#loi-du-chi2",
    "href": "Slides/slides_loi_normale1D.html#loi-du-chi2",
    "title": "Loi normale: cas univarié",
    "section": "Loi du \\(\\chi^2\\)",
    "text": "Loi du \\(\\chi^2\\)\nConcernant la prononciation, on prononce “khi-deux” le nom de cette loi.\n\nDéfinition 1 (Loi du \\(\\chi^2\\)) Soit \\(X_1, \\dots, X_k\\) des variables aléatoires i.I.d. de loi normale centrée réduite. La loi de la variable aléatoire \\(X = X_1^2 + \\dots + X_k^2\\) est appelée loi du \\(\\chi^2\\) à \\(k\\) degrés de liberté. Sa densité est donnée par \\[\nf(x) = \\frac{1}{2^{\\frac{k}{2}}\\Gamma(\\frac{k}{2})} x^{\\frac{k}{2}-1} e^{-x/2}\\,, \\quad x \\geq 0\\,,\n\\] où \\(\\Gamma\\) désigne la fonction gamma d’Euler : \\[\n\\Gamma(x) = \\int_0^{\\infty} t^{x-1} e^{-t}\\,  dt\\,.\n\\] On note alors \\(X \\sim \\chi^2(k)\\).",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#loi-de-student",
    "href": "Slides/slides_loi_normale1D.html#loi-de-student",
    "title": "Loi normale: cas univarié",
    "section": "Loi de Student",
    "text": "Loi de Student\n\n\n\nDéfinition 2 (Loi de Student) Soit \\(X \\sim \\mathcal{N}(0,1)\\) et \\(Y \\sim \\chi^2(k)\\) deux variables aléatoires indépendantes. La loi de la variable aléatoire \\(V = \\frac{X}{\\sqrt{Y/k}}\\) est appelée loi de Student à \\(k\\) degrés de liberté. Elle admet pour densité \\[\n    f_V(t)\n    = \\dfrac{1}{\\sqrt{k \\pi}} \\dfrac{\\Gamma(\\frac{k+1}{2})}{\\Gamma(\\frac{k}{2})} \\Big(1+\\dfrac{t^2}{k}\\Big)^{-\\frac{k+1}{2}}\\,,\n    \\quad t \\in \\mathbb{R}\\,.\n\\]\n\n\nApplication: elle est utilisée en statistiques pour déterminer l’intervalle de confiance de l’espérance d’une loi normale, quand la variance est inconnue (en lien avec le théorème de Cochran)\n\n\n\nCette loi a été décrite en 1908 par William Gosset: (1876-1937) statisticien et chimiste anglais. Il était employé à la brasserie Guinness à Dublin. Son employeur lui refusant le droit de publier sous son propre nom, W. Gosset choisit un pseudonyme, Student (🇫🇷: étudiant).",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#loi-de-cauchy",
    "href": "Slides/slides_loi_normale1D.html#loi-de-cauchy",
    "title": "Loi normale: cas univarié",
    "section": "Loi de Cauchy",
    "text": "Loi de Cauchy\n\n\n\nDéfinition 3 (Loi de Cauchy standard) Une v.a. \\(X\\) suit une loi de Cauchy standard si sa densité est donnée par \\[\n    f_X(x) = \\dfrac{1}{\\pi(1+x^2)}\\,, \\quad x \\in \\mathbb{R}\\,.\n\\] On note alors \\(X\\sim \\mathcal{C}(0,1)\\) dans ce cas.\n\n\nApplication: Loi souvent utile comme contre-exemple, n’ayant ni espérance (ni variance a fortiori), et ne satisfaisant pas la loi des grands nombres ou le TCL.\n\n\n\n\nLoi étudiée en particulier par Augustin-Louis Cauchy: (1789-1857) mathématicien et physicien français, connu pour ses travaux fondateurs en analyse complexe et dans l’étude du groupe des permutations. \ncf. (Stigler 1974) pour plus de détails historiques sur cette loi",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#loi-de-cauchy-fonctions-caractéristiques",
    "href": "Slides/slides_loi_normale1D.html#loi-de-cauchy-fonctions-caractéristiques",
    "title": "Loi normale: cas univarié",
    "section": "Loi de Cauchy: fonctions caractéristiques",
    "text": "Loi de Cauchy: fonctions caractéristiques\n\nDéfinition 4 (Loi de Cauchy) On dit que \\(Y\\) suit une loi de Cauchy de paramètres \\((\\mu,\\sigma)\\in \\mathbb{R} \\times ]0,+\\infty[\\) si \\(Y=\\mu + \\sigma X\\), où \\(X\\) suit une loi de Cauchy standard. On note alors \\(X\\sim \\mathcal{C}(0,1)\\) dans ce cas, et la densité de \\(Y\\) est donnée par \\[\n    f_Y(y) = \\dfrac{1}{\\sigma \\pi(1 + \\tfrac{1}{\\sigma^2}\\left(y-\\mu\\right)^2)}\\,, \\quad y \\in \\mathbb{R}\\,.\n\\]\n\n\nProposition 2 (Loi de Cauchy et fonction caractéristique) La fonction caractéristique de la loi de Cauchy standard est donnée par \\[\n\\begin{align*}\n\\varphi_X(t) & \\triangleq \\int_{\\mathbb{R}} e^{itx} f_X(x) \\, dx = e^{-|t|}\\,.\n\\end{align*}\n\\] et donc si \\(Y\\sim \\mathcal{C}(\\mu,\\sigma)\\), alors pour tout \\(t \\in \\mathbb{R}\\), \\(\\varphi_Y(t) = e^{i\\mu t - \\sigma |t|}\\).\n\nPour la preuve voir par exemple (Exemple III.5.5., Barbe et Ledoux 2006)",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#loi-de-cauchy-stabilité-par-somme",
    "href": "Slides/slides_loi_normale1D.html#loi-de-cauchy-stabilité-par-somme",
    "title": "Loi normale: cas univarié",
    "section": "Loi de Cauchy : stabilité par somme",
    "text": "Loi de Cauchy : stabilité par somme\nImplications:\n\nla somme de deux variables aléatoires indépendantes de loi de Cauchy est de Cauchy: Si \\(X_1 \\sim \\mathcal{C}(\\mu_1,\\sigma_2)\\) et \\(X_2 \\sim \\mathcal{C}(\\mu_2,\\sigma_2)\\) sont indépendantes, alors \\(X_1+X_2 \\sim \\mathcal{C}(\\mu_1+\\mu_2,\\sigma_1+\\sigma_2)\\) (preuve: même fonction caractéristique).\n\n\n\nla moyenne de variables de Cauchy standard i.i.d suit la loi de Cauchy standard: si \\(X_1, \\ldots, X_n\\) sont i.i.d de loi de Cauchy standard alors \\(\\bar{X}_n \\sim \\mathcal{C}(0,1)\\) (preuve: pour tout \\(t \\in \\mathbb{R}\\), \\(\\varphi_{\\bar{X}_n}(t) = e^{-|t|}\\))\n\nConclusion: la moyenne empirique de v.a. \\(\\mathcal{C}(0,1)\\) i.i.d ne converge pas en probabilité vers une constante!",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#loi-de-cauchy-propriété",
    "href": "Slides/slides_loi_normale1D.html#loi-de-cauchy-propriété",
    "title": "Loi normale: cas univarié",
    "section": "Loi de Cauchy: propriété",
    "text": "Loi de Cauchy: propriété\n\nProposition 3 (Loi de Cauchy et loi normale) Soient \\(X\\) et \\(Y\\) deux variables aléatoires indépendantes de loi normale centrée réduite. Alors, \\(Y/X\\) suit une loi de Cauchy standard.\n\nRemarque: la méthode d’inversion permet aussi de simuler une variable aléatoire de loi de Cauchy (cf. TD/TP).\n\n\nConséquence: \\(X\\sim \\mathcal{C}(0,1) \\implies 1/X \\sim \\mathcal{C}(0,1)\\)",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#preuve-rapport-de-variables-gaussiennes",
    "href": "Slides/slides_loi_normale1D.html#preuve-rapport-de-variables-gaussiennes",
    "title": "Loi normale: cas univarié",
    "section": "Preuve (rapport de variables gaussiennes):",
    "text": "Preuve (rapport de variables gaussiennes):\nPreuve: Comme pour la loi de Student, on démontre ce résultat avec un changement de variables. On considère l’application \\[\n    \\begin{array}{ccccc}\n        \\phi & : & \\mathbb{R}^* \\times \\mathbb{R} & \\to     & \\mathbb{R}^* \\times \\mathbb{R} \\\\\n                &   & (x,y) & \\mapsto & \\Big(x, \\dfrac{y}{x}\\Big)\\\\\n        \\phi^{-1} & :  & \\mathbb{R}^* \\times \\mathbb{R} & \\to     & \\mathbb{R}^* \\times \\mathbb{R}\\\\\n                &   & (u, v) & \\mapsto & \\Big(u, uv)\n\\end{array}\n\\]\n\\[\n    J_{\\phi^{-1}} (u,v)\n    =\n    \\begin{pmatrix}\n        1 & 0 \\\\\n        v & u\n    \\end{pmatrix}\\,,\n\\] et son déterminant vaut \\(u\\). Le reste est calculatoire et laissé en exercice.",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale1D.html#bibliographie",
    "href": "Slides/slides_loi_normale1D.html#bibliographie",
    "title": "Loi normale: cas univarié",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\nBarbe, Philippe, et Michel Ledoux. 2006. Probabilités.\n\n\nStigler, Stephen M. 1974. « Studies in the History of Probability and Statistics. XXXIII Cauchy and the witch of Agnesi: An historical note on the Cauchy distribution ». Biometrika, 375‑80.\n\n\n\n\n\nLoi normale: cas univarié",
    "crumbs": [
      "Slides",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#section",
    "href": "Slides/slides_intro.html#section",
    "title": "Introduction",
    "section": "",
    "text": "PS: n’oubliez pas de mettre [HAX603X] dans le titre de vos mails!",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#enseignants",
    "href": "Slides/slides_intro.html#enseignants",
    "title": "Introduction",
    "section": "Enseignants",
    "text": "Enseignants\n\n\nJoseph Salmon : CM et TP\n\nSituation actuelle : Professeur à l’Université de Montpellier\nPrécédemment : Paris Diderot-Paris 7, Duke Univ., Télécom ParisTech, Univ. Washington\nSpécialités : statistiques, optimisation, traitement des images, sciences participatives\nBureau : 415, Bat. 9\n\n\n\n\n\n\n\n\nBenjamin Charlier : CM, TD et TP\n\nSituation actuelle : Maître de conférences à l’Université de Montpellier\nPrécédemment : Université Paul Sabatier, ENS Paris-Saclay\nSpécialités : traitement des images, statistiques, différentiation automatique\nBureau : 423, Bat. 9",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#ressources-en-ligne",
    "href": "Slides/slides_intro.html#ressources-en-ligne",
    "title": "Introduction",
    "section": "Ressources en ligne",
    "text": "Ressources en ligne\n\nInformations principales : site du cours http://josephsalmon.github.io/HAX603X\n\n\n\nSyllabus\nCours (détaillé: site web)\nSlides (résumé)\nFeuilles de TD\nFeuilles de TP\nRendu TP : Moodle de l’université (https://moodle.umontpellier.fr/course/view.php?id=5558)",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#validation",
    "href": "Slides/slides_intro.html#validation",
    "title": "Introduction",
    "section": "Validation",
    "text": "Validation\n\nTP notés : Rendu = fichier Python .py unique\n\nTP noté 1 : rendre en fin de session (en S11)\nTP noté 2 : rendre en fin de session (en S17)\n\nCC : devoir sur table d’une heure (S18)\n\n\n\nCoefficients:\n\nNote Session 1 : (40% CC + 30% TP 1 + 30% TP 2)\nNote Session 2 : (30% CC + 35% TP 1 + 35% TP 2)\n\n\n\n\n\n\n\n\nImportant\n\n\nLe rendu est individuel pour le TP noté !!!",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#notation-pour-les-tps",
    "href": "Slides/slides_intro.html#notation-pour-les-tps",
    "title": "Introduction",
    "section": "Notation pour les TPs",
    "text": "Notation pour les TPs\nRendu : sur Moodle, en déposant un fichier nom_prenom.py dans le dossier adéquat.\nDétails de la notation des TPs :\n\nQualité des réponses aux questions\nQualité de rédaction et d’orthographe\nQualité des graphiques (légendes, couleurs)\nQualité du code (noms de variables, clairs, commentaires utiles, code synthétique, etc.)\nCode reproductible et absence de bug\n\n\n\n\n\n\n\n\nPénalités\n\n\n\nEnvoi par mail : zéro\nRetard : zéro (uploader avant la fin, fermeture automatique de moodle)",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#prérequis---à-revoir-seul",
    "href": "Slides/slides_intro.html#prérequis---à-revoir-seul",
    "title": "Introduction",
    "section": "Prérequis - à revoir seul",
    "text": "Prérequis - à revoir seul\n\n \n\nBases de probabilités (en particulier “HAX506X- Théorie des Probabilités”): probabilité, densité, espérance, fonction de répartition, mesure, intégration, analyse numérique élémentaire, etc. (Foata et Fuchs 1996; Barbe et Ledoux 2006; Ouvrard 2007, 2008)\n\n\n\nProgrammation élémentaire (en Python): if … then… else …, for, while, fonctions, etc. HLMA310 - Logiciels scientifiques, (Courant et al. 2013), Cours de Python: Univ. Paris Diderot\n\n\n\nPour aller plus loin: conditionnement, martingales (Williams 1991)",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#description-du-cours",
    "href": "Slides/slides_intro.html#description-du-cours",
    "title": "Introduction",
    "section": "Description du cours",
    "text": "Description du cours\n\n\nGénérer l’aléa\n\ngénérateurs pseudo-aléatoires, simulations de variables aléatoires (inverse, rejet, etc.)\nillustrations numériques et visualisation en Python (loi des grands nombres, TCL)\n\nMéthode de Monte-Carlo\n\nméthode de Monte-Carlo pour le calcul approché d’une intégrale\nréduction de la variance : variables antithétiques, variables de contrôle, etc.\n\nCompléments\n\nvecteurs gaussiens et lien avec les lois usuelles de la statistique inférentielle (student, chi2)\nconstruction d’intervalles de confiance.\nmarche aléatoire simple, etc.",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#buffon-et-les-prémisses-de-la-méthode-de-monte-carlo",
    "href": "Slides/slides_intro.html#buffon-et-les-prémisses-de-la-méthode-de-monte-carlo",
    "title": "Introduction",
    "section": "Buffon et les prémisses de la méthode de Monte-Carlo",
    "text": "Buffon et les prémisses de la méthode de Monte-Carlo\n\n\n\n\n1733: l’aiguille de Buffon, méthode d’estimation de la valeur de \\(\\pi\\).\n\n\n\n\nProblème initial: une aiguille de taille 1 tombe sur un parquet composé de lattes de largeur \\(1\\): quelle est alors la probabilité \\(P\\) que l’aiguille croise une ligne de la trame du parquet ?\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\nGeorges-Louis Leclerc, Comte de Buffon(1707-1788) : naturaliste, mathématicien et industriel français du siècle des Lumières",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#laiguille-de-buffon-suite",
    "href": "Slides/slides_intro.html#laiguille-de-buffon-suite",
    "title": "Introduction",
    "section": "L’aiguille de Buffon (suite)",
    "text": "L’aiguille de Buffon (suite)\n\nProblème initial: une aiguille de taille 1 tombe sur un parquet composé de lattes de largeur \\(1\\): quelle est alors la probabilité \\(P\\) que l’aiguille croise une ligne de la trame du parquet ?\n\n\n\nRéponse: \\[\nP = \\frac{2}{\\pi} \\approx 0.6366 \\enspace.\n\\] Une preuve de ce résultat est donnée ici.",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#principe-de-monte-carlo-et-estimation",
    "href": "Slides/slides_intro.html#principe-de-monte-carlo-et-estimation",
    "title": "Introduction",
    "section": "Principe de Monte Carlo et estimation",
    "text": "Principe de Monte Carlo et estimation\nIdée sous-jacente de Buffon :\nsi l’on répète cette expérience un grand nombre de fois, on peut approché la quantité \\(P\\) numériquement, par exemple en proposant un estimateur \\(\\hat{P}_n\\) qui compte la proportion de chevauchement après avoir fait \\(n\\) répétition des lancers.\n Estimation de \\(\\pi\\):\n\\[\n\\pi \\approx \\frac{2}{\\hat{P}_n}\n\\]",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#principe-de-monte-carlo-pour-lestimation-suite",
    "href": "Slides/slides_intro.html#principe-de-monte-carlo-pour-lestimation-suite",
    "title": "Introduction",
    "section": "Principe de Monte Carlo pour l’estimation (suite)",
    "text": "Principe de Monte Carlo pour l’estimation (suite)",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#méthode-de-monte-carlo",
    "href": "Slides/slides_intro.html#méthode-de-monte-carlo",
    "title": "Introduction",
    "section": "Méthode de Monte-Carlo",
    "text": "Méthode de Monte-Carlo\nMéthode de calcul numérique qui consiste à utiliser des nombres aléatoires pour résoudre des problèmes déterministes.\n\nDomaines d’applications:\n\nla physique\nla chimie\nla biologie\nla finance\nl’apprentissage automatique",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#contexte-de-la-naissance-de-la-méthode-de-monte-carlo",
    "href": "Slides/slides_intro.html#contexte-de-la-naissance-de-la-méthode-de-monte-carlo",
    "title": "Introduction",
    "section": "Contexte de la naissance de la méthode de Monte Carlo",
    "text": "Contexte de la naissance de la méthode de Monte Carlo\n\n\n\n\nLieu: Los Alamos\nÉpoque: seconde guerre mondial\nContexte: Projet Manathan, produire une bombe atomique\nBesoins: modéliser les réactions nucléaires en chaîne (combinatoires)\n\n\n\n\n\n\n\n\nJohn von Neumann (1903-1957), mathématicien et physicien américano-hongrois, un des pères de l’informatique.\n\n\n\n\n\n\n\nNicholas Metropolis (1915-1999), physicien gréco-américain, un des initiateurs de la méthode de Monte Carlo et du recuit simulé\n\n\n\n\n\n\n\nStanisław Ulam (1909-1984), mathématicien polono-américainm, un des initiateurs de la méthode de Monte Carlo et de la propulsion nucléaire pulsée\n\n\n\n\n\n\n\n\n\n\nExplosion de Trinity (16 Juillet 1945)",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#lorigine-du-nom-monte-carlo",
    "href": "Slides/slides_intro.html#lorigine-du-nom-monte-carlo",
    "title": "Introduction",
    "section": "L’origine du nom “Monte-Carlo”",
    "text": "L’origine du nom “Monte-Carlo”\nInitialement: besoin de confidentialité du projet Manhattan\n\nMonte-Carlo: connue pour ses jeux de hasard, où l’oncle de Stanisław Ulam aimait se rendre pour assouvir sa soif de jeu.\n Ce serait N. Metropolis qui aurait proposé ce nom, cf. (Metropolis 1987):\nIt was at that time that I suggested an obvious name for the statistical method—a suggestion not unrelated to the fact that Stan had an uncle who would borrow money from relatives because he “just had to go to Monte Carlo”.",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#essor-de-la-méthode-de-monte-carlo",
    "href": "Slides/slides_intro.html#essor-de-la-méthode-de-monte-carlo",
    "title": "Introduction",
    "section": "Essor de la méthode de Monte Carlo",
    "text": "Essor de la méthode de Monte Carlo\n\n\n\n\nPopularisation croissante:\n\nEssor de l’informatique (depuis les années 80)\nEssor des méthodes de calcul parallèle (GPUs, clusters, etc.)\n\n\n\n\n\nDomaine principaux impactés:\n\nfinance : évaluation des prix de produits dérivés\napprentissage automatique: utilisation de l’aléatoire pour généré des scénarios\nExemples: Alphago (2016), AlphaGeometry (2024)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecherche arborescente Monte-Carlo (🇬🇧: Monte Carlo tree search): analyse des scénarios les plus prometteurs, en élargissant l’arbre de recherche sur la base d’un échantillonnage aléatoire de l’espace entier (ingrédient important d’AlphaGo)",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Slides/slides_intro.html#bibliographie",
    "href": "Slides/slides_intro.html#bibliographie",
    "title": "Introduction",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\nBarbe, Philippe, et Michel Ledoux. 2006. Probabilités.\n\n\nCourant, J., M. de Falco, S. Gonnord, J.-C. Filliâtre, S. Conchon, G. Dowek, et B. Wack. 2013. Informatique pour tous en classes préparatoires aux grandes écoles: Manuel d’algorithmique et programmation structurée avec Python. Eyrolles.\n\n\nFoata, D., et A. Fuchs. 1996. Calcul des probabilités: cours et exercices corrigés. Masson.\n\n\nMetropolis, Nicholas. 1987. « The beginning of the Monte Carlo method ». Los Alamos Science, nᵒ 15: 125‑30.\n\n\nOuvrard, J.-Y. 2007. Probabilités : Tome 2, Licence - CAPES. 2ᵉ éd. Enseignement des mathématiques. Cassini.\n\n\n———. 2008. Probabilités : Tome 1, Licence - CAPES. 2ᵉ éd. Enseignement des mathématiques. Cassini.\n\n\nWilliams, D. 1991. Probability with martingales. Cambridge Mathematical Textbooks. Cambridge: Cambridge University Press.\n\n\n\n\n\nIntroduction",
    "crumbs": [
      "Slides",
      "Introduction"
    ]
  },
  {
    "objectID": "Courses/slides.html",
    "href": "Courses/slides.html",
    "title": "Slides: menu principal",
    "section": "",
    "text": "Vous trouverez ci-dessous la listes des slides associés:\nCours introduction, plein écran\n\nCours: notations premiers pas, plein écran\n\nCours: théorème asymptotiques, plein écran\n\nCours: simulation, méthodes classiques\n\n\n\n\n Retour au sommet",
    "crumbs": [
      "Slides",
      "Slides: menu principal"
    ]
  },
  {
    "objectID": "Courses/perspective_historique.html",
    "href": "Courses/perspective_historique.html",
    "title": "Perspectives historiques",
    "section": "",
    "text": "Nous allons présenter ici quelques éléments historiques sur les méthodes de Monte-Carlo, dont les prémisses remontent au XVIIIème siècle.",
    "crumbs": [
      "Cours",
      "Perspectives historiques"
    ]
  },
  {
    "objectID": "Courses/perspective_historique.html#laiguille-de-buffon",
    "href": "Courses/perspective_historique.html#laiguille-de-buffon",
    "title": "Perspectives historiques",
    "section": "L’aiguille de Buffon",
    "text": "L’aiguille de Buffon\nGeorges-Louis Leclerc, Comte de Buffon1 proposa en 1733 une méthode qui s’avéra être utile pour estimer la valeur de \\pi. On désigne de nos jours cette expérience sous le nom de l’aiguille de Buffon. C’est l’une des premières méthodes de Monte-Carlo référencée dans la littérature (la source du texte est disponible ici sur le site de la BNF).\n1 Georges-Louis Leclerc, Comte de Buffon: (1707-1788) naturaliste, mathématicien et industriel français du siècle des Lumières La question initiale (simplifiée ici) posée par Buffon était la suivante: une aiguille de taille 1 tombe sur un parquet composé de lattes de largeur 1: quelle est alors la probabilité P que l’aiguille croise une ligne de la trame du parquet ?\nLe contexte original était dans celui d’un jeu à deux joueurs: un joueur parie sur le fait que l’aiguille croise une ligne de la trame du parquet, l’autre sur le fait que l’aiguille ne croise pas une ligne de la trame du parquet. L’enjeu est alors de calculer la probabilité de succès de chacun des joueurs, et de voir si le jeu est équilibré ou non.\nVoilà brièvement la question que s’est posée Buffon en 1733. La réponse est donnée par la formule suivante, qui montre que le jeu qu’il propose n’est pas équilibré:\n\nP = \\frac{2}{\\pi} \\approx 0.6366 \\enspace.\n Une preuve de ce résultat sera donnée ci-dessous.\nL’idée sous-jacente de Buffon est que si l’on répète cette expérience un grand nombre de fois, on peut approché la quantité P numériquement, par exemple en proposant un estimateur \\hat{P}_n qui compte la proportion de chevauchement après avoir fait n répétition des lancers. Pour estimer \\pi, il ne restera donc plus qu’à évaluer \\frac{2}{\\hat{P}_n}.\nOn peut faire cette expérience dans le monde réelle (c’est un peu long pour n grand!), mais on peut aussi utiliser une méthode numérique pour cela. Il s’agit alors de tirer aléatoire la position du centre de l’aiguille, puis de tirer aussi de manière aléatoire son angle de chute. On teste à la fin si l’aiguille croise une ligne de la trame du parquet ou non, et on recommence l’expérience un grand nombre de fois.\nCette méthode est donnée ci-dessous, avec un exemple interactif généré en Python.\n\nCode\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nrng = np.random.default_rng(44)\n\nn_samples = 200\nxmax = 14.499999\nxmin = -xmax\n\n\n# Create the needles\ncenters_x = rng.uniform(xmin, xmax, n_samples)\nangles = rng.uniform(0, 2 * np.pi, n_samples)\ncenters_y = rng.uniform(-2, 2, n_samples)\n\n# Compute the right borders of the needles\nborders_right = np.zeros((n_samples, 2))\nborders_right[:, 0] = centers_x + np.cos(angles) / 2\nborders_right[:, 1] = centers_y + np.sin(angles) / 2\n\n# Compute the left borders of the needles\nborders_left = np.zeros((n_samples, 2))\nborders_left[:, 0] = centers_x + np.cos(angles + np.pi) / 2\nborders_left[:, 1] = centers_y + np.sin(angles + np.pi) / 2\n\ncenters_x_round = np.round(centers_x)\noverlap = (borders_right[:, 0] - centers_x_round) * (\n    borders_left[:, 0] - centers_x_round\n) &lt; 0\noverlap = np.where(overlap, 1, 0)\nn_overlap = int(np.sum(overlap))\n\n\n# Check if the needles cross a line\nborders_red = np.empty((3 * n_overlap, 2), dtype=object)\nborders_red.fill(None)\nborders_red[::3, :] = borders_right[overlap == 1]\nborders_red[1::3, :] = borders_left[overlap == 1]\n\nborders_blue = np.empty((3 * (n_samples - n_overlap), 2), dtype=object)\nborders_blue.fill(None)\nborders_blue[::3, :] = borders_right[overlap == 0]\nborders_blue[1::3, :] = borders_left[overlap == 0]\n\noverlaps = np.empty((3 * n_samples), dtype=object)\noverlaps.fill(None)\noverlaps[::3] = overlap\noverlaps[1::3] = overlap\noverlaps[2::3] = overlap\n\nidx_red = np.cumsum(overlaps)\nidx_blue = np.cumsum(1 - overlaps)\n\n\n# Create subplots with 2 rows and 1 column with ratio x /  y  of 10\nfig = make_subplots(rows=2, cols=1, vertical_spacing=0.1, row_heights=[2, 1])\n\n# Use a loop to plot vertical lines equation \"y=c\" for integer values c in [-2, -1, 0, 1, 2]\nfor i in range(int(np.round(xmin)), int(np.round(xmax)) + 1):\n    fig.add_shape(\n        type=\"line\",\n        y0=-3,\n        x0=i,\n        y1=3,\n        x1=i,\n        line=dict(\n            color=\"black\",\n            width=2,\n        ),\n        row=1,\n        col=1,\n    )\n\ncolor = np.where(overlaps, 1.0, 0.0)\n\nn_samples_array = np.arange(1, n_samples + 1)\npi_estimate = 2 / (np.cumsum(overlap) / n_samples_array)\nt = n_samples\n\nfig.update_layout(\n    template=\"simple_white\",\n    xaxis=dict(range=[xmin, xmax], constrain=\"domain\", showgrid=False),\n    yaxis_scaleanchor=\"x\",\n    xaxis_visible=False,\n    yaxis_visible=False,\n)\n\nfor i in range(3, t):\n    fig.add_trace(\n        go.Scatter(\n            x=borders_red[: idx_red[3 * i] + 1, 0],\n            y=borders_red[: idx_red[3 * i] + 1, 1],\n            mode=\"lines\",\n            line=dict(width=2),\n            marker=dict(color=\"red\"),\n            name=\"Avec intersection\",\n            visible=False,\n        ),\n        row=1,\n        col=1,\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=borders_blue[: idx_blue[3 * i] + 1, 0],\n            y=borders_blue[: idx_blue[3 * i] + 1, 1],\n            mode=\"lines\",\n            line=dict(width=2),\n            marker=dict(color=\"darkblue\"),\n            name=\"Sans intersection\",\n            visible=False,\n        ),\n        row=1,\n        col=1,\n    )\n\n    fig.add_trace(\n        go.Scatter(\n            x=n_samples_array[:i],\n            y=pi_estimate[:i],\n            mode=\"lines\",\n            line=dict(width=1),\n            marker=dict(color=\"red\"),\n            showlegend=False,\n            visible=False,\n        ),\n        row=2,\n        col=1,\n    )\n\nfig.add_annotation(\n    dict(\n        x=1.01,\n        y=0.14,\n        xref=\"paper\",\n        yref=\"paper\",\n        text=\"Estimation de pi\",\n        showarrow=False,\n        font=dict(color=\"red\"),\n    )\n)\n\nfig.add_annotation(\n    dict(x=-0.04, y=0.19, xref=\"paper\", yref=\"paper\", text=\"pi\", showarrow=False)\n)\n\nfig.update_xaxes(title_text=\"Nombre d'aiguilles tirées\", row=2, col=1)\n\nfig.update_layout(\n    template=\"none\",\n    xaxis2=dict(showgrid=True, zeroline=True, zerolinewidth=1, range=[0, n_samples]),\n    yaxis2=dict(showgrid=True, zeroline=True, zerolinewidth=1, range=[0, 6]),\n)\n# plot a dash line at y=pi\nfig.add_shape(\n    type=\"line\",\n    y0=np.pi,\n    x0=0,\n    y1=np.pi,\n    x1=n_samples,\n    line=dict(\n        color=\"black\",\n        width=1,\n        dash=\"dashdot\",\n    ),\n    row=2,\n    col=1,\n)\n\n\nfig.data[10 * 3].visible = True\nfig.data[10 * 3 + 1].visible = True\nfig.data[10 * 3 + 2].visible = True\n\n\nsteps = []\nfor i in range(len(fig.data) // 3):\n    step = dict(\n        label=str(i + 4),\n        method=\"update\",\n        args=[\n            {\"visible\": [False] * len(fig.data)},\n            {\n                \"title\": \"Estimation avec \"\n                + str(i + 4)\n                + f\" aiguilles: pi = {pi_estimate[i]:.4f}\"\n            },\n        ],\n    )\n    step[\"args\"][0][\"visible\"][3 * i] = True\n    step[\"args\"][0][\"visible\"][3 * i + 1] = True\n    step[\"args\"][0][\"visible\"][3 * i + 2] = True\n\n    steps.append(step)\n\nslider = dict(\n    active=0,\n    currentvalue={\"prefix\": \"Nombre d'aiguilles: \"},\n    pad={\"t\": 50},\n    y=-0.32,\n    steps=steps,\n)\n\nfig.update_layout(legend=dict(x=0.5, y=0.31, xanchor='center', yanchor='bottom'))\nfig.update_layout(sliders=[slider])\nfig.show()\n\n\n\n\n                                                \n\n\n\nOn va fournir ici le calcul de la probabilité P. Pour cela on aura besoin de quelques éléments décrits dans le dessin ci-dessous.\n\nx : distance entre le centre de l’aiguille et la ligne de la trame du parquet la plus proche\n\\theta : angle entre l’aiguille et la ligne de la trame du parquet la plus proche\n1 : longueur de l’aiguille (et donc la demi longueur est \\frac{1}{2})\n\\frac{1}{2}\\sin(\\theta) : distance entre l’extrémité de l’aiguille et la ligne de la trame du parquet la plus proche\n\n\n\n\n\n\n\n\n\nSans croisement\n\n\n\n\n\n\n\nAvec croisement\n\n\n\n\n\n\nFigure 1: Configuration sans croisement (à gauche) et avec croisement (à droite) de l’aiguille avec une ligne de la trame du parquet.\n\n\n\nAvec les éléments ci-dessus, on voit qu’il y a chevauchement si et seulement si: \\frac{1}{2}\\sin(\\theta) \\geq x.\nMaintenant par des arguments de symétrie on voit qu’on peut se restreindre à \\theta \\in [0, \\frac{\\pi}{2}], et à x \\in [0, \\frac{1}{2}]. Les lois de générations des variables aléatoires X et \\Theta sont les suivantes:\n\nX \\sim \\mathcal{U}([0, \\frac{1}{2}]), de densité f_X(x) = 2 {1\\hspace{-3.8pt} 1}_{[0, \\frac{1}{2}]}(x)\n\\Theta \\sim \\mathcal{U}([0, \\frac{\\pi}{2}]) de densité f_\\Theta(\\theta) = \\frac{2}{\\pi} {1\\hspace{-3.8pt} 1}_{[0, \\frac{\\pi}{2}]}(\\theta)\n\nDe plus on suppose que X et \\Theta sont indépendantes.\nMaintenant pour calculer la probabilité P on procède comme suit: \n\\begin{align*}\nP\n& = \\mathbb{P}\\left(\\frac{1}{2}\\sin(\\Theta) \\geq X\\right) \\\\\n& = \\int_{\\mathbb{R}^2} {1\\hspace{-3.8pt} 1}_{\\{\\frac{1}{2}\\sin(\\theta) \\geq x\\}} f_{\\Theta}(\\theta) f_X(x) d\\theta dx  \\quad (\\text{par indépendance})\\\\\n& = \\int_{\\mathbb{R}} \\int_{\\mathbb{R}}\n{1\\hspace{-3.8pt} 1}_{\\{\\frac{1}{2}\\sin(\\theta) \\geq x\\}} \\frac{2}{\\pi} {1\\hspace{-3.8pt} 1}_{[0, \\frac{\\pi}{2}]}(\\theta) \\cdot 2 {1\\hspace{-3.8pt} 1}_{[0, \\frac{1}{2}]}(x) d\\theta dx \\\\\n& = \\int_{0}^{\\frac{\\pi}{2}} \\int_{0}^{\\frac{1}{2}\\sin(\\theta)} \\frac{4}{\\pi} dx  d\\theta \\\\\n& = \\frac{4}{\\pi} \\int_{0}^{\\frac{\\pi}{2}} {\\frac{1}{2}\\sin(\\theta)}  d\\theta\\\\  \n& = \\frac{2}{\\pi} \\Big[ -\\cos(\\theta)\\Big]_{0}^{\\frac{\\pi}{2}} \\\\\n& = \\frac{2}{\\pi} \\enspace.\n\\end{align*}\n\n\n\n\n\n\n\nExercice: rendre le jeu équilibré?\n\n\n\nEn reprenant le même type de raisonnement que ci-dessus, trouver la distance entre les lattes du parquet qui rend le jeu équilibrer entre les deux joueurs introduit par Buffon (l’un pariant sur le fait que l’aiguille croise une ligne de la trame du parquet, l’autre pariant sur le fait que l’aiguille ne croise pas une ligne de la trame du parquet).",
    "crumbs": [
      "Cours",
      "Perspectives historiques"
    ]
  },
  {
    "objectID": "Courses/perspective_historique.html#méthode-de-monte-carlo",
    "href": "Courses/perspective_historique.html#méthode-de-monte-carlo",
    "title": "Perspectives historiques",
    "section": "Méthode de Monte-Carlo",
    "text": "Méthode de Monte-Carlo\nLa méthode de Monte-Carlo, est une méthode de calcul numérique qui consiste à utiliser des nombres aléatoires pour résoudre des problèmes déterministes. Elle est utilisée dans de nombreux domaines, comme la physique, la chimie, la biologie, la finance, ou encore l’apprentissage automatique. Cette méthode basée sur la loi des grands nombres a été mis au point à Los Alamos, dans le cadre du projet Manhattan (dont l’objectif était le développement du nucléaire civil et militaire) par un groupe de scientifiques dont les plus connus sont: John von Neumann2, Nicholas Metropolis3 ou encore Stanisław Ulam4\n2 John von Neumann: (1903-1957) mathématicien et physicien américano-hongrois, un des pères de l’informatique. 3 Nicholas Metropolis: (1915-1999), physicien gréco-américain, est des initiateurs de la méthode de Monte Carlo et du recuit simulé 4 Stanisław Ulam: (1909-1984) Dans le cadre du projet Manhattan, il s’agissait de calculer des intégrales de manière numérique pour modéliser l’évolution de particules, en utilisant des nombres aléatoires.\nEckhardt (1987) donne un bref aperçu historique, et mentionne les premières description de la méthode du rejet et de la méthode de l’inversion dans des lettres entre Von Neumann et Ulam datant de 1947. Ulam aurait une l’idée d’utiliser de telles méthodes pour résoudre le jeu du solitaire lors d’un séjour à l’hôpital en 1946, et éviter ainsi de faire des calculs combinatoires fastidieux. Rapidement, la possibilité d’appliquer cette approche pour des calculs en physique mathématiques (diffusion des neutrons notamment) lui serait apparue prometteuse. Le développement de l’informatique naissante allait permettre une mise en oeuvre pratique de ces idées, et c’est ainsi que la méthode de Monte-Carlo est née. Le nom Monte-Carlo est lui venu du besoin de confidentialité du projet, et provient du nom de la ville de Monte-Carlo, connue pour ses jeux de hasard, où l’oncle de Stanisław Ulam aimait se rendre pour assouvir sa soif de jeu. Ce serait N. Metropolis qui aurait proposé ce nom (cf. Metropolis 1987):\n\nEckhardt, R. 1987. « Stan Ulam, John Von Neumann, and the Monte Carlo Method ». Los Alamos Science, nᵒ 15: 131‑37.\n\nMetropolis, Nicholas. 1987. « The beginning of the Monte Carlo method ». Los Alamos Science, nᵒ 15: 125‑30.\nIt was at that time that I suggested an obvious name for the statistical method—a suggestion not unrelated to the fact that Stan had an uncle who would borrow money from relatives because he “just had to go to Monte Carlo”.",
    "crumbs": [
      "Cours",
      "Perspectives historiques"
    ]
  },
  {
    "objectID": "Courses/perspective_historique.html#autres-méthodes-stochastiques-populaires",
    "href": "Courses/perspective_historique.html#autres-méthodes-stochastiques-populaires",
    "title": "Perspectives historiques",
    "section": "Autres méthodes stochastiques populaires",
    "text": "Autres méthodes stochastiques populaires\n\nMéthode d’Hasting-Metropolis\nL’algorithme de Hasting-Metropolis est une méthode MCMC (🇬🇧: Monte Carlo Markov Chains) dont le but est d’obtenir un échantillonnage aléatoire d’une distribution de probabilité quand l’échantillonnage direct en est difficile (en particulier en grande dimension)\nUn avantage est qu’il ne requiert la connaissance de loi de densité qu’à constante multiplicative près.\n\n\n🇬🇧: Recuit simulé\nLe recuit simulé est une méthode (empirique) d’optimisation, inspirée d’un processus, le recuit, utilisé en métallurgie. On alterne dans cette dernière des cycles de refroidissement lent et de réchauffage (recuit) qui ont pour effet de minimiser l’énergie du matériau. Cette méthode est transposée en optimisation pour trouver les extrema d’une fonction.",
    "crumbs": [
      "Cours",
      "Perspectives historiques"
    ]
  },
  {
    "objectID": "Courses/monte_carlo.html",
    "href": "Courses/monte_carlo.html",
    "title": "Méthode de Monte Carlo",
    "section": "",
    "text": "{{ % variance % covariance }}\nDe manière générale, ce qu’on appelle une méthode de Monte-Carlo est une technique visant à calculer une quantité déterministe par le biais d’un procédé aléatoire. Une application très usuelle des méthodes Monte-Carlo est l’approximation numérique d’intégrales ou d’espérance, c’est ce que nous allons beaucoup développer dans ce chapitre.\nIl existe également de nombreuses méthodes pour l’intégration numérique déterministe (méthodes des rectangles, trapèzes,…). Ces méthodes sont très rapides et efficaces en petite dimension, mais elles ne le sont plus du tout pour des dimensions plus grandes ou pour l’intégration de fonction peu régulières. Ainsi une intégration par Monte Carlo pour le cas de la grande dimension sera bien plus profitable.",
    "crumbs": [
      "Cours",
      "Méthode de Monte Carlo"
    ]
  },
  {
    "objectID": "Courses/monte_carlo.html#principe-de-la-méthode",
    "href": "Courses/monte_carlo.html#principe-de-la-méthode",
    "title": "Méthode de Monte Carlo",
    "section": "Principe de la méthode",
    "text": "Principe de la méthode\n\nL’idée de la Méthode de Monte Carlo est d’exprimer l’intégrale qu’on cherche à approcher comme l’espérance d’une variable aléatoire, puis d’approcher cette espérance par une moyenne empirique. Si on veut calculer une intégrale de la forme \n    I=\\int g(x)f(x)dx,\n on la réécrit comme \n    I=\\mathbb E[g(X)],\n où X est une variable aléatoire de densité f. On suppose évidemment que g(X) est bien intégrable, puis on approche l’espérance par la moyenne empirique \n    I_n=\\frac{g(X_1)+g(X_2)+\\cdots+g(X_n)}{n}.\n Il y a donc deux étapes : traduction sous forme d’espérance puis calcul de la moyenne empirique. Si l’expression à calculer est déjà sous forme d’espérance, il y a juste le calcul de la moyenne empirique à faire. Ce calcul se fait à partir de simulation de la variable aléatoire X sous-jacente.\n\nExemple 1 On peut approcher l’intégrale\n\n    I=\\int_0^1 g(x)dx \\simeq  \\sum_{i=0}^nw_ig(x_i),\n où les w_i sont des nombres entre 0 et 1 dont la somme vaut 1, et les x_i sont des points de l’intervalle [0,1]. Par exemple, pour la méthode des trapèzes, on prend w_0=w_n=\\frac{1}{2n} et w_i=\\frac 1 n sinon et les x_i=\\frac i  n sont régulièrement répartis. Pour une méthode de Monte Carlo, on interprète l’intégrale comme \\mathbb E[g(X)] où X est une variable aléatoire de loi uniforme sur [0,1]. Alors les w_i valent \\frac{1}{n+1} et les x_i sont tirés selon la loi uniforme sur [0,1]. Contrairement aux méthodes déterministes, la valeur de l’approximation change si on relance le calcul puisque les tirages sont aléatoires.\n\nLa méthode de Monte Carlo est très facile à programmer si on dispose d’un simulateur de la loi de X, et n’impose aucune régularité sur g à part de la mesurabilité.",
    "crumbs": [
      "Cours",
      "Méthode de Monte Carlo"
    ]
  },
  {
    "objectID": "Courses/monte_carlo.html#théorèmes-de-convergence",
    "href": "Courses/monte_carlo.html#théorèmes-de-convergence",
    "title": "Méthode de Monte Carlo",
    "section": "Théorèmes de convergence",
    "text": "Théorèmes de convergence\nOn s’intéresse maintenant à la convergence de cet algorithme : sous quelles conditions est-ce que I_n converge vers I, en quel sens, et à la vitesse de cette convergence : combien de tirages faut-il faire pour atteindre une précision souhaitée.\n\nConvergence de la méthode\nCommençons par énoncer des conditions sous lesquelles la méthode converge.\n\nProposition 1 Soit (X_n)_{n\\in\\N} une suite de variables aléatoires indépendantes et de même loi que X, et g une fonction mesurable telle que g(X) est intégrable. Alors la variable aléatoire \n    I_n=\\frac{g(X_1)+g(X_2)+\\cdots+g(X_n)}{n}\n converge presque presque sûrement vers I=\\mathbb E[g(X)] lorsque n tend vers l’infini.\n\n\nPreuve. Comme g(X) est intégrable, et que les variables sont indépendantes et de même loi, il s’agit d’une application directe de la loi forte des grands nombres.\n\nEn particulier, si on sait simuler X, on peut en faire des tirages X_1, , X_n et ainsi calculer I_n qui est une valeur approchée de I pour n assez grand.\n\nExemple 2 Par exemple, si l’on répète un très grand nombre de fois n une expérience aléatoire et que l’on s’intéresse à la réalisation de l’événement A alors la loi des grands nombres nous garantit que : \nf_n(A)=\\frac1n \\times \\hbox{ Nbre de fois où } A \\hbox{ s'est réalisé} \\xrightarrow[n \\to \\infty]{ps}\\mathbb P(A).\n car f_n(A)=(1/n) \\sum_{i=1}^n X_i où X_i est une v.a. de Bernoulli de paramètre p=\\mathbb P(A)=\\mathbb E[X]. Autrement dit, la fréquence observée f_n(A) de la réalisation de l’événement A au cours d’un grand nombre de répétitions de l’expérience se rapproche de la probabilité P(A).\n\n\nExemple 3 (Le jeu des trois portes ou paradoxe de Monty Hall) Un jeu télévisé se déroule face à trois portes identiques. On a placé une voiture derrière l’une des portes, et une chèvre derrière chacune des deux autres. Le candidat est placé devant les trois portes, il en choisit une au hasard et se place devant.\nLa présentatrice (qui sait où se trouve la voiture) ouvre alors l’une des deux autres portes, derrière laquelle il y a une chèvre, puis elle demande au candidat : “Voulez-vous modifier votre choix ?”\nLe candidat a alors deux possibilités :\n\nsoit il ouvre la porte qu’il avait choisie en premier ; (il conserve son premier choix)\nsoit il ouvre une autre porte (celle qui n’a pas été ouverte par la présentatrice).\n\nQuelle est la meilleure stratégie pour le candidat ? Garder son premier choix ou changer de porte ?\nUn raisonnement probabiliste peut fournir la solution. Mais vous pouvez vous aider en faisant des expériences pour faire une conjecture ! On peut par exemple lancer le programme ci-dessous en demandant de reproduire dix mille fois l’expérience (n= 10 000).\n\nimport numpy as np\n\nportes = np.array([\"chevre\", \"chevre\", \"voiture\"])\nNbSimulations = 10000\n\ngagne_avec_change = 0\ngagne_avec_conserve = 0\n\nfor _ in range(NbSimulations):\n    porte_choisie = np.random.choice(portes)\n    if porte_choisie == \"voiture\":\n        gagne_avec_conserve += 1\n    else:\n        gagne_avec_change += 1\n\nprint(f\"Gagne en changeant : {gagne_avec_change / NbSimulations * 100:.3f} %\")\nprint(f\"Gagne sans changer : {gagne_avec_conserve / NbSimulations * 100:.3f} %\")\n\nGagne en changeant : 67.150 %\nGagne sans changer : 32.850 %\n\n\nOn peut alors conjecturer que la probabilité de gagner en changeant de porte est égale à 2/3 alors que si le candidat reste sur son premier choix la probabilité de gagner ne sera que de 1/3.\n\n\n\nPrécision de la méthode\nOn souhaiterait maintenant savoir quand on peut considérer que n est assez grand pour que l’approximation soit satisfaisante.\n\nProposition 2 Si g(X) est de carré intégrable, alors un intervalle de confiance asymptotique de niveau de confiance 1-\\alpha pour l’intégrale I est \n    \\left(I_n-F^{-1}_{\\mathcal{N}(0,1)}\\big(\\frac{\\alpha}{2}\\big)\\sqrt{\\frac{S_n^2}{n}}\\leq I\\leq I_n+F^{-1}_{\\mathcal{N}(0,1)}\\big(\\frac{\\alpha}{2}\\big)\\sqrt{\\frac{S_n^2}{n}}\\right),\n où F^{-1}_{\\mathcal{N}(0,1)} est la fonction quantile de la loi normale centrée réduite et \n    S_n^2=\\frac{1}{n-1}\\sum_{i=1}^n\\big(g(X_i)-I_n\\big)^2\n est l’estimateur sans biais de la variance empirique.\n\n\nPreuve. Comme g(X) est de carré intégrable, et que les X_i sont iid, on peut appliquer le théorème central limite à la suite (g(X_i)), ce qui donne \n    \\frac{\\frac{1}{n}\\sum_{i=1}^n g(X_i)-\\mathbb E[g(X)]}{\\sqrt{\\frac{\\mathop{\\mathrm{Var}}(g(X))}{n}}}\\xrightarrow[n\\to\\infty]{\\mathcal L}\\mathcal N(0,1),\n ce qui se traduit dans notre contexte par \n    \\frac{I_n-I}{\\sqrt{\\frac{\\mathop{\\mathrm{Var}}(g(X))}{n}}}\\xrightarrow[n\\to\\infty]{\\mathcal L}\\mathcal N(0,1).\n En général, on ne connaît pas non plus \\mathop{\\mathrm{Var}}(g(X)), donc on la remplace par un estimateur de la variance S_n^2=\\frac{1}{n-1}\\sum_{i=1}^n(g(X_i)-I_n)^2. D’après la loi des grands nombres, cet estimateur converge ps, donc en probabilité (donc en loi) vers \\mathop{\\mathrm{Var}}(g(X)) qui est une constante. D’après le lemme de Slutsky, le couple (\\frac{I_n-I}{\\sqrt{n\\mathop{\\mathrm{Var}}(g(X))}},S^2_n) converge en loi vers le couple (\\mathcal N(0,1), \\delta_{\\mathop{\\mathrm{Var}}(g(X))}). En particulier, on a encore la convergence en loi du produit \n    \\frac{I_n-I}{\\sqrt{\\frac{S^2_n}{n}}}=\\frac{I_n-I}{\\sqrt{\\frac{\\mathop{\\mathrm{Var}}(g(X))}{n}}}\\times \\frac{\\sqrt{\\mathop{\\mathrm{Var}}(g(X))}}{\\sqrt{S^2_n}}\\xrightarrow[n\\to\\infty]{\\mathcal L}\\mathcal N(0,1) \\times 1.\n On peut en déduire facilement la construction de l’intervalle de confiance asymptotique de l’énoncé.\n\nCe résultat a deux conséquences importantes. D’une part, la vitesse de convergence est en n^{-1/2}, ce qui est relativement lent, mais indépendant à la fois de la dimension de X et de la régularité de g. D’autre part, on peut calculer S_n^2 donc estimer l’erreur commise sans tirages aléatoires supplémentaires, avec le même échantillon qui sert pour estimer I. Il est fortement recommandé de toujours faire une estimation de la précision en même temps que l’estimation Monte Carlo de l’espérance.\n\nExemple 4 En finance, certains contrats permettent de vendre un actif à une date future N fixée par le contrat s’il dépasse à ce moment là une certaine valeur cible K également fixée dans la contrat. Considérons un modèle simplifié pour le cours de l’actif (S_n)_{n\\geq 1} : pour n\\geq 1, on pose S_n=\\sum_{i=1}^nX_i où les X_i sont des variables aléatoires indépendantes de loi normale centrée réduite. Le gain moyen de la détentrice ou du détenteur du contrat décrit ci-dessus est donc \\mathbb E[\\max(S_N-K,0)]. Estimons cette quantité par la méthode de Monte Carlo.\n\nimport numpy as np\n\nn = 100000\nN = 60\nI = []\n\nfor i in range(n):\n    X = np.random.normal(0, 1, N)\n    S = max(np.sum(X) - 1, 0)\n    I.append(S)\n\nI = np.array(I)\nm = np.mean(I)\ns = np.var(I)\n\nprint(f\"[{m - 1.96 * np.sqrt(s / n):.3f}, {m:.3f}, {m + 1.96 * np.sqrt(s / n):.3f}]\")\n\n[2.623, 2.649, 2.675]",
    "crumbs": [
      "Cours",
      "Méthode de Monte Carlo"
    ]
  },
  {
    "objectID": "Courses/monte_carlo.html#réduction-de-variance",
    "href": "Courses/monte_carlo.html#réduction-de-variance",
    "title": "Méthode de Monte Carlo",
    "section": "Réduction de variance",
    "text": "Réduction de variance\nLa proposition Proposition 2 donne deux leviers pour augmenter la précision de l’estimation I_n de I :\n\naugmenter le nombre n de tirages,\ndiminuer la variance \\mathop{\\mathrm{Var}}(g(X)).\n\nSi le premier levier est facilement praticable pour des cas simples, il n’est pas envisageable lorsque une simulation de g(X) est coûteuse en temps de calcul ou lorsque la variance est très grande, ce qui arrive couramment. Nous allons examiner le deuxième levier dans cette partie, c’est ce qu’on appelle les méthodes de réduction de variance.\nRegardons d’abord un exemple pour bien comprendre l’intérêt de ces méthodes.\n\nExemple 5 Revenons sur l’exemple Exemple 2 où on cherche à estimer p=\\mathbb P(A) à partir de tirages de loi de Bernoulli. Avec n tirages, on a I_n\\simeq p + \\sqrt{\\frac{p(1-p)}{n}}Z avec Z de loi normale centrée réduite. La valeur de p est inconnue, mais on peut majorer p(1-p) par 1/4. Si on veut faire une erreur de l’ordre 0.01 sur p, il convient de choisir n=\\frac{1}{4\\times 0.01^2}=0.25\\cdot 10^{4}=2500.\nSi p est proche de 0.5, une erreur de 10^{-2} peut être acceptable. Mais si on cherche à approcher une probabilité très petite, par exemple p=10^{-5}, il faudra une précision d’au moins 10^{-6}, et donc prendre n=0.25\\cdot 10^{12} tirages. On voit bien apparaître les limites de la méthode directe, et l’intérêt de toujours calculer l’ordre de grandeur de l’erreur commise.\n\nIl existe de nombreuses techniques de réduction de variance pour améliorer la vitesse de convergence. Malheureusement, aucune ne marche de façon automatique, il faut les choisir et les adapter au cas par cas. Il s’agit essentiellement d’exploiter d’une façon ou d’une autre l’idée que l’intégrale I peut s’écrire de nombreuses façons différentes comme une espérance, et de choisir l’expression de variance minimale.\n\nVariable de contrôle\nUne première façon très simple de décomposer I est la suivante \n    I=\\mathbb{E}[g(X)]=\\mathbb{E}[g(X)-h(X)]+\\mathbb{E}[h(X)].\n Cette méthode est intéressante si on sait calculer explicitement \\mathbb{E}[h(X)] et si la variance diminue : \\mathop{\\mathrm{Var}}\\big(g(X)-h(X)\\big)&lt;\\mathop{\\mathrm{Var}}\\big(g(X)\\big). Idéalement, on voudrait que la variance de g(X)-h(X) soit très petite. Or rappelons qu’une variable aléatoire est de variance nulle si et seulement si elle est constante. Pour mettre en oeuvre cette méthode, on va donc chercher une fonction h qui soit une bonne approximation de g sur l’intervalle d’intégration pour que la différence g-h soit presque constante.\n\nExemple 6 Supposons que l’on veuille calculer I=\\int_0^1 e^{x^2} dx à l’aide de la loi uniforme sur [0,1]. Comme au voisinage de 0, on a e^{x^2}\\simeq 1+x^2, on propose de prendre h(x)=1+x^2. On a alors \n    \\mathbb E[h(X)]=\\int_0^11+x^2dx=\\big[x+\\frac{x^3}{3}\\big]_0^1=\\frac{4}{3}.\n On peut donc approcher I par \n    I_n^{c}=\\frac{1}{n}\\sum_{i=1}^n\\big(e^{X_i^2}-1-X_i^2\\big)+\\frac{4}{3},\n où les X_i sont iid de loi uniforme sur [0,1]. Regardons ce que ça donne numériquement.\n\nimport numpy as np\n\nn = 10000\nX = np.random.uniform(0, 1, n)\n\n# Direct method\ngX = np.exp(X**2)\nm1 = np.mean(gX)\ns1 = np.var(gX)\n\nprint(f\"Direct method confidence interval: [{m1 - 1.96 * np.sqrt(s1 / n):.3f}, {m1:.3f}, {m1 + 1.96 * np.sqrt(s1 / n):.3f}]\")\nprint(f\"Variance {s1:.3f}\")\n\nDirect method confidence interval: [1.458, 1.467, 1.476]\nVariance 0.228\n\n\n\n# Control variable\nghX = np.exp(X**2) - 1 - X**2\nm2 = np.mean(ghX) + 4/3\ns2 = np.var(ghX)\n\nprint(f\"Control variable confidence interval: [{m2 - 1.96 * np.sqrt(s2 / n):.3f}, {m2:.3f}, {m2 + 1.96 * np.sqrt(s2 / n):.3f}]\")\nprint(f\"Variance {s2:.3f}\")\n\nControl variable confidence interval: [1.461, 1.465, 1.468]\nVariance 0.034\n\n\nOn constate que l’intervalle de confiance est plus étroit donc la précision meilleure avec la variable de contrôle. On a divisé la variance (empirique) par 6.7. Pour obtenir le même gain en augmentant le nombre de simulations, il aurait fallu 6.7^2\\simeq45 fois plus de simulations.\n\n\n\nVariables antithétiques\nS’il existe une fonction h telle que X et h(X) ont la même loi, on peut écrire I comme \nI=\\mathbb{E}\\left[\\frac{g(X)+g(h(X))}{2}\\right].\n On a en fait décomposé l’intégrale I comme somme de deux espérance. Notons que ces deux intégrales font apparaître la même variable aléatoire, donc on peut estimer les deux espérances avec les . En fait on a introduit une certaine forme de dépendance puisqu’on utilise g(X_i) et g(h(X_i)) dans l’estimateur.\nExaminons l’effet de cette décomposition sur la variance.\n\nSupposons qu’il existe une fonction h telle que X et h(X) ont la même loi de carré intégrable. Si \\mathop{\\mathrm{Cov}}(g(X),g(h(X))\\leq 0 alors \n    \\mathop{\\mathrm{Var}}\\left(\\frac{g(X)+g(h(X))}{2}\\right) \\leq \\frac{\\mathop{\\mathrm{Var}}(g(X))}{2},\n\nAutrement dit la méthode des variables antithétiques permet de réduire la variance au moins de moitié si g(X) et g(h(X)) sont négativement corrélées.\n\n\nPreuve. Calculons la variance V=\\mathop{\\mathrm{Var}}\\big(g(X)+g(h(X))\\big): \n\\begin{align*}\n  V &= \\mathop{\\mathrm{Var}}\\big(g(X)+g(h(X))\\big)\\\\\n    &=\\mathbb E[(g(X)-\\mathbb E[g(X)]+g(h(X))-\\mathbb E[g(h(X))])^2]\\\\\n    &= \\mathbb E[(g(X)-\\mathbb E[g(X)])^2]+\\mathbb E[(g(h(X))-\\mathbb E[g(h(X))])^2]\\\\\n    &\\quad + 2\\mathbb E[(g(X)-\\mathbb E[g(X)])(g(h(X))-\\mathbb E[g(h(X))])]\\\\\n    &= \\mathop{\\mathrm{Var}}(g(X))+\\mathop{\\mathrm{Var}}(g(h(X)) + 2 \\mathop{\\mathrm{Cov}}(g(X),g(h(X)).\n\\end{align*}\n\nEn particulier, si \\mathop{\\mathrm{Cov}}(g(X),g(h(X))\\leq 0, on a \n\\begin{align*}\n    \\mathop{\\mathrm{Var}}\\left(\\frac{g(X)+g(h(X))}{2}\\right)\n    & \\leq \\frac{ \\mathop{\\mathrm{Var}}(g(X))+\\mathop{\\mathrm{Var}}(g(h(X))}{4}\\\\\n    & =\\frac{\\mathop{\\mathrm{Var}}(g(X))}{2},\n\\end{align*}\n\ncar g(X) et g(h(X)) ont la même loi donc la même variance. Dans le cas général, on a quand toujours 2\\mathop{\\mathrm{Cov}}(g(X),g(h(X))\\leq \\mathop{\\mathrm{Var}}(g(X))+\\mathop{\\mathrm{Var}}(g(h(X)) par l’inégalité de Cauchy-Schwartz, ce qui implique \n\\begin{align*}\n    \\mathop{\\mathrm{Var}}\\left(\\frac{g(X)+g(h(X))}{2}\\right)\n    & \\leq 2\\frac{\\mathop{\\mathrm{Var}}(g(X))+\\mathop{\\mathrm{Var}}(g(h(X)))}{4}\\\\\n    & = \\mathop{\\mathrm{Var}}(g(X)),\n\\end{align*}\n\ndonc même si on ne réduit pas effectivement la variance, on ne peut pas l’augmenter par cette méthode. On peut faire des calculs plus précis en faisant intervenir la covariance de g(X) et g(h(X)) dans certains cas particuliers si on spécifie les lois.\n\nCette méthode est particulièrement simple à mettre en oeuvre pour les lois qui ont des propriétés de symétrie\n\nExemple 7 Revenons sur l’exemple Exemple 6 où on cherche à approcher I=\\int_0^1 e^{x^2} dx à l’aide de la loi uniforme sur [0,1]. Cette loi a une propriété de symétrie : X et 1-X ont la même loi. On a donc une approximation de I de qualité identique ou meilleure en prenant \n    I_n^{a}=\\frac{1}{2n}\\sum_{i=1}^{n}\\big(e^{X_i^2}+e^{(1-X_i)^2}\\big).\n\nRegardons ce que cela donne numériquement.\n\nimport numpy as np\n\nn = 10000\nX = np.random.uniform(0, 1, n)\n\n# Direct method\ngX = np.exp(X**2)\nm1 = np.mean(gX)\ns1 = np.var(gX)\n\nprint(f\"Direct method confidence interval: [{m1 - 1.96 * np.sqrt(s1 / n):.3f}, {m1:.3f}, {m1 + 1.96 * np.sqrt(s1 / n):.3f}]\")\nprint(f\"Variance {s1:.3f}\")\n\nDirect method confidence interval: [1.464, 1.473, 1.483]\nVariance 0.229\n\n\n\n# Antithetic variable method\ngaX = (np.exp(X**2) + np.exp((1 - X)**2)) / 2\nm3 = np.mean(gaX)\ns3 = np.var(gaX)\n\nprint(f\"Antithetic variable method confidence interval:, [{m3 - 1.96 * np.sqrt(s3 / n):.3f}, {m3:.3f}, {m3 + 1.96 * np.sqrt(s3 / n):.3f}]\")\nprint(f\"Variance {s3:.3f}\")\n\nAntithetic variable method confidence interval:, [1.461, 1.464, 1.468]\nVariance 0.028\n\n\nOn constate que l’intervalle de confiance est plus étroit donc la précision meilleure avec la variable antithétique. On a divisé la variance (empirique) par 8. Pour obtenir le même gain en augmentant le nombre de simulations, il aurait fallu 8^2=64 fois plus de simulations.\n\n\n\nÉchantillonnage préférentiel\nL’idée derrière l’échantillonnage préférentiel est similaire à celle des variables de contrôle. Cette fois-ci, au lieu de retrancher et d’ajouter une quantité, on va multiplier et diviser. L’interprétation en terme d’espérance est cependant complètement différente.\nSupposons que l’on sache simuler une variable aléatoire Y de densité h. On peut alors écrire I comme \n\\begin{align*}\nI&=\\mathbb E[g(X)]=\\int g(x)f(x)dx\n\\\\ &= \\int \\frac{g(x)f(x)}{h(x)}h(x)dx=\\mathbb{E}\\left[ \\frac{g(Y)f(Y)}{h(Y)}\\right].\n\\end{align*}\n\nOn a gagné quelque chose si \\mathop{\\mathrm{Var}}\\Big(\\frac{gf}{h}(Y)\\Big)&lt;\\mathop{\\mathrm{Var}}\\big(g(X)\\big).\nComme pour la méthode de la variable de contrôle, on souhaite que la nouvelle variable \\frac{g(Y)f(Y)}{h(Y)} soit de variance aussi petite que possible, donc proche d’une constante. Si on prend h(x)=\\frac{g(x)f(x)}{\\mathbb E[g(X)]} (qui est bien une densité si g est positive), alors la variance de \\frac{g(Y)f(Y)}{h(Y)} est nulle. Évidemment, ce résultat n’est pas utilisable en pratique puisqu’on cherche justement à calculer \\mathbb E[g(X)]. Cependant, il guide la recherche d’une bonne fonction h vers une approximation de |gf| normalisée pour obtenir une densité.\n\nExemple 8 Revenons une fois de plus sur l’exemple Exemple 6 où on cherche à approcher I=\\int_0^1 e^{x^2} dx à l’aide de la loi uniforme sur [0,1]. On a donc f(x)=1 sur l’intervalle d’intégration, on cherche donc à nouveau une approximation de g(x)=e^{x^2}. Utilisons encore l’approximation g(x)\\simeq 1+x^2, ce qui nous conne comme densité candidate h(x)=\\frac{3}{4}(1+x^2). Regardons si on peut facilement simuler cette densité. Calculons sa fonction de répartition (sur [0,1]) \n    F(t)=\\int_0^t \\frac{3}{4}(1+x^2)=\\frac{3}{4}\\big[x+\\frac{x^3}{3}\\big]_0^1=\\frac{3}{4}(t+\\frac{t^3}{3}).\n Essayons de l’inverser \n    F(t)=u \\Leftrightarrow u = \\frac{4}{3}(t+\\frac{t^3}{3}) \\Leftrightarrow t^3+3t-4u=0\n\nOn trouve alors par la méthode de Cardan1 \n    F(t)=u \\Leftrightarrow t=(\\sqrt{1+4u^2}+2u)^{1/3}-(\\sqrt{1+4u^2}-2u)^{1/3}.\n\n1 voir par exemple la page Equation du troisième degré / Méthode de CardanRegardons ce que ça donne numériquement.\n\nimport numpy as np\n\nn = 10000\nX = np.random.uniform(0, 1, n)\n\n# Direct method\ngX = np.exp(X**2)\nm1 = np.mean(gX)\ns1 = np.var(gX)\n\nprint(f\"Direct method confidence interval: [{m1 - 1.96 * np.sqrt(s1 / n):.3f}, {m1:.3f}, {m1 + 1.96 * np.sqrt(s1 / n):.3f}]\")\nprint(f\"Variance {s1:.3f}\")\n\nDirect method confidence interval: [1.454, 1.463, 1.472]\nVariance 0.226\n\n\n\n# Importance sampling\nY = (2*X + np.sqrt(1 + 4*X**2))**(1/3) - (np.sqrt(1 + 4*X**2) - 2*X)**(1/3)\ngpX = np.exp(Y**2) / (3 * (1 + Y**2) / 4)\nm4 = np.mean(gpX)\ns4 = np.var(gpX)\n\nprint(f\"Importance sampling confidence interval: [{m4 - 1.96 * np.sqrt(s4 / n):.3f}, {m4:.3f}, {m4 + 1.96 * np.sqrt(s4 / n):.3f}]\")\nprint(f\"Variance {s4:.3f}\")\n\nImportance sampling confidence interval: [1.460, 1.463, 1.466]\nVariance 0.020\n\n\nOn constate que l’intervalle de confiance est plus étroit donc la précision meilleure avec l’échantillonnage préférentiel. On a divisé la variance (empirique) par environ 12. Pour obtenir le même gain en augmentant le nombre de simulations, il aurait fallu 12^2=144 fois plus de simulations.\n\nIl existe bien d’autres méthodes de réduction de variance, comme par exemple la méthode de stratification très utilisée en théorie des sondages.",
    "crumbs": [
      "Cours",
      "Méthode de Monte Carlo"
    ]
  },
  {
    "objectID": "Courses/marche_aleatoire.html",
    "href": "Courses/marche_aleatoire.html",
    "title": "Marches aléatoires",
    "section": "",
    "text": "{{ % variance % covariance\n}}\nL’objet de ce chapitre est de faire une première introduction à un exemple intéressant de processus stochastique, soit la marche aléatoire simple symétrique, et ce avec un minimum de formalisme.\nDans la partie Section 1, on définit la marche aléatoire simple symétrique, et on étudie l’allure de ses trajectoires. La partie Section 2 est dédiée à son comportement en temps long. La partie Section 3 présente une première application vers les mathématiques financières avec l’étude d’un problème de ruine.",
    "crumbs": [
      "Cours",
      "Marches aléatoires"
    ]
  },
  {
    "objectID": "Courses/marche_aleatoire.html#sec-chap03-traj",
    "href": "Courses/marche_aleatoire.html#sec-chap03-traj",
    "title": "Marches aléatoires",
    "section": "Trajectoires de la marche aléatoire",
    "text": "Trajectoires de la marche aléatoire\nUn processus stochastique est une suite de variables aléatoires indexée par le temps. Il permet de modéliser l’évolution temporelle d’un phénomène comme la richesse d’une joueuse ou la valeur d’un portefeuille d’actions par exemple. La marche aléatoire simple symétrique est le modèle le plus simple de processus à temps discret.\nDans toute la suite, on se place sur un espace probabilisé (\\Omega, \\mathcal{F}, \\mathbb{P}).\n\nDéfinition\nCommençons par définir la marche aléatoire simple symétrique.\n\nDéfinition 1 Une marche aléatoire simple symétrique sur \\Z est une suite (S_n)_{n\\in\\mathbb{N}} de variables aléatoires telles que\n\nS_0=x\\in\\Z est déterministe,\nS_{n+1}=S_n+X_{n+1} pour tout n\\in\\mathbb{N},\n\noù (X_n)_{n\\geq 1} est une suite de variables aléatoires indépendantes et de même loi de Rademacher de paramètre \\frac 1 2 : \n\\mathbb{P}(X_1=-1)=\\mathbb{P}(X_1=1)=\\frac{1}{2}.\n\n\nOn parle de marche car ce processus peut représenter la position d’une personne qui se déplace en ligne droite par pas d’une unité avec équiprobabilité d’aller vers l’avant (+1) ou vers l’arrière (-1). Cette marche est dite simple car on ne fait que des pas d’amplitude 1 et symétrique car il y a la même probabilité de tirer 1 et -1 pour chaque incrément.\nCe processus peut également servir à modéliser la richesse d’une joueuse qui joue à pile ou face avec une pièce équilibrée. Partant d’une richesse initiale S_0=x&gt;0, à chaque pas de temps elle perd ou gagne 1 en fonction du tirage obtenu. Les variables X_n représentent alors le gain du n-ème jeu, et S_n la richesse totale de la joueuse après le n-ème tirage.\n\n\n\nPlotly = require('plotly.js-dist');\ndists = require( 'https://cdn.jsdelivr.net/gh/stdlib-js/stats-base-dists@umd/browser.js' );\njstat = require('jstat');\nseedrandom = require('seedrandom@3.0.5');\nmath = require(\"mathjs\");\n// see source here: https://github.com/stdlib-js/stats-base-dists/tree/umd\n// continuous case\n\nviewof inputs = Inputs.form([\n  Inputs.range([-10, 10], {label: tex`x`, step: 1}, {value: 3}),\n  Inputs.range([1, 100], {label: tex`n`, step: 1}),\n  Inputs.button(\"Re-Tirage\")\n])\n\nmu = inputs[0];\nn_samples = inputs[1];\nseed = 44 + inputs[2];\n\n{\n\nconst rng = seedrandom(seed)\n\nfunction random_walk(n=100){\n    var samples = Array.from({length: n}, () =&gt; {\n         if (rng.double() &gt; 0.5) {\n            return 1;\n        } else {\n            return -1;\n            }\n    });\n\n    return samples;\n}\nvar samples = random_walk(100);\n\n\n// create a cumsum function:\nfunction cumsum(array) {\n  var result = [];\n  array.reduce(function(a,b,i) { return result[i] = a+b; },0);\n  return result;\n}\n\n\nvar npoints=100, mini = 0, maxi=100;\nvar x = new Array(npoints), walk = new Array(npoints), zeros = new Array(npoints), z = new Array(npoints), i, j;\n\n//  Densité:s\nfor(var i = 0; i &lt; npoints; i++) {\n    x[i] = i ;\n    zeros[i] = 0;\n    }\n\n{\n    // points lower\nvar trace1 = {\n        x: x.slice(1, n_samples+1),\n        y: zeros.slice(1, n_samples+1),\n        z: samples.slice(0, n_samples),\n        // mode: 'markers',\n        type: 'heatmap',\n            xaxis: 'x2',\n\n        // marker: {\n        //     color: samples2.slice(0, n_samples2).map((x) =&gt; x &gt; 0 ? 'blue' : 'red'),\n        //     size: 5,\n        // },\n        showscale: false,\n        colorscale: [[0, \"rgb(66, 139, 202)\"], [1, \"rgb(255,0,0)\"]],\n\n  }\n\nwalk = cumsum(samples);\nfor(var i = 0; i &lt; npoints; i++) {\n    walk[i] = walk[i] + mu ;\n    }\n\n\nvar trace22 = {\n        x: x.slice(0, n_samples),\n        y: walk.slice(0, n_samples),\n        type: \"scatter\",\n        mode: \"lines\",\n        name: 'Marche aléatoire',\n        line: {color: 'black'},\n        yaxis: 'y2',\n        xaxis: 'x2',\n        }\n\n\n\nvar data = [\n  trace1,\n  trace22,\n  ];\n\n\nvar layout = {\n    width: 600,\n  xaxis: {range: [0, n_samples+1],\n          showticklabels: false,\n          autorange: false},\n    yaxis: {domain: [0, 0.08],\n            showticklabels: false,\n      ticks:\"\",\n            range: [-0.5, 0.5],\n            autorange: false},\n    xaxis2: {matches: 'x',\n              range: [0, n_samples+1],\n          autorange: true},\n    yaxis2: {domain: [0.29, 0.99],\n              range: [-20, 20]},\n\n  showlegend: false,\n\n};\n\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.react(div, data, layout, config);\n    return div;\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Marche aléatoire simple symétrique et son chemin, initialisée en (0,x).\n\n\n\nA partir de la définition, on obtient très facilement le comportement moyen de la marche.\n\nProposition 1 Pour tout n\\in\\mathbb{N}, on a \n\\mathbb{E}[S_n]=S_0,\\quad \\mathop{\\mathrm{Var}}(S_n)=n.\n\n\n\nPreuve. Remarquons d’abord que \n\\begin{align*}\n\\mathbb{E}[X_1]&=(-1)\\times \\frac{1}{2}+1\\times  \\frac{1}{2}=0,\\\\\n\\mathop{\\mathrm{Var}}(X_1)&=\\mathbb{E}[X_1^2]=(-1)^2\\times \\frac{1}{2}+1^2\\times  \\frac{1}{2}=1,\n\\end{align*}\n les incréments sont donc centrés et réduits. Par linéarité de l’espérance, on obtient \n\\mathbb{E}[S_n]=\\mathbb{E}[S_0+\\sum_{k=1}^n X_k]=S_0+\\sum_{k=1}^n \\mathbb{E}[X_k]=S_0,\n puisque S_0 est déterministe. Enfin, en utilisant l’indépendance des X_k, on obtient \n\\mathop{\\mathrm{Var}}(S_n)=\\mathop{\\mathrm{Var}}(S_0+\\sum_{k=1}^n X_k)=\\sum_{k=1}^n \\mathop{\\mathrm{Var}}(X_k)=n,\n d’où le résultat.\n\nAinsi, en moyenne la marche reste constante, mais sa variance devient de plus en plus grande au cours du temps.\n\n\nReprésentation graphique\nLes marches aléatoires, comme tous les processus à valeurs discrètes, ont une représentation graphique naturelle. On représente graphiquement un tirage de la marche (S_n)_{n\\in\\mathbb{N}} sur l’intervalle de temps \\llbracket 0,N \\rrbracket par une ligne brisée joignant les points (0,S_0), (1,S_1), ,(N,S_N). On a donc en abscisse le temps, et en ordonnée la valeur de la marche, cf. Figure 1.\n\nLa marche aléatoire est un processus à temps discret, donc rigoureusement sa représentation graphique devrait être constituée des points (n,S_n) non reliés. Par exemple, S_{1/2} n’est pas défini. Cependant, on relie les points pour une meilleure lecture des graphiques.\nOn s’intéresse maintenant aux représentations graphiques qui peuvent correspondre à des tirages de la marche aléatoire.\n\nDéfinition 2 Soit n&gt;m deux entiers naturels et (a,b)\\in\\Z^2 deux entiers relatifs. On appelle chemin de (m,a) à (n,b) la représentation graphique d’un tirage de la marche aléatoire telle que S_m=a et S_n=b.\n\n\nExemple 1 La figure présente deux chemins de (1,1) à (5,3). \n\nOn peut maintenant se poser la question de savoir s’il existe toujours un chemin qui relie deux points quelconques, et s’il en existe, combien on peut construire de chemins différents reliant ces deux points. On peut facilement montrer que certains chemins sont impossibles en regardant la parité de la marche aléatoire et son amplitude maximale.\n\nProposition 2 (Parité) Pour tout n\\in\\mathbb{N}, S_{2n} a la même parité que S_0 et S_{2n+1} a la parité opposée à celle de S_0.\n\n\nPreuve. Pour tout n, X_{n+1} prend les valeurs -1 ou 1 donc est impair. Comme S_{n+1}=S_n+X_{n+1}, la marche change de parité à chaque pas de temps.\n\nOn en déduit immédiatement que les chemins doivent respecter cette alternance de parité.\n\nCorollaire 1 Si n-m et b-a n’ont pas la même parité, alors il n’existe pas de chemin de (m,a) à (n,b).\n\n\nPreuve. Supposons sans perte de généralité que n-m est pair, et qu’il existe un chemin de (m,a) à (n,b). Alors S_m=a et S_n=b ont nécessairement la même parité, donc S_n-S_m=b-a est pair.\n\n\nExemple 2 Il n’existe pas de chemin de (0,0) à (2,1).\n\n\nProposition 3 (Amplitude) Pour tout n\\in\\mathbb{N}, on a S_0-n\\leq S_n\\leq S_0+n.\n\n\nPreuve. Pour tout n, X_{n} prend les valeurs -1 ou 1 donc en particulier \n-1\\leq X_n\\leq 1.\n Comme S_{n}=S_0+\\sum_{k=1}^n X_k, en sommant les inégalités on obtient bien \nS_0-n\\leq S_n\\leq S_0+n,\n d’où le résultat.\n\n\nCorollaire 2 Si n-m&lt;|b-a|, alors il n’existe pas de chemin de (m,a) à (n,b).\n\n\nPreuve. Supposons qu’il existe un chemin de (m,a) à (n,b). Alors S_m=a et S_n=b. En particulier, S_n=S_m+\\sum_{k=m+1}^nX_k, d’où \\begin{align*}\n&S_m-(n-m)\\leq S_n\\leq S_m+(n-m)\\\\\n\\Rightarrow & \\; a-(n-m)\\leq b\\leq a+(n-m)\\\\\n\\Rightarrow & \\; -(n-m)\\leq b-a\\leq n-m.\n\\end{align*} On a donc nécessairement |b-a|\\leq n-m.\n\n\nExemple 3 Il n’existe pas de chemin de (0,0) à (2,4).\n\n\n\n\nviewof inputs2 = Inputs.form([\n  Inputs.range([2, 100], {label: tex`n`, step: 2}),\n  Inputs.button(\"Re-Tirage\")\n])\n\nn_samples2 = inputs2[0];\nseed2 = 44 + inputs2[1];\n\n{\nvar npoints2=n_samples2\nconst rng = seedrandom(seed2)\nvar samples2 = new Array(npoints2)\n// create a vector of size 100 whose first half is 1 and second half is -1\nfor (var i = 0; i &lt; npoints2 ; i++) {\n  samples2[i] = i &gt;= npoints2/2  ? 1 : -1;\n}\n\n// https://www.codemzy.com/blog/shuffle-array-javascript\nfunction shuffleArray(array) {\n  let length = array.length;\n  let shuffle = array.slice(); // copy of array\n  // loop over the array\n  for (let i = length - 1; i &gt; 0; i -= 1) {\n    let random = Math.floor(rng.double() * (i + 1)); // random card position\n    let current = shuffle[i]; // current card\n    // swap the random card and the current card\n    shuffle[i] = shuffle[random]; // move the random card to the current position\n    shuffle[random] = current; // put the current card in the random position\n  }\n  return shuffle; // return shuffled array\n};\n\n\nsamples2=shuffleArray(samples2);\n\nvar x2 = new Array(npoints2), walk2 = new Array(npoints2), zeros2 = new Array(npoints2), z = new Array(npoints2), i, j;\n\n\n// create a cumsum function:\nfunction cumsum(array) {\n  var result = [];\n  array.reduce(function(a,b,i) { return result[i] = a+b; },0);\n  return result;\n}\n\nvar walkint = cumsum(samples2);\nwalk2 = new Array(npoints2+1),\nwalk2[0] = 0\nfor(i = 0; i &lt; npoints2; i++) {\n    walk2[i+1] = walkint[i];\n    }\n\n//  Densité:\nfor(var i = 0; i &lt; npoints2+1; i++) {\n    x2[i] = i ;\n    zeros2[i] = 0;\n    }\n\n{\n    // points lower\nvar trace1 = {\n        x: x2.slice(1, n_samples2+1),\n        y: zeros2.slice(1, n_samples2+1),\n        z: samples2.slice(0, n_samples2),\n        // mode: 'markers',\n        type: 'heatmap',\n            xaxis: 'x2',\n\n        // marker: {\n        //     color: samples2.slice(0, n_samples2).map((x) =&gt; x &gt; 0 ? 'blue' : 'red'),\n        //     size: 5,\n        // },\n        showscale: false,\n        colorscale: [[0, \"rgb(66, 139, 202)\"], [1, \"rgb(255,0,0)\"]],\n\n  }\n\n\n\nvar trace22 = {\n        x: x2.slice(0, n_samples2+1),\n        y: walk2.slice(0, n_samples2+1),\n        type: \"scatter\",\n        mode: \"lines\",\n        name: 'Marche aléatoire',\n        line: {color: 'black'},\n        yaxis: 'y2',\n        xaxis: 'x2',\n        }\n\n\n\nvar data = [\n  trace1,\n  trace22,\n  ];\n\n\nvar layout = {\n    width: 600,\n  xaxis: {range: [0, n_samples2+1],\n          showticklabels: false,\n          autorange: false},\n    yaxis: {domain: [0, 0.08],\n            showticklabels: false,\n      ticks:\"\",\n            range: [-0.5, 0.5],\n            autorange: false},\n    xaxis2: {matches: 'x',\n              range: [0, n_samples2+1],\n          autorange: true},\n    yaxis2: {domain: [0.29, 0.99],\n              range: [-14, 14]},\n\n  showlegend: false,\n\n};\n\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.react(div, data, layout, config);\n    return div;\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Marche aléatoire simple symétrique passant en (0,0) et en (100,0).\n\n\n\nUne fois les conditions de parité et d’amplitude satisfaites, il existe toujours des chemins reliant deux points, et on peut les dénombrer explicitement.\n\nProposition 4 (Nombre de chemins) Si |b-a|\\leq n-m et n-m et b-a ont la même parité, alors le nombre de chemins de (m,a) à (n,b) est le nombre de combinaisons \\displaystyle \\binom{n-m}{\\frac{n-m}{2}+\\frac{b-a}{2}}.\n\n\nPreuve. Un chemin de (m,a) à (n,b) correspond à n-m pas de la marche aléatoire en partant de a et en arrivant en b. Supposons sans perte de généralité que b&gt;a. Alors on peut décomposer les pas de la marche entre x pas vers le haut (tirages de +1) et y pas vers le bas (tirages de -1). On doit avoir un nombre total de pas de x+y=n-m, et une différence des ordonnées de x-y=b-a, ce qui donne le système \n\\begin{align*}\n\\left\\{\\begin{array}{rcl}\nx+y&=&n-m\\\\\nx-y&=&b-a\n\\end{array}\n\\right.\n\\Leftrightarrow\n\\left\\{\\begin{array}{rcl}\nx&=&\\frac{n-m}{2}+\\frac{b-a}{2}\\\\\ny&=&\\frac{n-m}{2}-\\frac{b-a}{2}\n\\end{array}\n\\right..\n\\end{align*}\n Pour dénombrer le nombre total de chemins de longueur x+y avec x montées et y descentes, il suffit de choisir les emplacements de x montées parmi les x+y pas. On obtient donc \\binom{x+y}{x}=\\binom{n-m}{\\frac{n-m}{2}+\\frac{b-a}{2}} chemins.\n\nRemarquons que pour dénombrer le nombre de chemins d’un point à un autre, nous n’avons pas utilisé le fait que \\mathbb P(X=1)=\\mathbb P(X=-1), mais uniquement le fait que X ne peut prendre que les valeurs -1 et 1. Le résultat ci-dessus est donc également valable pour les marches asymétriques où p=\\mathbb P(X=1)=1-\\mathbb P(X=-1)\\neq \\frac{1}{2}.\n\n\nPrincipe de réflexion\nOn souhaite maintenant dénombrer les chemins qui ont une propriété particulière supplémentaire, comme passer par un point fixé. Pour cela, on utilise les propriétés de symétrie de la marche.\n\nProposition 5 (Principe de réflexion) Soit a et b deux entiers naturels non nuls et n,m deux entiers naturels tels que n&gt;m, |b-a|\\leq n-m et b-a et n-m ont la même parité. Alors le nombre de chemins de (m,a) à (n,b) passant par 0 (i.e. touchant l’axe des abscisses) est égal au nombre de chemins de (m,a) à (n,-b).\n\n\nPreuve. \nLe principe est de construire une bijection entre les deux ensembles de chemins pour prouver qu’ils ont le même cardinal. Pour cela, on exploite la symétrie de la marche, comme illustré figure . %=========================\n%========================= Considérons un chemin (S_m,\\ldots,S_n) de (m,a) à (n,b) passant par 0 pour la première fois en p. On a alors m&lt;p&lt;n. On construit un chemin (\\widetilde{S}_m,\\ldots,\\widetilde{S}_n)de (m,a) à (n,-b) en gardant la première partie du chemin initial de (m,a) à (p,0), puis en prenant ensuite le symétrique du chemin initial par rapport à l’axe des abscisses de (p,0) à (n,-b) : \\begin{align*}\n\\widetilde{S}_k=\\left\\{\n\\begin{array}{lcl}\nS_k &\\text{ si }& m\\leq k\\leq p,\\\\\n-S_k&\\text{ si }& p\\leq k\\leq n.\n\\end{array}\n\\right.\n\\end{align*} Cette application définit une bijection entre les deux ensembles de chemins. En effet, si on prend maintenant un chemin (\\widetilde{S}_m,\\ldots,\\widetilde{S}_n) de (m,a) à (n,-b), comme il fait des pas de 1, que a&gt;0 et -b&lt;0, ce chemin passe nécéssairement par 0. Soit p le premier instant où le chemin est en 0. On construit alors un chemin (S_m,\\ldots,S_n) de (m,a) à (n,b) passant par 0 en posant \\begin{align*}\nS_k=\\left\\{\n\\begin{array}{lcl}\n\\widetilde{S}_k &\\text{ si }& m\\leq k\\leq p,\\\\\n-\\widetilde{S}_k&\\text{ si }& p\\leq k\\leq n.\n\\end{array}\n\\right.\n\\end{align*} Il y a donc le même nombre de chemins des deux types.\n\nA nouveau, nous n’avons pas utilisé le fait que \\mathbb P(X=1)=\\mathbb P(X=-1), mais uniquement le fait que X ne peut prendre que les valeurs -1 et 1 qui sont symétriques l’une de l’autre. Le résultat ci-dessus est donc également valable pour les marches asymétriques où p=\\mathbb P(X=1)=1-\\mathbb P(X=-1)\\neq \\frac{1}{2}. Une première application de cette propriété est le résultat suivant connu sous le nom de théorème su scrutin.\n\nThéorème 1 Au cours d’une élection opposant deux candidates A et B, la candidate A (resp. B) a obtenu a (resp. b) voix, avec a&gt;b. Alors la probabilité que A ait été majoritaire (au sens large) tout au long du dépouillement est \np=1-\\frac{b}{a+1}.\n\n\n\nPreuve. Tous les dépouillement étant équiprobables, p s’obtient comme le rapport du nombre de dépouillements avec A en tête tout le long par le nombre total de dépouillements. On peut modéliser un dépouillement par une marche aléatoire (S_n) (pas nécessairement symétrique) où S_n est le nombre de voix d’avance de A sur B après le dépouillement du n-ème bulletin.\nIl y a en tout a+b bulletins et à la fin a-b voix d’avance de A sur B, donc le nombre total de dépouillements est le nombre de chemins de (0,0) à (a+b,a-b) et vaut \\binom{a+b}{a}.\nLe nombre de dépouillements avec A en tête tout le long correspond\nIl vaut donc \\binom{a+b}{a}-\\binom{a+b}{b-1}. Ainsi \\begin{align*}\np=\\frac{\\binom{a+b}{a}-\\binom{a+b}{b-1}}{\\binom{a+b}{a}}=1-\\frac{\\binom{a+b}{b-1}}{\\binom{a+b}{a}}=1-\\frac{(a+b)!a!b!}{(b-1)!(a+1)!(a+b)!}=1-\\frac{b}{a+1},\n\\end{align*} d’où le résultat.",
    "crumbs": [
      "Cours",
      "Marches aléatoires"
    ]
  },
  {
    "objectID": "Courses/marche_aleatoire.html#sec-chap03-infini",
    "href": "Courses/marche_aleatoire.html#sec-chap03-infini",
    "title": "Marches aléatoires",
    "section": "Comportement asymptotique",
    "text": "Comportement asymptotique\nOn s’intéresse maintenant au comportement de la marche sans limite de temps. Parmi les questions d’intérêt, on peut se demander si elle revient à son point de départ x, combien de fois et en combien de temps.\nComme les (X_n)_{n\\geq 1} sont indépendantes et de même loi intégrable, on peut appliquer la loi des grands nombres pour obtenir que \n\\frac{S_n}{n}\\xrightarrow[n\\to\\infty]{ps}\\mathbb{E}[X_1]=0,\n ce qui ne donne aucune information sur le comportement en temps long de S_n.\n\nPropriété de Markov et stationnarité\nLes deux propriétés suivantes sont des propriétés du processus et non plus seulement des trajectoires. Elles énoncent une certaine forme d’invariance de la marche au cours du temps. La première est une propriété d’absence de mémoire : la position future de la marche ne dépend que de sa position actuelle et pas de la trajectoire qui l’a amenée à cette position.\n\nProposition 6 (Markov) Pour tout n\\in\\mathbb{N} et pour tous (a_0,a_1,\\ldots,a_{n+1})\\in\\Z^{n+2}, on a \\begin{align*}\n\\mathbb{P}(S_{n+1}=a_{n+1}& | S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)\\\\\n=\\mathbb{P}(S_{n+1}=a_{n+1}& | S_n=a_n).\n\\end{align*}\n\n\nPreuve. Par définition des probabilités conditionnelles, on a \\begin{align*}\n\\mathbb{P}(S_{n+1}=a_{n+1} &| S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)\\\\\n&=\\frac{\\mathbb{P}(S_{n+1}=a_{n+1}, S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)}{\\mathbb{P}(S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)}\\\\\n&=\\frac{\\mathbb{P}(X_{n+1}=a_{n+1}-a_n, S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)}{\\mathbb{P}(S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)},\n\\end{align*} puisque S_{n+1}=S_n+X_{n+1}. Remarquons maintenant que X_{n+1} est indépendante de X_1,\\ldots, X_n, donc de S_0,\\ldots,S_n. On obtient alors \\begin{align*}\n\\mathbb{P}(S_{n+1}=a_{n+1} &| S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)\\\\\n&=\\frac{\\mathbb{P}(X_{n+1}=a_{n+1}-a_n)\\mathbb{P}(S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)}{\\mathbb{P}(S_n=a_n, S_{n-1}=a_{n-1},\\ldots,S_1=a_1,S_0=a_0)}\\\\\n&=\\mathbb{P}(X_{n+1}=a_{n+1}-a_n).\n\\end{align*} Par ailleurs, par un raisonnement analogue on a \\begin{align*}\n\\mathbb{P}(S_{n+1}=a_{n+1} | S_n=a_n)\n&=\\frac{\\mathbb{P}(S_{n+1}=a_{n+1},S_n=a_n)}{\\mathbb{P}(S_n=a_n)}\\\\\n&=\\frac{\\mathbb{P}(X_{n+1}=a_{n+1}-a_n,S_n=a_n)}{\\mathbb{P}(S_n=a_n)}\\\\\n&=\\frac{\\mathbb{P}(X_{n+1}=a_{n+1}-a_n)\\mathbb{P}(S_n=a_n)}{\\mathbb{P}(S_n=a_n)}\\\\\n&=\\mathbb{P}(X_{n+1}=a_{n+1}-a_n),\n\\end{align*} d’où le résultat.\n\n\nProposition 7 Pour tout n &gt; m entiers positifs S_n-S_m est indépendant de (S_0,S_1,\\ldots, S_m).\n\n\nPreuve. Comme les (X_n) sont indépendantes, on a directement que \nS_n-S_m=\\sum_{k=m+1}^nX_k,\n qui est indépendant de (S_0=x,S_1=x+X_1,\\ldots, S_m=x+\\sum_{k=1}^mX_k).\n\nOn a un résultat analogue à la propriété de Markov lorsqu’on regarde deux pas de temps plus éloignés.\n\nCorollaire 3 Pour tout n&gt;m entiers positifs et pour tous (a_0,a_1,\\ldots,a_m,a_{n})\\in\\Z^{m+2}, on a \\begin{align*}\n\\mathbb{P}(S_{n}=a_{n}& | S_m=a_m, S_{m-1}=a_{m-1},\\ldots,S_1=a_1,S_0=a_0)\\\\\n=\\mathbb{P}(S_{n}=a_{n}& | S_m=a_m).\n\\end{align*}\n\n\nPreuve. Par un raisonnement analogue à la preuve de la propriété de Markov, on obtient \\begin{align*}\n\\mathbb{P}(S_{n}=a_{n}&| S_m=a_m, S_{m-1}=a_{m-1},\\ldots,S_1=a_1,S_0=a_0)\\\\\n&=\\frac{\\mathbb{P}(S_{n}=a_{n},S_m=a_m, S_{m-1}=a_{m-1},\\ldots,S_1=a_1,S_0=a_0)}{\\mathbb{P}(S_m=a_m, S_{m-1}=a_{m-1},\\ldots,S_1=a_1,S_0=a_0)}\\\\\n&=\\frac{\\mathbb{P}(S_{n}-S_m=a_{n}-a_m,S_m=a_m, S_{m-1}=a_{m-1},\\ldots,S_1=a_1,S_0=a_0)}{\\mathbb{P}(S_m=a_m, S_{m-1}=a_{m-1},\\ldots,S_1=a_1,S_0=a_0)}\\\\\n&=\\frac{\\mathbb{P}(S_{n}-S_m=a_{n}-a_m)\\mathbb{P}(S_m=a_m, S_{m-1}=a_{m-1},\\ldots,S_1=a_1,S_0=a_0)}{\\mathbb{P}(S_m=a_m, S_{m-1}=a_{m-1},\\ldots,S_1=a_1,S_0=a_0)}\\\\\n&=\\mathbb{P}(S_{n}-S_m=a_{n}-a_m)\\\\\n&=\\mathbb{P}(S_n=a_n|S_m=a_m),\n\\end{align*} en utilisant la propriété des accroissement indépendants.\n\nLa seconde propriété dite de stationnarité signifie qu’on peut changer l’origine du repère sans influence sur le comportement futur de la marche.\n\nProposition 8 (Sationnarité) Pour tout n&gt;m entiers positifs et (a,b)\\in\\Z^2, on a \n\\mathbb{P}(S_n=b|S_m=a)=\\mathbb{P}(S_{n-m}= b-a|S_0= 0).\n\n\n\nPreuve. En utilisant l’indépendance des accroissements, on obtient \\begin{align*}\n\\mathbb{P}(S_n=b|S_m=a)\n&=\\frac{\\mathbb{P}(S_n=b,S_m=a)}{\\mathbb{P}(S_m=a)}\\\\\n&=\\frac{\\mathbb{P}(S_n-S_m=b-a,S_m=a)}{\\mathbb{P}(S_m=a)}\\\\\n&=\\frac{\\mathbb{P}(S_n-S_m=b-a)\\mathbb{P}(S_m=a)}{\\mathbb{P}(S_m=a)}\\\\\n&=\\mathbb{P}(S_n-S_m=b-a)\\\\\n&=\\mathbb{P}(\\sum_{k=m+1}^nX_k=b-a)\\\\\n&=\\mathbb{P}(\\sum_{k=1}^{n-m}X_k=b-a)\\\\\n&=\\mathbb{P}(S_{n-m}=b-a|S_0=0),\n\\end{align*} car les (X_n) sont indépendantes et de même loi.\n\n\n\nPremier retour en 0\nOn suppose maintenant que la marche part de 0 : S_0=0 et on cherche à savoir si la marche reviendra en 0 presque sûrement. Commençons par remarquer que si S_n=0 alors n est nécessairement pair.\n\nProposition 9 Pour tout n\\in\\mathbb{N}, on a \n\\mathbb{P}(S_{2n}=0)=\\frac{1}{4^n}\\binom{2n}{n}.\n\n\n\nPreuve. Cette probabilité correspond au nombre de chemins de (0,0) à (2n,0) divisé par le nombre total de chemins de longueur 2n, puisque tous les chemins sont équiprobables. On a donc directement \\mathbb{P}(S_{2n}=0)=\\frac{\\binom{2n}n}{4^n}.\n\nOn s’intéresse maintenant au premier instant de retour en 0. On le note T_0. Il s’agit donc de la variable aléatoire \nT_0=\\inf\\{n\\geq 1; S_n=0\\},\n avec la convention que \\inf\\emptyset= +\\infty. C’est donc une variable aléatoire discrète à valeurs dans \\mathbb{N}^*\\cup\\{+\\infty\\}. On peut calculer explicitement la loi de T_0.\n\nProposition 10 Pour tout n\\in\\mathbb{N}^*, on a \n\\mathbb{P}(T_0=2n)=\\frac{(2n-2)!}{2^{2n-1}n!(n-1)!}.\n\n\n\nPreuve. L’événement (T_0= 2n) correspond à (S_2\\neq 0, \\ldots,S_{2n-2}\\neq 0,S_{2n}=0) puisqu’alors 2n est le premier temps où la marche retourne en 0. En particulier, entre l’instant 0 et l’instant 2n la marche ne change pas de signe, et garde le signe de S_1. Ainsi, on a \\begin{align*}\n\\mathbb{P}(T_0=2n)&=\\mathbb{P}(S_1=1,S_2&gt;0,\\ldots,S_{2n-2}&gt;0,S_{2n}=0)\\\\\n&\\quad+\\mathbb{P}(S_1=-1,S_2&lt;0,\\ldots,S_{2n-2}&lt;0,S_{2n}=0).\n\\end{align*} Par symétrie, ces deux probabilités sont égales. De plus, si S_{2n-2}&gt;0 et S_{2n}=0 alors nécessairement on a S_{2n-1}=1. Ainsi il vient \\begin{align*}\n{\\mathbb{P}(T_0=2n)}\\\\\n&=2\\mathbb{P}(S_1=1,S_2&gt;0,\\ldots,S_{2n-2}&gt;0,S_{2n-1}=1,S_{2n}=0)\\\\\n&=2\\mathbb{P}(S_{2n}=0|S_1=1,S_2&gt;0,\\ldots,S_{2n-2}&gt;0,S_{2n-1}=1)\\\\\n&\\quad \\times\\mathbb{P}(S_1=1,S_2&gt;0,\\ldots,S_{2n-2}&gt;0,S_{2n-1}=1)\\\\\n&=2\\mathbb{P}(S_{2n}=0|S_{2n-1}=1)\\mathbb{P}(S_1=1,S_2&gt;0,\\ldots,S_{2n-2}&gt;0,S_{2n-1}=1)\\\\\n&=2\\mathbb{P}(S_{1}=-1|S_0=0)\\mathbb{P}(S_1=1,S_2&gt;0,\\ldots,S_{2n-2}&gt;0,S_{2n-1}=1)\\\\\n&=\\mathbb{P}(S_1=1,S_2&gt;0,\\ldots,S_{2n-2}&gt;0,S_{2n-1}=1),\n\\end{align*} en utilisant la propriété de Markov, la propriété de stationnarité puis le fait que \n{\\mathbb P}(S_1=-1|S_0=0) = {\\mathbb P}(X_1=-1) = \\frac{1}{2}.\n Cette dernière probabilité correspond au nombre de chemins de (1,1) à (2n-1,1) ne touchant pas 0 divisée par le nombre total de chemins de longueur 2n-1. En utilisant le principe de réflexion, on obtient \\begin{align*}\n\\mathbb{P}(T_0=2n)\n&=\\frac{\\binom{2n-2}{n-1}-\\binom{2n-2}{n}}{2^{2n-1}}\\\\\n&=\\frac{1}{2^{2n-1}}\\left(\\frac{(2n-2)!}{(n-1)!(n-1)!}-\\frac{(2n-2)!}{n!(n-2)!}\\right)\\\\\n&=\\frac{1}{2^{2n-1}}\\frac{(2n-2)!}{(n-1)!(n-2)!}\\left(\\frac{1}{n-1}-\\frac{1}{n}\\right)\\\\\n&=\\frac{(2n-2)!}{2^{2n-1}n!(n-1)!},\n\\end{align*} d’où le résultat.\n\nNous pouvons maintenant énoncer le résultat principal de cette partie.\n\nThéorème 2 La marche aléatoire partant de 0 revient en 0 en temps fini avec probabilité 1, i.e. \n\\mathbb{P}(T_0 &lt; +\\infty)=1.\n\n\n\nPreuve. On a \\mathbb{P}(T_0&lt;+\\infty)=\\sum_{n=1}^\\infty\\mathbb{P}(T_0=2n), il s’agit donc d’identifier la somme de cette série. Pour cela, on exprime différemment le probabilité de l’événement (T_0=2n), en repartant de l’expression du nombre de chemins de (1,1) à (2n-1,1) ne touchant pas 0 divisée par le nombre total de chemins de longueur 2n-1. Ce nombre de chemins est égal à la différence entre le nombre de chemins de (1,1) à (2n-1,1) et le nombre de chemins de (1,1) à (2n-1,-1) d’après le principe de réflexion. On obtient ainsi : \\begin{align*}\n{\\mathbb{P}(T_0=2n)}\\\\\n&=\\mathbb{P}(S_1=1, S_{2n-1}=1)-\\mathbb{P}(S_1=1, S_{2n-1}=-1)\\\\\n&=\\mathbb{P}(S_{2n-1}=1|S_1=1)\\mathbb{P}(S_1=1)-\\mathbb{P}(S_{2n-1}=-1|S_1=1)\\mathbb{P}(S_1=1)\\\\\n&=\\frac{1}{2}\\mathbb{P}(S_{2n-2}=0|S_0=0)-\\frac{1}{2}\\mathbb{P}(S_{2n-2}=-2|S_0=0)\\\\\n&=\\frac{1}{2}\\mathbb{P}(S_{2n-2}=0)-\\frac{1}{2}\\mathbb{P}(S_{2n-2}=-2),\n\\end{align*} par la propriété de stationnarité et puisque S_0=0. Par ailleurs, on a \\begin{align*}\n{\\mathbb{P}(S_{2n}=0)}  \\\\\n&=\\mathbb{P}(S_{2n}=0, S_{2n-2} =-2)+\\mathbb{P}(S_{2n}=0, S_{2n-2}=0) +\\mathbb{P}(S_{2n}=0, S_{2n-2}=2)\\\\\n&=2\\mathbb{P}(S_{2n}=0, S_{2n-2}=-2)+\\mathbb{P}(S_{2n}=0, S_{2n-2}=0),\n\\end{align*} par symétrie. Il vient \\begin{align*}\n{\\mathbb{P}(S_{2n}=0)}\\\\\n&=2\\mathbb{P}(S_{2n}=0|S_{2n-2}=-2)\\mathbb{P}(S_{2n-2}=-2)+\\mathbb{P}(S_{2n}=0|S_{2n-2}=0)\\mathbb{P}(S_{2n-2}=0)\\\\\n&=2\\mathbb{P}(S_2=2|S_0=0)\\mathbb{P}(S_{2n-2}=-2)+\\mathbb{P}(S_2=0|S_0=0)\\mathbb{P}(S_{2n-2}=0)\\\\\n&=2\\frac{1}{4}\\mathbb{P}(S_{2n-2}=-2)+\\frac{1}{2}\\mathbb{P}(S_{2n-2}=0)\\\\\n&=\\frac{1}{2}\\mathbb{P}(S_{2n-2}=-2)+\\frac{1}{2}\\mathbb{P}(S_{2n-2}=0),\n\\end{align*} où on a utilisé le fait que \\begin{align*}\n\\mathbb{P}(S_2=2|S_0=0)& =   \\mathbb{P}(X_1 + X_2 = 0) \\\\\n&= \\mathbb{P}(X_1 = -1; X_2= 1)+ \\mathbb{P}(X_1 = 1; X_2= -1)\\\\\n&=\\mathbb{P}(X_1 = -1) \\mathbb{P}( X_2= 1)+ \\mathbb{P}(X_1 = 1)\\mathbb{P}( X_2= -1) \\\\\n&=\\frac{1}{2}.\n\\end{align*} Donc on a \\mathbb{P}(S_{2n-2}=-2)=2\\mathbb{P}(S_{2n}=0)-\\mathbb{P}(S_{2n-2}=0).\nRevenons maintenant à T_0. On obtient \\begin{align*}\n\\mathbb{P}(T_0=2n)\n&=\\frac{1}{2}\\mathbb{P}(S_{2n-2}=0)-\\frac{1}{2}\\mathbb{P}(S_{2n-2}=-2)\\\\\n&=\\frac{1}{2}\\mathbb{P}(S_{2n-2}=0)-\\mathbb{P}(S_{2n}=0)+\\frac{1}{2}\\mathbb{P}(S_{2n-2}=0)\\\\\n&=\\mathbb{P}(S_{2n-2}=0)-\\mathbb{P}(S_{2n}=0).\n\\end{align*} Ainsi, la probabilité de l’événement (T_0= +\\infty) peut s’écrire à l’aide d’une somme télescopique : \\begin{align*}\n\\mathbb{P}(T_0=+\\infty)\n&=1-\\sum_{n=1}^\\infty\\mathbb{P}(T_0=2n)\\\\\n&=1-\\lim_{N\\to\\infty}\\sum_{n=1}^N\\mathbb{P}(T_0=2n)\\\\\n&=1-\\lim_{N\\to\\infty}\\sum_{n=1}^N\\left(\\mathbb{P}(S_{2n-2}=0)-\\mathbb{P}(S_{2n}=0)\\right)\\\\\n&=1-\\lim_{N\\to\\infty}\\left(\\mathbb{P}(S_0=0)-\\mathbb{P}(S_{2N}=0)\\right)\\\\\n&=\\lim_{N\\to\\infty}\\mathbb{P}(S_{2N}=0)\\\\\n&=\\lim_{N\\to\\infty}\\frac{1}{4^N}\\binom{2N}{N}.\n\\end{align*} En utilisant la formule de Stirling, on obtient l’équivalence \\begin{align*}\n\\frac{1}{4^N}\\binom{2N}{N} &= \\frac{1}{4^N}\\frac{(2N)!}{N!N!}\n\\sim  \\frac{1}{4^N}\\frac{(2N)^{2N}\\sqrt{4\\pi N}e^{-2N}}{(N^{N}\\sqrt{2\\pi N}e^{-N})^2}\n= \\frac{1}{\\sqrt{\\pi N}},\n\\end{align*} donc on a bien \\mathbb{P}(T_0=+\\infty)=0.\n\n\n\nPremier passage en a\\neq 0\nOn peut obtenir par une méthode similaire la loi du temps d’atteinte de n’importe quel autre point. Soit a\\in\\Z^*. Le temps d’atteinte de a est la variable aléatoire \nT_a=\\inf\\{n\\geq 1; S_n=a\\}.\n\n\nThéorème 3 La marche aléatoire partant de 0 atteint tout état a\\in\\Z en temps fini avec probabilité 1. Plus précisément, si a\\neq 0, on a \\mathbb{P}(T_a=n)=0 si n et a n’ont pas la même parité ou si |a|&gt;n, et sinon \n\\mathbb{P}(T_a=n)=\\frac{|a|}{n2^n}\\binom{n}{\\frac{n+a}{2}}.\n\n\n\nPreuve. \nOn suit les mêmes étapes que ce qu’on a fait pour T_0. Les contraintes de parité et de longueur de chemin ont déjà été vues. Si n et a ont la même parité et que |a|&gt;n, alors l’événement (T_a= n) correspond à (S_1\\neq a, \\ldots,S_{n-1}\\neq a,S_{n}=a) puisqu’alors n est le premier temps où la marche atteint a. Supposons sans perte de généralité que a&gt;0. Donc la probabilité \\mathbb{P}(T_a= n) est égale au nombre de chemins de (0,0) à (n,a) ne touchant pas a avant n divisée par le nombre total de chemins de longueur n. 0r, ce nombre de chemin est égal\nAinsi, on a\n\\begin{align*}\n\\mathbb{P}(T_a=n)\n&=\\frac{\\binom{n-1}{\\frac{n-1}{2}+\\frac{a-1}{2}}-\\binom{n-1}{\\frac{n-1}{2}+\\frac{1+a}{2}}}{2^{n}}\\\\\n&=\\frac{1}{2^{n}}\\left(\\frac{(n-1)!}{(\\frac{n+a-2}{2})!(\\frac{n-a}{2})!}-\\frac{(n-1)!}{(\\frac{n+a}{2})!(\\frac{n-a-2}{2})!}\\right)\\\\\n&=\\frac{1}{2^n}\\frac{(n-1)!}{(\\frac{n+a-2}{2})!(\\frac{n-a-2}{2})!}\\left(\\frac{1}{\\frac{n-a}{2}}-\\frac{1}{\\frac{n+a}{2}}\\right)\\\\\n&=\\frac{a}{2^n}\\frac{(n-1)!}{(\\frac{n+a}{2})!(\\frac{n-a}{2})!}\\\\\n&=\\frac{a}{n2^n}\\binom{n}{\\frac{n+a}{2}}\n\\end{align*} d’où le résultat.\nNous démontrerons dans la partie suivante que \\mathbb{P}(T_a&lt;+\\infty)=1.\n\nEn particulier, la marche partant de 0 va atteindre tout point de \\Z avec probabilité 1, donc elle est presque sûrement non bornée.",
    "crumbs": [
      "Cours",
      "Marches aléatoires"
    ]
  },
  {
    "objectID": "Courses/marche_aleatoire.html#sec-chap03-ruine",
    "href": "Courses/marche_aleatoire.html#sec-chap03-ruine",
    "title": "Marches aléatoires",
    "section": "La ruine de la joueuse",
    "text": "La ruine de la joueuse\nOn s’intéresse maintenant à un problème de ruine. Une joueuse dispose d’un capital initial x. Elle joue à pile ou face avec une pièce équilibrée, et gagne 1 si elle obtient pile, perd 1 si elle obtient face. La joueuse s’est fixé un objectif de gain a\\geq x et un plancher de perte b\\leq x. Elle joue jusqu’à ce que sa richesse atteigne a ou b.\nOn modélise la fortune de la joueuse par une marche aléatoire (S_n)_{n\\in\\mathbb{N}}, avec S_0=x et S_n=S_0+\\sum_{k=1}^n X_k, où X_k représente le gain du k-ème tirage.\nOn sait qu’atteindre a ou b partant de x est équivalent à atteindre a-x ou b-x partant de 0. Le jeu s’arrête donc presque sûrement au bout d’un temps fini.\nOn note p_x la probabilité de ruine partant d’un capital initial x, et R_x l’événement être ruinée en partant de x, c’est-à-dire \np_x=\\mathbb{P}(T_b &lt; T_a)= \\mathbb{P}(R_x).\n On peut remarquer directement que p_a=0 et p_b=1 puisque dans ces deux situations, le jeu ne démarre pas, la ruine est impossible dans le premier cas, et certaine dans le second.\nNous allons obtenir une formule de récurrence sur les p_x. Si b&lt;x&lt;a, on a par la formule des probabilités totales \\begin{align*}\np_x&=\\mathbb{P}(R_x)\\\\\n&=\\mathbb{P}(R_x|S_1=x+1)\\mathbb{P}(S_1=x+1)+\\mathbb{P}(R_x|S_1=x-1)\\mathbb{P}(S_1=x-1)\\\\\n&=\\mathbb{P}(R_{x+1})\\frac{1}{2}+\\mathbb{P}(R_{x-1})\\frac{1}{2},\n\\end{align*} en utilisant la stationnarité. On obtient ainsi que (p_x)_{a&lt;x&lt; b} est une suite récurrente linéaire1 d’ordre 2, de polynôme caractéristique X^2-2X+1=(X-1)^2. Ainsi p_x=\\alpha +\\beta x. On identifie \\alpha et \\beta avec les conditions extrémales p_a=0 et p_b=1 \\begin{align*}\n\\left\\{\\begin{array}{rcl}\np_a=0&=&\\alpha+\\beta a\\\\\np_b=1&=&\\alpha+\\beta b\n\\end{array}\n\\right.\n\\Leftrightarrow\n\\left\\{\\begin{array}{rcl}\n\\alpha&=&\\frac{a}{a-b},\\\\\n\\beta&=&-\\frac{1}{a-b}.\n\\end{array}\n\\right.\n\\end{align*}\n1 Une suite (u_n)_{n \\in {\\mathbb N}} est dite récurrente linéaire d’ordre 2 s’il existe (a,b)\\in\\mathbb{R}\\times\\mathbb{R}^* tel que, pour entier n, on a \nu_{n+2} = a u_{n+1} + b u_n .\n Le polynôme X^2 - a X + b est appelé le polynôme caractéristique de la suite. Si le polynôme caractéristique admet deux racines simples r_1 et r_2, alors il existe deux réels \\alpha et \\beta tels que pour tout entier n, \nu_n = \\alpha r_1^n  + \\beta  r_2^n.\n Si le polynôme caractéristique admet une racine double r, alors il existe deux réels \\alpha et \\beta tels que pour tout entier n, \nu_n = (\\alpha  + \\beta n) r^n.\nAinsi la probabilité de ruine partant de x vaut \np_x=\\frac{a-x}{a-b}.\n\nUn calcul analogue en cherchant la probabilité q_x de faire fortune partant d’une richesse x conduit à q_x=\\frac{x-b}{a-b}=1-p_x, autrement dit il n’y a pas d’autre issue possible : le jeu va s’arrêter avec probabilité 1. Si on fait tendre b vers -\\infty, on trouve que \\mathbb{P}(T_a&lt;\\infty |x_0=a)=1. Donc partant de n’importe quel point, la marche atteindra n’importe quel autre point avec probabilité 1.\nOn peut montrer avec un raisonnement analogue que la durée du jeu d_x partant de x est solution de l’équation récurrente linéaire avec second membre2 \nd_x=\\frac{1}{2}(d_{x+1}+d_{x-1})+1,\n avec d_a=d_b=0.\n2 Une suite (u_n)_{n \\in {\\mathbb N}} est dite récurrente linéaire d’ordre 2 avec second membre s’il existe (a,b) \\in {\\mathbb R} \\times {\\mathbb R}^* et une fonction f à valeurs dans {\\mathbb R} tels que, pour entier n, on a \nu_{n+2} = a u_{n+1} + b u_n  + f(n).\n L’équation \\displaystyle u_{n+2} = a u_{n+1} + b u_n s’appelle alors l’équation homogène associée. Les solutions de l’équation avec second membre sont la somme de la solution générique de l’équation homogène et d’une solution particulière de l’équation avec second membre.En effet, il est clair que d_a=d_b=0, et si a&lt;x&lt;b, alors on a d_x=\\mathbb{E}(T_a\\wedge T_b). Attention, la variable aléatoire T_a\\wedge T_b est à valeurs dans \\mathbb{N}\\cup\\{+\\infty\\}. Si \\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x)&gt;0, alors \\mathbb{E}(T_a\\wedge T_b)=+\\infty. Par ailleurs, partant de x+1, on a \\begin{align*}\n\\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x+1)&\\geq \\mathbb{P}(T_a\\wedge T_b=+\\infty, S_1=x|S_0=x+1)\\\\\n&= \\mathbb{P}(T_a\\wedge T_b=+\\infty|S_1=x,S_0=x+1)\\mathbb{P}(S_1=x|S_0=x+1)\\\\\n&=\\frac{1}{2}\\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x)\n\\end{align*} par les propriétés de Markov et de stationnarité. Donc \\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x+1)&gt;0. Ainsi, les membres de gauche et de droite de l’équation d_x=\\frac{1}{2}(d_{x+1}+d_{x-1})+1 valent tous les deux +\\infty, et l’égalité est vraie. On montrerait de même que \\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x)&gt;0 implique \\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x-1)&gt;0, et par contraposée et décalage d’indices que \\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x)=0 implique \\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x+1)=\\mathbb{P}(T_a\\wedge T_b=+\\infty|S_0=x-1)=0. Plaçons nous dans ce dernier cas. On a donc \\begin{align*}\nd_x&=\\mathbb{E}(T_a\\wedge T_b)\\\\\n&=\\sum_{k=1}^\\infty k \\mathbb{P}(T_a\\wedge T_b=k|S_0=x)\\\\\n&=\\sum_{k=1}^\\infty k \\big(\\mathbb{P}(T_a\\wedge T_b=k|S_1=x+1)\\mathbb{P}(S_1=x+1)+\\mathbb{P}(T_a\\wedge T_b=k|S_1=x-1)\\mathbb{P}(S_1=x-1)\\big)\\\\\n&=\\frac{1}{2}\\sum_{k=1}^\\infty k \\mathbb{P}(T_a\\wedge T_b=k-1|S_0=x+1)+\\frac{1}{2}\\sum_{k=1}^\\infty k\\mathbb{P}(T_a\\wedge T_b=k-1|S_0=x-1)\\\\\n&=\\frac{1}{2}\\sum_{j=0}^\\infty (j+1) \\mathbb{P}(T_a\\wedge T_b=j|S_0=x+1)+\\frac{1}{2}\\sum_{j=0}^\\infty (j+1)\\mathbb{P}(T_a\\wedge T_b=j|S_0=x-1)\\\\\n&=\\frac{1}{2}\\sum_{j=0}^\\infty j \\mathbb{P}(T_a\\wedge T_b=j|S_0=x+1)+\\frac{1}{2}\\sum_{j=0}^\\infty j\\mathbb{P}(T_a\\wedge T_b=j|S_0=x-1)+1\\\\\n&=1+\\frac{1}{2}\\mathbb{E}(T_a\\wedge T_b|S_0=x+1)+\\frac{1}{2}\\mathbb{E}(T_a\\wedge T_b|S_0=x-1)\\\\\n&=1+\\frac{1}{2}(d_{x+1}+d_{x-1}).\n\\end{align*} % Cherchons une solution particulière sous la forme cn^2 (puisque les constantes et les multiples de n sont solutions de l’équation homogène) : \\begin{align*}\ncn^2=\\frac{1}{2}(c(n+1)^2+c(n-1)^2)+1\n&\\Leftrightarrow\ncn^2=\\frac{1}{2}(cn^2+c+2cn+cn^2+c-2cn)+1\\\\\n&\\Leftrightarrow\ncn^2=cn^2+c+1\\\\\n&\\Leftrightarrow\nc=-1.\n\\end{align*} % Ansi, d est la somme d’une solution homogène et d’une solution particulière, donc d_x=\\alpha +\\beta x-x^2. En utilisant d_a=d_b=0, on trouve \\alpha et \\beta \\begin{align*}\n\\left\\{\\begin{array}{rcl}\nd_a=0&=&\\alpha+\\beta a-a^2\\\\\nd_b=0&=&\\alpha+\\beta b-b^2\n\\end{array}\n\\right.\n\\Leftrightarrow\n\\left\\{\\begin{array}{rcl}\n\\alpha&=-ab,\\\\\n\\beta&=a+b.\n\\end{array}\n\\right.\n\\end{align*} Finalement, on obtient que d_x=-ab+x(a+b)-x^2.\nEn particulier, si x=0 et b tend vers -\\infty, on obtient que \\mathbb{E}[T_a]=+\\infty. On sait que la marche partant de 0 atteindra a presque sûrement en temps fini, cependant ce temps est en moyenne infini.",
    "crumbs": [
      "Cours",
      "Marches aléatoires"
    ]
  },
  {
    "objectID": "Courses/marche_aleatoire.html#sec-chap03-MB",
    "href": "Courses/marche_aleatoire.html#sec-chap03-MB",
    "title": "Marches aléatoires",
    "section": "De la marche aléatoire vers le mouvement brownien",
    "text": "De la marche aléatoire vers le mouvement brownien\nOn s’intéresse maintenant à une autre forme de comportement asymptotique de la marche aléatoire. Nous allons la renormaliser pour la contraindre à rester dans l’intervalle de temps [0,1]. Pour cela, pour tout N\\in\\mathbb{N}^*, on pose \nB^N_t  =\\frac{1}{\\sqrt{N}} S_{\\lfloor Nt \\rfloor} = \\frac{1}{\\sqrt{N}} \\sum_{k=1}^{\\lfloor Nt \\rfloor} X_k.\n\nAlors la suite (B^N_t) converge en loi lorsque N tend vers l’infini, et c’est également le cas lorsqu’on prend plusieurs temps t_i.\n\nProposition 11 Pour tous t_0=0&lt;t_1 &lt;\\dots&lt; t_p, le vecteur (B^N_{t_1},\\dots,B^N_{t_p}) converge en loi vers un vecteur (B_{t_1},\\dots,B_{t_p}) tel que pour tout i \\in\\{1,\\dots,p\\}, B_{t_{i}}-B_{t_{i-1}} est indépendant de B_{t_{i-1}} et suit une loi normale \\mathcal{N}(0, t_i - t_{i-1} )\n\n\nPreuve. On a \nB^N_{t_i} - B^N_{t_{i-1}}  =\\frac{1}{\\sqrt{N}} S_{\\lfloor Nt \\rfloor} = \\frac{1}{\\sqrt{N}} \\sum_{k=\\lfloor N t_{i-1} \\rfloor + 1}^{\\lfloor N t_i \\rfloor} X_k\n donc les accroissements du vecteur (B^N_{t_1},\\dots,B^N_{t_p}) sont indépendant. Il suffit maintenant de montrer qu’ils convergent vers la loi normale. On a \nB^N_{t_i} - B^N_{t_{i-1}}  = \\sqrt{\\frac{\\lfloor N t_i \\rfloor - \\lfloor N t_{i-1} \\rfloor }{N}}  \\frac{1}{\\sqrt{\\lfloor N t_i \\rfloor - \\lfloor N t_{i-1} \\rfloor }} \\sum_{k=\\lfloor N t_{i-1} \\rfloor + 1}^{\\lfloor N t_i \\rfloor}   X_k \\to \\sqrt{t_i - t_{i-1}} \\mathcal{N}(0,1),\n par le théorème central limite appliqué à la suite (X_k).\n\nCe résultat permet de poser la définition suivante.\n\nDéfinition 3 (Mouvement Brownien) On appelle mouvement Brownien standard, tout processus (B_t)_{t\\geq 0} satisfaisant les trois points suivants\n\nB_0=0,\n\\forall t\\geq s, B_{t} - B_s indepandant de (B_r)_{r \\leq s},\n\\forall t\\geq s, B_{t} - B_s \\sim \\mathcal{N}(0, t-s).\n\n\nLe théorème précédent ne donne pas l’existence d’un tel processus, mais si un tel processus existe, il donne la convergence des lois marginales fini-dimensionnelles de la marche aléatoire renormalisée vers les lois marginales fini-dimensionnelles du mouvement Brownien. On admettra qu’il existe bien un mouvement Brownien. On peut montrer que la marche aléatoire converge pour la norme infinie vers le mouvement Brownien dans l’espace des variables aléatoires à valeurs dans les fonctions continues de [0,1] dans \\R. Ce résultat est connu sous le nom de théorème de Donsker. Pour simuler un mouvement Brownien, on simule en fait une marche aléatoire et on la renormalise comme ci-dessus avec N assez grand.",
    "crumbs": [
      "Cours",
      "Marches aléatoires"
    ]
  },
  {
    "objectID": "Courses/loi_normale1D.html",
    "href": "Courses/loi_normale1D.html",
    "title": "Loi normale: cas univarié",
    "section": "",
    "text": "On rappelle que la loi normale de paramètres \\mu \\in \\mathbb{R} et \\nu &gt; 0 a une densité donnée pour tout x \\in \\mathbb{R} par \n    \\varphi_{\\mu, \\nu}(x)=\\frac{1}{\\sqrt{2 \\pi \\nu}}\\exp\\Big(-\\frac{(x-\\mu)^2}{2\\nu}\\Big)\\enspace.\n\nOn note X \\sim \\mathcal{N}(\\mu, \\nu), si X est une variable aléatoire ayant pour densité \\varphi_{\\mu, \\nu}. Notons que si X \\sim \\mathcal{N}(\\mu,\\nu), alors X a pour espérance \\mu et pour variance \\nu. Le cas particulier \\mu=0 et \\nu=1 correspond à une variable aléatoire dite centrée réduite.\nPlotly = require('plotly.js-dist');\ndists = require( 'https://cdn.jsdelivr.net/gh/stdlib-js/stats-base-dists@umd/browser.js' );\njstat = require('jstat');\nmath = require(\"mathjs\");\n// see source here: https://github.com/stdlib-js/stats-base-dists/tree/umd\n// continuous case\n\nviewof inputs = Inputs.form([\n  Inputs.range([-2, 2], {label: tex`\\mu`, step: 0.1}, {value: 0}),\n  Inputs.range([0.1, 10], {label: tex`\\nu`, step: 0.1, value: 1}),\n  Inputs.range([1, 1000], {label: tex`n`, step: 1}),\n  Inputs.button(\"Re-Tirage\")\n])\n\nmu = inputs[0];\nnu = inputs[1];\nn_samples = inputs[2];\n\n{\n\nfunction mvnpdf(x, mu, nu){\n    return 1.0 / (2*math.pi *nu)**(0.5)* math.exp(-0.5*(x-mu)**2 / nu);\n}\n\n\nfunction normal_rng(mu, nu, n=100){\n    var samples = Array.from({length: n}, () =&gt; {\n        var x = jstat.normal.sample(mu, nu**0.5);\n        return x;\n    });\n\n    return samples;\n}\n\nvar samples = normal_rng(mu, nu, 1000);\nvar samples_jitter = normal_rng(0, 0.03, 1000);\nvar npoints=500, mini = -10, maxi=10, x = new Array(npoints), z = new Array(npoints), i, j;\n\n//  Densité:s\nfor(var i = 0; i &lt; npoints; i++) {\n    x[i] = mini + i * (maxi - mini) / (npoints - 1);\n    z[i] = mvnpdf(x[i], mu, nu);\n    }\n\n{\nvar trace1 = {\n        x: samples.slice(0, n_samples),\n        y: samples_jitter.slice(0, n_samples),\n        mode: 'markers',\n        type: 'scatter',\n        marker: {\n            color: 'rgba(0,0,0,0.5)',\n            size: 5,\n        },\n\n  }\n\nvar trace22 = {\n        x: x,\n        y: z,\n        type: \"scatter\",\n        mode: \"lines\",\n        name: 'Pdf',\n        line: {color: 'black'},\n        yaxis: 'y2',\n        xaxis: 'x2',\n        }\n\n\nvar data = [\n  trace1,\n  trace22,\n  ];\n\n\nvar layout = {\n    width: 600,\n    yaxis: {domain: [0, 0.2],\n            showticklabels: false,\n            range: [-0.6, 0.6],\n            autorange: false},\n    xaxis2: {matches: 'x',\n              range: [-10, 10],\n          autorange: false},\n    yaxis2: {domain: [0.29, 0.99]},\n\n  showlegend: false,\n\n};\n\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.react(div, data, layout, config);\n    return div;\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn parle aussi souvent de loi gaussienne, en hommage au mathématicien Carl Friedrich Gauss, le prince des mathématiciens1.\n1 Carl Friedrich Gauss: (1777-1855) mathématicien, astronome et physicien né à Brunswick, directeur de l’observatoire de Göttingen de 1807 jusqu’à sa mort en 1855 La loi normale vérifie la propriété de stabilité par transformation affine : si X \\sim \\mathcal{N}(\\mu, \\nu) et si (a,b) \\in \\mathbb{R}^* \\times \\mathbb{R}, alors la variable aléatoire a X + b suit une loi normale \\mathcal{N}(a\\mu + b, a^2 \\nu). On peut donc facilement passer d’une loi normale centrée réduite à une loi normale quelconque via une transformation affine :\n\nsi X \\sim \\mathcal{N}(0,1), alors \\sqrt{\\nu} X + \\mu \\sim \\mathcal{N}(\\mu, \\nu),\nsi X \\sim \\mathcal{N}(\\mu, \\nu), alors (X-\\mu)/\\sqrt{\\nu} \\sim \\mathcal{N}(0,1).\n\nAinsi, savoir simuler une loi normale centrée réduite, permet de simuler n’importe quelle loi normale.\n\nProposition 1 (Fonction caractéristique de la loi normale) La fonction caractéristique d’une variable aléatoire X \\sim \\mathcal{N}(\\mu, \\nu) est donnée pour tout t \\in \\mathbb{R} par \n\\begin{align*}\n\\phi_{\\mu,\\nu}(t) & \\triangleq \\mathbb{E}(e^{i t X})  \\\\\n& = \\exp\\Big( i \\mu t - \\frac{\\nu t^2}{2}\\Big)\\enspace.\n\\end{align*}\n\n\n\nPreuve. on remarque d’abord que si X \\sim \\mathcal{N}(0,1) alors pour tout z \\in \\mathbb{R}, on a\n\n\\begin{align*}\n\\mathbb{E}[e^{zX}]&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12x^2}e^{zx}\\,dx\\\\\n&= \\frac{e^{\\frac12z^2}}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12(x-z)^2}\\,dx\\\\\n&=\\frac{e^{\\frac12z^2}}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12y^2}\\,dy\\\\\n&=e^{\\frac12z^2}.\n\\end{align*}\n En utilisant le théorème de prolongement analytique (voir par exemple (Théorème I.10., Queffélec et Zuily 2013) on peut donc étendre cette formule à tout z \\in \\mathbb{C}, et particulier au cas z=it pour t \\in \\mathbb{R}. On obtient alors \\phi_{\\mu,\\nu}(t)=e^{-\\frac{t^2}{2}}. Enfin, on utilise la linéarité de l’espérance pour obtenir le résultat pour X \\sim \\mathcal{N}(\\mu,\\nu). En effet, si X \\sim \\mathcal{N}(0,1), alors X=\\mu+\\sqrt{\\nu}Z avec Z \\sim \\mathcal{N}(0,1), et donc \\phi_{\\mu,\\nu}(t)=e^{i\\mu t}\\phi_{0,1}(\\sqrt{\\nu}t)=e^{i\\mu t-\\frac{\\nu t^2}{2}}.\n\nQueffélec, H., et C. Zuily. 2013. Analyse pour l’agrégation. Dunod.\n\n\n\n\n\n\n\n\n\nUne mauvaise piste pour simuler une loi normale\n\n\n\nOn peut simuler une loi normale à partir de variables aléatoires uniformes U_1, \\dots, U_n iid en appliquant le théorème central limite à \n    \\frac{U_1 + \\cdots + U_n - n/2}{\\sqrt{n/12}}\\,.\n Cependant, cette méthode ne donne qu’une approximation d’une loi normale. Par ailleurs, la vitesse de convergence étant relativement lente (de l’ordre de \\sqrt n), il faudra simuler beaucoup de variables aléatoires uniformes pour avoir une approximation correcte, ce qui demande un temps de calcul assez élevé.\n\n\n\n\nLe théorème suivant permet de passer de la loi d’un couple (X,Y) à celle de (U,V) = \\phi(X,Y), où \\phi est un C^1-difféomorphisme, c’est-à-dire une application bijective dont la réciproque est également de classe C^1.\nPour cela rappelons que la jacobienne de \\phi^{-1} correspond à la matrice (application linéaire) des dérivées partielles. Ainsi, si \\phi(x,y) = (u,v) \\iff (x,y) = \\phi^{-1}(u,v), alors \n\\begin{align*}\n{\\rm{J}}_{\\phi^{-1}}: (u,v) & \\mapsto\n\\begin{pmatrix}\n  \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v}    \\\\\n  \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}\n\\end{pmatrix} \\enspace.\n\\end{align*}\n\n\nThéorème 1 (Caractérisation de la loi d’une variable aléatoire réelle) Soit (X,Y) un vecteur aléatoire de densité f_{(X,Y)} définie sur l’ouvert A \\subset \\mathbb{R}^2 et \\phi : A \\to B \\subset \\mathbb{R}^2 un C^1-difféomorphisme. Le vecteur aléatoire (U,V)=\\phi(X,Y) admet alors pour densité f_{(U,V)} définie sur B pour tout (u,v) \\in \\mathbb{R}^2 par \n\\begin{align*}\n    (u,v) & \\mapsto\n    f_{(X,Y)} (\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| {1\\hspace{-3.8pt} 1}_B(u,v)\\enspace.\n\\end{align*}\n\n\nOn a énoncé le résultat en dimension 2 par simplicité. Il s’étend bien évidemment à une dimension d quelconque. En particulier, pour d=1, on retrouve le changement de variable classique dans le cas de l’intégration d’une fonction à valeurs réelles.\n\nPreuve. On rappelle que la loi de (U,V) est caractérisée par les quantités \\mathbb{E}[h(U,V)] pour tout h : \\mathbb{R}^2 \\to \\mathbb{R} mesurable bornée. On considère donc une telle fonction h et on applique la formule de transfert : \n\\begin{align*}\n  \\mathbb{E}[h(U,V)] &\n  =\\mathbb{E}[h(\\phi(X,Y))]\\\\\n& = \\int_{\\mathbb{R}^2} h(\\phi(x,y)) f_{(X,Y)}(x,y) \\, dx dy \\\\\n& = \\int_{A} h(\\phi(x,y)) f_{(X,Y)}(x,y) \\, d x d y\\enspace.\n\\end{align*}\n On applique alors la formule du changement de variables vu en théorie de l’intégration avec (u,v) = \\phi(x,y) \\iff \\phi^{-1}(u,v) = (x,y) : \n\\begin{align*}\n  & \\mathbb{E}[h(U,V)]\\\\\n  & = \\!\\int_{B}  \\!\\!\\! h(u,v) f_{(X,Y)}(\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| \\, d u d v\\\\\n  & = \\!\\int_{\\mathbb{R}^2} \\!\\!\\!\\! h(u,v) f_{(X,Y)}(\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| {1\\hspace{-3.8pt} 1}_B(u,v)\\, d u d v .\n\\end{align*}\n  ce qui donne le résultat voulu.\n\n\n\nExemple 1 (Exemple : loi de \\cos(X), avec X \\sim \\mathcal{U}(]0,\\pi[)) Donnons un exemple dans le cas réel. On considère une variable aléatoire X de loi uniforme sur ]0,\\pi[. Sa densité est donnée par f_X(x) = {1\\hspace{-3.8pt} 1}_{]0,\\pi[}(x)/\\pi. On pose U = \\cos(X) et on souhaite déterminer la loi de U.\nOn applique le théorème précédent avec la fonction \\phi^{-1}(u) = \\arccos(u) sur ]-1,1[. La densité de U est alors donnée pour tout u \\in \\mathbb{R} par \n\\begin{align*}\n  f_U(u)\n& = \\frac{{1\\hspace{-3.8pt} 1}_{]0,\\pi[}(\\arccos(u))}{\\pi} \\Big| \\frac{-1}{\\sqrt{1-u^2}} \\Big| {1\\hspace{-3.8pt} 1}_{]-1,1[}(u)\\\\\n& = \\frac{1}{\\pi \\sqrt{1-u^2}} {1\\hspace{-3.8pt} 1}_{]-1,1[}(u)\\enspace.\n\\end{align*}",
    "crumbs": [
      "Cours",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale1D.html#définitions-et-propriétés-de-la-loi-normale",
    "href": "Courses/loi_normale1D.html#définitions-et-propriétés-de-la-loi-normale",
    "title": "Loi normale: cas univarié",
    "section": "",
    "text": "On rappelle que la loi normale de paramètres \\mu \\in \\mathbb{R} et \\nu &gt; 0 a une densité donnée pour tout x \\in \\mathbb{R} par \n    \\varphi_{\\mu, \\nu}(x)=\\frac{1}{\\sqrt{2 \\pi \\nu}}\\exp\\Big(-\\frac{(x-\\mu)^2}{2\\nu}\\Big)\\enspace.\n\nOn note X \\sim \\mathcal{N}(\\mu, \\nu), si X est une variable aléatoire ayant pour densité \\varphi_{\\mu, \\nu}. Notons que si X \\sim \\mathcal{N}(\\mu,\\nu), alors X a pour espérance \\mu et pour variance \\nu. Le cas particulier \\mu=0 et \\nu=1 correspond à une variable aléatoire dite centrée réduite.\nPlotly = require('plotly.js-dist');\ndists = require( 'https://cdn.jsdelivr.net/gh/stdlib-js/stats-base-dists@umd/browser.js' );\njstat = require('jstat');\nmath = require(\"mathjs\");\n// see source here: https://github.com/stdlib-js/stats-base-dists/tree/umd\n// continuous case\n\nviewof inputs = Inputs.form([\n  Inputs.range([-2, 2], {label: tex`\\mu`, step: 0.1}, {value: 0}),\n  Inputs.range([0.1, 10], {label: tex`\\nu`, step: 0.1, value: 1}),\n  Inputs.range([1, 1000], {label: tex`n`, step: 1}),\n  Inputs.button(\"Re-Tirage\")\n])\n\nmu = inputs[0];\nnu = inputs[1];\nn_samples = inputs[2];\n\n{\n\nfunction mvnpdf(x, mu, nu){\n    return 1.0 / (2*math.pi *nu)**(0.5)* math.exp(-0.5*(x-mu)**2 / nu);\n}\n\n\nfunction normal_rng(mu, nu, n=100){\n    var samples = Array.from({length: n}, () =&gt; {\n        var x = jstat.normal.sample(mu, nu**0.5);\n        return x;\n    });\n\n    return samples;\n}\n\nvar samples = normal_rng(mu, nu, 1000);\nvar samples_jitter = normal_rng(0, 0.03, 1000);\nvar npoints=500, mini = -10, maxi=10, x = new Array(npoints), z = new Array(npoints), i, j;\n\n//  Densité:s\nfor(var i = 0; i &lt; npoints; i++) {\n    x[i] = mini + i * (maxi - mini) / (npoints - 1);\n    z[i] = mvnpdf(x[i], mu, nu);\n    }\n\n{\nvar trace1 = {\n        x: samples.slice(0, n_samples),\n        y: samples_jitter.slice(0, n_samples),\n        mode: 'markers',\n        type: 'scatter',\n        marker: {\n            color: 'rgba(0,0,0,0.5)',\n            size: 5,\n        },\n\n  }\n\nvar trace22 = {\n        x: x,\n        y: z,\n        type: \"scatter\",\n        mode: \"lines\",\n        name: 'Pdf',\n        line: {color: 'black'},\n        yaxis: 'y2',\n        xaxis: 'x2',\n        }\n\n\nvar data = [\n  trace1,\n  trace22,\n  ];\n\n\nvar layout = {\n    width: 600,\n    yaxis: {domain: [0, 0.2],\n            showticklabels: false,\n            range: [-0.6, 0.6],\n            autorange: false},\n    xaxis2: {matches: 'x',\n              range: [-10, 10],\n          autorange: false},\n    yaxis2: {domain: [0.29, 0.99]},\n\n  showlegend: false,\n\n};\n\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.react(div, data, layout, config);\n    return div;\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn parle aussi souvent de loi gaussienne, en hommage au mathématicien Carl Friedrich Gauss, le prince des mathématiciens1.\n1 Carl Friedrich Gauss: (1777-1855) mathématicien, astronome et physicien né à Brunswick, directeur de l’observatoire de Göttingen de 1807 jusqu’à sa mort en 1855 La loi normale vérifie la propriété de stabilité par transformation affine : si X \\sim \\mathcal{N}(\\mu, \\nu) et si (a,b) \\in \\mathbb{R}^* \\times \\mathbb{R}, alors la variable aléatoire a X + b suit une loi normale \\mathcal{N}(a\\mu + b, a^2 \\nu). On peut donc facilement passer d’une loi normale centrée réduite à une loi normale quelconque via une transformation affine :\n\nsi X \\sim \\mathcal{N}(0,1), alors \\sqrt{\\nu} X + \\mu \\sim \\mathcal{N}(\\mu, \\nu),\nsi X \\sim \\mathcal{N}(\\mu, \\nu), alors (X-\\mu)/\\sqrt{\\nu} \\sim \\mathcal{N}(0,1).\n\nAinsi, savoir simuler une loi normale centrée réduite, permet de simuler n’importe quelle loi normale.\n\nProposition 1 (Fonction caractéristique de la loi normale) La fonction caractéristique d’une variable aléatoire X \\sim \\mathcal{N}(\\mu, \\nu) est donnée pour tout t \\in \\mathbb{R} par \n\\begin{align*}\n\\phi_{\\mu,\\nu}(t) & \\triangleq \\mathbb{E}(e^{i t X})  \\\\\n& = \\exp\\Big( i \\mu t - \\frac{\\nu t^2}{2}\\Big)\\enspace.\n\\end{align*}\n\n\n\nPreuve. on remarque d’abord que si X \\sim \\mathcal{N}(0,1) alors pour tout z \\in \\mathbb{R}, on a\n\n\\begin{align*}\n\\mathbb{E}[e^{zX}]&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12x^2}e^{zx}\\,dx\\\\\n&= \\frac{e^{\\frac12z^2}}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12(x-z)^2}\\,dx\\\\\n&=\\frac{e^{\\frac12z^2}}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-\\frac12y^2}\\,dy\\\\\n&=e^{\\frac12z^2}.\n\\end{align*}\n En utilisant le théorème de prolongement analytique (voir par exemple (Théorème I.10., Queffélec et Zuily 2013) on peut donc étendre cette formule à tout z \\in \\mathbb{C}, et particulier au cas z=it pour t \\in \\mathbb{R}. On obtient alors \\phi_{\\mu,\\nu}(t)=e^{-\\frac{t^2}{2}}. Enfin, on utilise la linéarité de l’espérance pour obtenir le résultat pour X \\sim \\mathcal{N}(\\mu,\\nu). En effet, si X \\sim \\mathcal{N}(0,1), alors X=\\mu+\\sqrt{\\nu}Z avec Z \\sim \\mathcal{N}(0,1), et donc \\phi_{\\mu,\\nu}(t)=e^{i\\mu t}\\phi_{0,1}(\\sqrt{\\nu}t)=e^{i\\mu t-\\frac{\\nu t^2}{2}}.\n\nQueffélec, H., et C. Zuily. 2013. Analyse pour l’agrégation. Dunod.\n\n\n\n\n\n\n\n\n\nUne mauvaise piste pour simuler une loi normale\n\n\n\nOn peut simuler une loi normale à partir de variables aléatoires uniformes U_1, \\dots, U_n iid en appliquant le théorème central limite à \n    \\frac{U_1 + \\cdots + U_n - n/2}{\\sqrt{n/12}}\\,.\n Cependant, cette méthode ne donne qu’une approximation d’une loi normale. Par ailleurs, la vitesse de convergence étant relativement lente (de l’ordre de \\sqrt n), il faudra simuler beaucoup de variables aléatoires uniformes pour avoir une approximation correcte, ce qui demande un temps de calcul assez élevé.\n\n\n\n\nLe théorème suivant permet de passer de la loi d’un couple (X,Y) à celle de (U,V) = \\phi(X,Y), où \\phi est un C^1-difféomorphisme, c’est-à-dire une application bijective dont la réciproque est également de classe C^1.\nPour cela rappelons que la jacobienne de \\phi^{-1} correspond à la matrice (application linéaire) des dérivées partielles. Ainsi, si \\phi(x,y) = (u,v) \\iff (x,y) = \\phi^{-1}(u,v), alors \n\\begin{align*}\n{\\rm{J}}_{\\phi^{-1}}: (u,v) & \\mapsto\n\\begin{pmatrix}\n  \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v}    \\\\\n  \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}\n\\end{pmatrix} \\enspace.\n\\end{align*}\n\n\nThéorème 1 (Caractérisation de la loi d’une variable aléatoire réelle) Soit (X,Y) un vecteur aléatoire de densité f_{(X,Y)} définie sur l’ouvert A \\subset \\mathbb{R}^2 et \\phi : A \\to B \\subset \\mathbb{R}^2 un C^1-difféomorphisme. Le vecteur aléatoire (U,V)=\\phi(X,Y) admet alors pour densité f_{(U,V)} définie sur B pour tout (u,v) \\in \\mathbb{R}^2 par \n\\begin{align*}\n    (u,v) & \\mapsto\n    f_{(X,Y)} (\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| {1\\hspace{-3.8pt} 1}_B(u,v)\\enspace.\n\\end{align*}\n\n\nOn a énoncé le résultat en dimension 2 par simplicité. Il s’étend bien évidemment à une dimension d quelconque. En particulier, pour d=1, on retrouve le changement de variable classique dans le cas de l’intégration d’une fonction à valeurs réelles.\n\nPreuve. On rappelle que la loi de (U,V) est caractérisée par les quantités \\mathbb{E}[h(U,V)] pour tout h : \\mathbb{R}^2 \\to \\mathbb{R} mesurable bornée. On considère donc une telle fonction h et on applique la formule de transfert : \n\\begin{align*}\n  \\mathbb{E}[h(U,V)] &\n  =\\mathbb{E}[h(\\phi(X,Y))]\\\\\n& = \\int_{\\mathbb{R}^2} h(\\phi(x,y)) f_{(X,Y)}(x,y) \\, dx dy \\\\\n& = \\int_{A} h(\\phi(x,y)) f_{(X,Y)}(x,y) \\, d x d y\\enspace.\n\\end{align*}\n On applique alors la formule du changement de variables vu en théorie de l’intégration avec (u,v) = \\phi(x,y) \\iff \\phi^{-1}(u,v) = (x,y) : \n\\begin{align*}\n  & \\mathbb{E}[h(U,V)]\\\\\n  & = \\!\\int_{B}  \\!\\!\\! h(u,v) f_{(X,Y)}(\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| \\, d u d v\\\\\n  & = \\!\\int_{\\mathbb{R}^2} \\!\\!\\!\\! h(u,v) f_{(X,Y)}(\\phi^{-1}(u,v)) |\\det ({\\rm{J}}_{\\phi^{-1}} (u,v))| {1\\hspace{-3.8pt} 1}_B(u,v)\\, d u d v .\n\\end{align*}\n  ce qui donne le résultat voulu.\n\n\n\nExemple 1 (Exemple : loi de \\cos(X), avec X \\sim \\mathcal{U}(]0,\\pi[)) Donnons un exemple dans le cas réel. On considère une variable aléatoire X de loi uniforme sur ]0,\\pi[. Sa densité est donnée par f_X(x) = {1\\hspace{-3.8pt} 1}_{]0,\\pi[}(x)/\\pi. On pose U = \\cos(X) et on souhaite déterminer la loi de U.\nOn applique le théorème précédent avec la fonction \\phi^{-1}(u) = \\arccos(u) sur ]-1,1[. La densité de U est alors donnée pour tout u \\in \\mathbb{R} par \n\\begin{align*}\n  f_U(u)\n& = \\frac{{1\\hspace{-3.8pt} 1}_{]0,\\pi[}(\\arccos(u))}{\\pi} \\Big| \\frac{-1}{\\sqrt{1-u^2}} \\Big| {1\\hspace{-3.8pt} 1}_{]-1,1[}(u)\\\\\n& = \\frac{1}{\\pi \\sqrt{1-u^2}} {1\\hspace{-3.8pt} 1}_{]-1,1[}(u)\\enspace.\n\\end{align*}",
    "crumbs": [
      "Cours",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale1D.html#méthode-de-box-müller",
    "href": "Courses/loi_normale1D.html#méthode-de-box-müller",
    "title": "Loi normale: cas univarié",
    "section": "Méthode de Box-Müller",
    "text": "Méthode de Box-Müller\nUn cas particulier fondamental de la formule de changement de variables concerne le passage en coordonnées polaires. Cette transformation est définie via l’application \n    \\begin{array}{ccccc}\n        \\phi^{-1} & : & ]0, \\infty[ \\times ]0, 2\\pi[ & \\to   & \\mathbb{R}^2 \\setminus ([0,\\infty[ \\times \\{0\\}) \\\\\n                  &   & \\begin{pmatrix} r \\\\ \\theta \\end{pmatrix}                   & \\mapsto & \\begin{pmatrix} r \\cos(\\theta) \\\\ r \\sin(\\theta) \\end{pmatrix}\\,.\n    \\end{array}\n L’expression de \\phi ne nous sera pas utile. On peut tout de même la donner au passage :\n\n    \\begin{array}{ccccc}\n        \\phi & : & \\mathbb{R}^2 \\setminus ([0,\\infty[ \\times \\{0\\}) & \\to     & ]0, \\infty[ \\times ]0, 2\\pi[                                                      \\\\\n             &   & \\begin{pmatrix} x \\\\ y \\end{pmatrix}                                            & \\mapsto & \\begin{pmatrix}\\sqrt{x^2+y^2} \\\\ 2 \\arctan \\Big( \\frac{y}{x+\\sqrt{x^2+y^2}} \\Big)\\end{pmatrix}\\,.\n    \\end{array}\n\nIci, le jacobien de \\phi^{-1} est la matrice \n    {\\rm{J}}_{\\phi^{-1}} (r,\\theta)\n    =\n    \\begin{pmatrix}\n        \\cos(\\theta) & -r \\sin(\\theta) \\\\\n        \\sin(\\theta) & r \\cos(\\theta)\n    \\end{pmatrix}\\,,\n qui vérifie |\\det({\\rm{J}}_{\\phi^{-1}} (r, \\theta))| = r. Ainsi, si (X,Y) a pour densité f_{(X,Y)}, alors (R, \\Theta) = \\phi(X,Y) a pour densité \n  f_{(R, \\Theta)} (r, \\theta)\n  = r\\cdot f_{(X,Y)}(r \\cos(\\theta), r \\sin(\\theta)) \\!\\cdot\\! {1\\hspace{-3.8pt} 1}_{]0, \\infty[}(r)  {1\\hspace{-3.8pt} 1}_{]0, 2 \\pi[}(\\theta).\n\nDans le cas où X et Y sont des variables aléatoires gaussiennes indépendantes, on obtient le résultat suivant.\n\nThéorème 2 (Méthode de Box-Müller) Soit X et Y deux variables aléatoires indépendantes de loi normales centrées réduites : X,Y \\sim \\mathcal{N}(0,1). Le couple de variables aléatoires polaires (R, \\Theta) = \\phi(X,Y) a pour densité \n            f_{R, \\Theta}(r,\\theta)\n            = \\Big( r \\cdot e^{-\\tfrac{r^2}{2}} {1\\hspace{-3.8pt} 1}_{]0, \\infty[}(r) \\Big) \\bigg(\\frac{{1\\hspace{-3.8pt} 1}_{]0, 2 \\pi[}(\\theta)}{2 \\pi} \\bigg)\\,.\n Autrement dit, elles sont indépendantes, l’angle \\Theta suit une loi uniforme sur ]0, 2\\pi[ et la distance à l’origine R suit une loi de Rayleigh donnée par la densité \n    f_R(r) =  r \\cdot e^{-r^2/2} {1\\hspace{-3.8pt} 1}_{]0, \\infty[}(r)\\,, \\quad r &gt; 0\\,.\n\n\n\nPreuve. La densité du couple (X,Y) est donnée par \n  f_{(X,Y)}(x,y) = \\frac{1}{2\\pi} e^{-\\frac{x^2+y^2}{2}}\\,, \\quad x,y \\in \\mathbb{R}\\,.\n Le théorème précédent donne alors la densité de (R, \\Theta) : \n\\begin{align*}\n  f_{(R, \\Theta)} (r, \\theta) &\n  = r\\cdot f_{(X,Y)}(r \\cos(\\theta), r \\sin(\\theta)) \\!\\cdot\\! {1\\hspace{-3.8pt} 1}_{]0, \\infty[}(r)  {1\\hspace{-3.8pt} 1}_{]0, 2 \\pi[}(\\theta)\\\\\n  &= r \\cdot\\frac{1}{2\\pi} e^{-\\frac{r^2}{2}} \\cdot  {1\\hspace{-3.8pt} 1}_{]0, \\infty[}(r) {1\\hspace{-3.8pt} 1}_{]0, 2 \\pi[}(\\theta)\\,,\n\\end{align*}\n ce qui conclut la preuve.\n\nSi R suit une loi de Rayleigh alors \\sqrt{-2 \\log(U)} a la même loi que R, où U est une variable aléatoire de loi uniforme sur ]0,1[: Pour cela il suffit de remarquer que pour tout x &gt; 0, F_R(x)=\\mathbb{P}(R\\leq x) = 1-\\exp(-\\tfrac{x^2}{2}), et donc que pour tout q \\in ]0,1[, F_R^{^\\leftarrow}(q)=\\sqrt{-2\\log(1-q)} et donc \\sqrt{-2\\log(1-U)}, puis \\sqrt{-2\\log(U)} on donc la même loi que R.\nL’algorithme de Box-Müller s’en suit: si U et V sont des v.a. indépendantes de loi uniforme sur [0,1] et qu’on définit X et Y par \n\\begin{cases}\n  X = \\sqrt{-2 \\log(U)} \\cos(2\\pi V)\\\\\n  Y = \\sqrt{-2 \\log(U)} \\sin(2\\pi V)\\,.\n\\end{cases}\n alors X et Y des variables aléatoires gaussiennes centrées réduites indépendantes.\n\n\n\n\n\n\nNote\n\n\n\nCet algorithme n’est en fait pas souvent utilisé en pratique : il fait appel à des fonctions dont l’évaluation est coûteuse (logarithme, cosinus, sinus). Pour s’affranchir des fonctions trigonométriques, une version modifiée de l’algorithme de Box-Müller a été proposée : la méthode de Marsaglia, qui s’appuie sur des variables aléatoires uniformes sur le disque unité (voir l’exercice dédié en TD). Une autre alternative est la méthode de Ziggurat.",
    "crumbs": [
      "Cours",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale1D.html#lois-autour-de-la-loi-normale",
    "href": "Courses/loi_normale1D.html#lois-autour-de-la-loi-normale",
    "title": "Loi normale: cas univarié",
    "section": "Lois autour de la loi normale",
    "text": "Lois autour de la loi normale\n\nLoi du \\chi^2\nConcernant la prononciation, on prononce “khi-deux” le nom de cette loi.\n\nDéfinition 1 (Loi du \\chi^2) Soit X_1, \\dots, X_k des variables aléatoires i.i.d. de loi normale centrée réduite. La loi de la variable aléatoire X = X_1^2 + \\dots + X_k^2 est appelée loi du \\chi^2 à k degrés de liberté. Sa densité est donnée par \nf(x) = \\frac{1}{2^{\\frac{k}{2}}\\Gamma(\\frac{k}{2})} x^{\\frac{k}{2}-1} e^{-x/2}\\,, \\quad x \\geq 0\\,,\n où \\Gamma désigne la fonction gamma d’Euler : \n\\Gamma(x) = \\int_0^{\\infty} t^{x-1} e^{-t}\\,  dt\\,.\n On note alors X \\sim \\chi^2(k).\n\nAu vu de sa définition, la simulation d’une loi du \\chi^2 est claire : on simule k variables aléatoires gaussiennes centrées réduites indépendantes et on somme leur carrés.\n\nPreuve. Montrons pour k=1 que la densité est bien de la forme précédente, c’est-à-dire \n    f(x) = \\frac{1}{\\sqrt{2\\pi}} \\frac{e^{-x/2}}{\\sqrt x}\\,, \\quad x \\geq 0\\,,\n où on a utilisé la relation \\Gamma(1/2) = \\sqrt \\pi (intégrale de Gauss).\nSoit h : \\mathbb{R} \\to \\mathbb{R} une fonction mesurable bornée. On a \n\\begin{align*}\n    \\mathbb{E}[h(X_1^2)]\n    & = \\int_\\mathbb{R} h(x^2) \\frac{e^{-\\frac{x^2}{2}}}{\\sqrt{2 \\pi}} \\, dx\\\\\n    & = \\int_{-\\infty}^0 h(x^2) \\frac{e^{-\\frac{x^2}{2}}}{\\sqrt{2 \\pi}} \\, dx\n    + \\int_0^{\\infty} h(x^2) \\frac{e^{-\\frac{x^2}{2}}}{\\sqrt{2 \\pi}} \\, dx\\,.\n\\end{align*}\n En effectuant le changement de variable x=-\\sqrt u dans la première intégrale et x=\\sqrt u dans la deuxième, on obtient \n    \\mathbb{E}[h(X_1^2)]\n    = \\int_{\\infty}^0 h(u) \\frac{e^{-u/2}}{\\sqrt{2 \\pi}} \\frac{ du}{2 \\sqrt u}\n    + \\int_0^{\\infty} h(u) \\frac{e^{-u/2}}{\\sqrt{2 \\pi}} \\frac {du}{2 \\sqrt u}\\,.\n Les deux intégrales étant égales, on conclut que \n    \\mathbb{E}[h(X_1^2)] = \\int_0^{\\infty} h(u) \\frac{e^{-u/2}}{\\sqrt{2 \\pi}\\sqrt u}\\, du\\,,\n ce qui prouve le résultat pour k=1.\nLa généralisation à k quelconque se fait par récurrence: on utilise la formule de convolution des la loi pour obtenir la loi pour k+1:\n\n\\begin{align*}\n    X_1^2 + \\dots + X_k^2 + X_{k+1}^2\n    & = (X_1^2 + \\dots + X_k^2) + X_{k+1}^2\\\\\n    & = \\chi^2(k) + X_{k+1}^2\\,.\n\\end{align*}\n Ainsi, \n\\begin{align*}\n    f_{\\chi^2(k+1)}(x)\n    & = \\int_0^{\\infty} f_{\\chi^2(k)}(x-y) f_{X_{k+1}^2}(y) \\, dy\\\\\n    & = \\int_0^x \\frac{1}{2^{\\frac{k}{2}}\\Gamma(\\frac{k}{2})} (x-y)^{\\frac{k}{2}-1} e^{-\\frac{x-y}{2}} \\tfrac{e^{-\\frac{y}{2}}}{\\sqrt{2\\pi y}} \\, dy\\\\\n    & = \\frac{e^{-\\frac{x}{2}}}{2^{\\frac{k+1}{2}} \\Gamma(\\frac{k}{2})  \\Gamma(\\frac{1}{2})}\\int_0^x  (x-y)^{\\frac{k}{2}-1}  \\tfrac{1}{\\sqrt{ y}} \\, dy\\\\\n    & = \\frac{e^{-\\frac{x}{2}}}{2^{\\frac{k+1}{2}} \\Gamma(\\frac{k}{2})  \\Gamma(\\frac{1}{2})} x \\int_0^1  (x-ux)^{\\frac{k}{2}-1}  \\tfrac{1}{\\sqrt{xu}} \\, du\\\\\n\\end{align*}\n avec le changement de variable y=ux. Ensuite, \n\\begin{align*}\n    f_{\\chi^2(k+1)}(x)\n    & = \\frac{x^{\\frac{k+1}{2}} e^{-\\frac{x}{2}}}{2^{\\frac{k+1}{2}} \\Gamma(\\frac{k}{2})  \\Gamma(\\frac{1}{2})}  \\int_0^1  (1-u)^{\\frac{k}{2}-1}  u^{1/2-1} du\\enspace.\n\\end{align*}\n Or rappelons que si \\Beta(a,b) =  \\int_0^1  (1-u)^{a-1}  u^{b-1} \\, du, alors pour tout a,b \\in [0,+\\infty[, \\Beta(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}. En effet, en faisant le changement de variable dans l’intégrale double qui suit: \n\\begin{array}{ccccc}\n    \\psi & : & \\mathbb{R}^+ \\times \\mathbb{R}^+ & \\to     & \\mathbb{R}^+\\times ]0,1[                 \\\\\n            &   & (s,t)                          & \\mapsto & \\Big(s+t, \\frac{t}{s+t}\\Big)\\,,\n\\end{array}\n c’est-à-dire \\psi^{-1}(r,w) = (r(1-w), rw), et le jacobien est donné par J_{\\psi^{-1}}(r,w) = \\begin{pmatrix} 1-w & -r \\\\ w & r \\end{pmatrix}, et donc J_{\\psi^{-1}}(r,w)=r, on obtient: \n\\begin{align*}\n\\Gamma(a)\\Gamma(b) & = \\int_0^{\\infty} t^{a-1} e^{-t} \\, dt \\int_0^{\\infty} s^{b-1} e^{-s} \\, ds\\\\\n& = \\int_0^{\\infty} \\int_0^{\\infty} e^{-t-s} t^{a-1} s^{b-1} \\, dt \\, ds\\\\\n& = \\int_0^{1} \\int_0^{\\infty} e^{-r} (rw)^{a-1} (r(1-w))^{b-1} r \\, dr \\, dw\\\\\n& = \\int_0^1 w^{a-1} (1-w)^{b-1} \\int_0^{\\infty} e^{-r} r^{a+b-1} \\, dr \\, dw\\\\\n\\end{align*}\n et donc \\Beta(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}. En appliquant cette relation pour a=\\frac{k}{2} et b=1/2, on obtient\n\n\\begin{align*}\n    f_{\\chi^2(k+1)}(x)\n    & = \\frac{x^{\\frac{k+1}{2}} e^{-\\frac{x}{2}}}{2^{\\frac{k+1}{2}} \\Gamma(\\frac{k+1}{2})} \\enspace.\n\\end{align*}\n Le résultat est donc prouvé par récurrence.\n\n\n\n\nLoi de Student\n\nDéfinition 2 (Loi de Student) Soit X \\sim \\mathcal{N}(0,1) et Y \\sim \\chi^2(k) deux variables aléatoires indépendantes. La loi de la variable aléatoire V = \\frac{X}{\\sqrt{Y/k}} est appelée loi de Student à k degrés de liberté. Elle admet pour densité \n    f_V(t)\n    = \\dfrac{1}{\\sqrt{k \\pi}} \\dfrac{\\Gamma(\\frac{k+1}{2})}{\\Gamma(\\frac{k}{2})} \\Big(1+\\dfrac{t^2}{k}\\Big)^{-\\frac{k+1}{2}}\\,,\n    \\quad t \\in \\mathbb{R}\\,.\n\n\nLa loi de Student correspond donc au ratio d’une loi normale par la racine carrée d’une loi du \\chi^2(k) normalisée. Ce ratio apparaît souvent en statistique lors de la construction d’intervalles de confiance. Cette loi a été décrite en 1908 par William Gosset2.\n2 William Gosset: (1876-1937) statisticien et chimiste anglais. Il était employé à la brasserie Guinness à Dublin, chargé du contrôle qualité. Son employeur lui refusant le droit de publier sous son propre nom, W. Gosset choisit un pseudonyme, Student (🇫🇷: étudiant). Au vu de la proposition précédente, simuler une loi de Student est assez simple : on simule k+1 loi normales indépendantes X_1, \\ldots, X_{k+1} et on considère \n    V = \\dfrac{\\sqrt{k} X_{k+1}}{\\sqrt{X_1^2+\\cdots + X_k^2}}\\,.\n\n\nPreuve (Formule de la densité). On applique pour cela la formule du changement de variables avec la transformation \n    \\begin{array}{ccccc}\n        \\phi & : & \\mathbb{R}^* \\times ]0, \\infty[ & \\to     & \\mathbb{R}^* \\times \\mathbb{R}^*      \\\\\n             &   & (x,y)                           & \\mapsto & \\Big(x, \\dfrac{x}{\\sqrt{y/k}}\\Big)\\,,\n    \\end{array}\n c’est-à-dire \n    \\phi^{-1}(u,v) = \\Big(u, k\\dfrac{u^2}{v^2}\\Big)\\,.\n La fonction \\phi^{-1} a pour matrice jacobienne \n    J_{\\phi^{-1}} (u,v)\n    =\n    \\begin{pmatrix}\n        1              & 0                  \\\\\n        \\frac{2k}{v^2} & \\frac{-2ku^2}{v^3}\n    \\end{pmatrix}\\,,\n dont le déterminant vaut \\frac{-2ku^2}{v^3}. Par ailleurs, les variables aléatoires X et Y étant indépendantes, la densité du couple (X,Y) correspond au produit des densités : \n    f_{(X,Y)}(x,y) = \\dfrac{e^{-\\frac{x^2}{2}}}{\\sqrt{2 \\pi}}  \\dfrac{1}{2^{\\frac{k}{2}2} \\Gamma(\\frac{k}{2})} y^{\\frac{k}{2}-1} e^{-\\frac{y}{2}} {1\\hspace{-3.8pt} 1}_{]0, \\infty[}(y)\\, \\quad x,y \\in \\mathbb{R}\\,.\n Tout est prêt pour appliquer la théorème du changement de variables qui assure que la densité du couple (U,V) est donnée par \n    f_{(U,V)}(u,v)\n    = \\dfrac{e^{-\\frac{u^2}{2}}}{\\sqrt{2 \\pi}} \\dfrac{1}{2^{\\frac{k}{2}} \\Gamma(\\frac{k}{2})} \\bigg(\\dfrac{k u^2}{v^2}\\bigg)^{\\frac{k}{2}-1} e^{-\\frac{1}{2} \\frac{k u^2}{v^2}} \\dfrac{2 k u^2}{(v^2)^{\\frac{3}{2}}} {1\\hspace{-3.8pt} 1}_{\\mathbb{R}^*}(v)\\,.\n Il suffit alors de marginaliser pour obtenir la densité de V, ce qui s’effectue en calculant l’intégrale \n    \\int_\\mathbb{R} f_{(U,V)} (u,v) \\, du\\,.\n Les termes en u de l’expression précédente s’intègre en \n\\begin{align*}\n    \\int_{-\\infty}^\\infty e^{-\\frac{u^2}{2}(1+\\frac{k}{v^2})} (u^2)^{\\frac{k}{2}} \\, d u\n     & = \\int_0^\\infty e^{-s} \\bigg( \\dfrac{2 s}{1+\\frac{k}{v^2}} \\bigg)^{\\frac{k}{2}} \\sqrt{\\dfrac{2}{1+\\frac{k}{v^2}}} \\dfrac{ds}{2\\sqrt{s}} \\\\\n     & = \\frac{2^{\\frac{k+1}{2}}}{2} \\frac{1}{\\left(1+\\tfrac{k}{v^2}\\right)^{ \\frac{k+1}{2}}} \\!\\!\\! \\int_0^\\infty e^{-s} s^{\\frac{k}{2} - \\frac{1}{2}} \\, ds\\,,\n\\end{align*}\n où la première égalité résulte du changement de variable \n    s = \\dfrac{u^2}{2} \\left( 1 + \\dfrac{k}{v^2} \\right) \\iff \\sqrt{\\dfrac{2s }{1+\\frac{k}{v^2}}} = u\\,.\n On reconnaît dans l’intégrale la valeur de \\Gamma(\\frac{k+1}{2}) ce qui conduit à \n    f_V(v)\n    =\n    \\dfrac{1}{\\sqrt{2 \\pi}} \\dfrac{1}{2^{\\frac{k}{2}} \\Gamma(\\frac{k}{2})} \\bigg(\\dfrac{k}{v^2}\\bigg)^{\\frac{k}{2}-1} \\dfrac{2 k}{(v^2)^{\\frac{3}{2}}}\n    \\frac{2^{\\frac{k+1}{2}}}{2} \\frac{\\Gamma\\left(\\tfrac{k+1}{2}\\right)}{\\left(1+\\tfrac{k}{v^2}\\right)^{ \\frac{k+1}{2}}}\\,.\n On réécrit alors les termes en k/v^2 via \n\\begin{align*}\n\\left(\\tfrac{k}{v^2}\\right)^{\\frac{k}{2}-1} \\tfrac{k}{(v^2)^{\\frac{3}{2}}}\n    \\frac{1}{\\left(1+\\tfrac{k}{v^2}\\right)^{ \\frac{k+1}{2}}}\n    & =\n    \\left(\\tfrac{k}{v^2}\\right)^{\\frac{k}{2}-1} \\tfrac{1}{\\sqrt{k}} \\left(\\tfrac{k}{v^2}\\right)^{\\frac{3}{2}}\n    \\frac{1}{\\left(1+\\tfrac{k}{v^2}\\right)^{ \\frac{k+1}{2}}}\\\\\n    & = \\tfrac{1}{\\sqrt{k}}\\left(1+\\tfrac{v^2}{k}\\right)^{- \\frac{k+1}{2}}\\,,\n\\end{align*}\n ce qui permet de conclure : \n    f_V(v)\n    =\n    \\dfrac{1}{\\sqrt{k \\pi}} \\dfrac{\\Gamma(\\frac{k+1}{2})}{\\Gamma(\\frac{k}{2})} \\Big(  1+\\dfrac{v^2}{k}\\Big)^{-\\frac{k+1}{2}}\\,.\n\n\n\n\n\nLoi de Cauchy\n\nDéfinition 3 (Loi de Cauchy) Une variable aléatoire X suit une loi de Cauchy standard si sa densité est donnée par \n    f_X(x) = \\dfrac{1}{\\pi(1+x^2)}\\,, \\quad x \\in \\mathbb{R}\\,.\n\n\nOn note alors X\\sim \\mathcal{C}(0,1) dans ce cas. Plus généralement on dit que Y suit une loi de Cauchy de paramètres (\\mu,\\sigma)\\in \\mathbb{R} \\times ]0,+\\infty[ si Y=\\mu+\\sigma X où X suit une loi de Cauchy standard. Sa densité est alors donnée par \n    f_Y(y) = \\dfrac{1}{\\sigma \\pi(1 + \\tfrac{(y-\\mu)^2}{\\sigma^2})}\\,, \\quad y \\in \\mathbb{R}\\,.\n\nPour rappel cette loi est importante comme exemple de loi qui n’admet ni espérance, ni variance a fortiori. En effet, si X suit une loi de Cauchy standard, \n\\int_{\\mathbb{R}} |x| f_X(x) \\, dx = \\int_{\\mathbb{R}} \\frac{|x|}{\\pi(1+x^2)} \\, dx.\n Or \\frac{|x|}{\\pi(1+x^2)}\\sim \\frac{1}{\\pi x} quand |x|\\to \\infty, et x\\mapsto \\frac{|x|}{\\pi(1+x^2)} n’est donc pas intégrable sur \\mathbb{R} au sens de Lebesgue. C’est donc un exemple de loi pour laquelle la loi des grands nombres et le théorème central limite ne s’appliquent pas.\n\nFonction caractéristique\nLa fonction caractéristique de la loi de Cauchy standard est donnée par \n\\begin{align*}\n\\varphi_X(t) & \\triangleq \\int_{\\mathbb{R}} e^{itx} f_X(x) \\, dx = e^{-|t|}\\,.\n\\end{align*}\n et donc si X\\sim \\mathcal{C}(\\mu,\\sigma), alors pour tout t \\in \\mathbb{R}, \\varphi_X(t) = e^{i\\mu t - \\sigma |t|}. Pour la preuve voir par exemple (Exemple III.5.5., Barbe et Ledoux 2006) Une conséquence directe est que la somme de deux variables aléatoires indépendantes de loi de Cauchy reste une loi de Cauchy: Si X_1 \\sim \\mathcal{C}(\\mu_1,\\sigma_2) et X_2 \\sim \\mathcal{C}(\\mu_2,\\sigma_2) sont indépendantes, alors X_1+X_2 \\sim \\mathcal{C}(\\mu_1+\\mu_2,\\sigma_1+\\sigma_2) (car elles ont la même fonction caractéristique).\n\nBarbe, Philippe, et Michel Ledoux. 2006. Probabilités.\nOn en déduit que la moyenne de variables de Cauchy standard i.i.d suit la loi de Cauchy standard. En effet, si X_1, \\ldots, X_n sont i.i.d de loi de Cauchy standard, alors pour tout t \\in \\mathbb{R}, \\varphi_{\\frac{1}{n}\\sum_{i=1}^n X_i}(t) = e^{-|t|}, et donc \\frac{1}{n}\\sum_{i=1}^n X_i \\sim \\mathcal{C}(0,1). Ainsi la moyenne empirique ne converge pas en probabilité vers une constante!\n\n\nFonction de répartition et simulation\nLa fonction de répartition de X correspond, à une constante près, à la fonction arctangente qui est bijective de \\mathbb{R} sur ]\\frac{-\\pi}{2},\\frac{\\pi}{2}[. La méthode d’inversion permet donc de simuler une variable aléatoire de loi de Cauchy. La proposition suivante donne un autre moyen.\n\nProposition 2 (Loi de Cauchy et loi normale) Soit X et Y deux variables aléatoires indépendantes de loi normale centrée réduite. Alors la variable aléatoire Y/X suit une loi de Cauchy.\n\nNotons que Y/X est bien définie puisque X est différent de 0 presque sûrement.\n\nPreuve. Comme pour la loi de Student, on démontre ce résultat avec un changement de variables. On considère l’application \n    \\begin{array}{ccccc}\n        \\phi & : & \\mathbb{R}^* \\times \\mathbb{R} & \\to     & \\mathbb{R}^2                 \\\\\n                &   & (x,y)                          & \\mapsto & \\Big(x, \\dfrac{y}{x}\\Big)\\,,\n    \\end{array}\n c’est-à-dire \n    \\phi^{-1}(u,v) = (u, uv)\\,.\n La matrice jacobienne de \\phi^{-1} est donnée par \n    J_{\\phi^{-1}} (u,v)\n    =\n    \\begin{pmatrix}\n        1 & 0 \\\\\n        v & u\n    \\end{pmatrix}\\,,\n dont le déterminant vaut u. Rappelons également que la densité du couple (X,Y) vaut \n    f_{(X,Y)}(x,y) = \\dfrac{1}{2 \\pi} e^{- \\frac{x^2 + y^2}{2}}\\,, \\quad x,y \\in \\mathbb{R}\\,.\n La formule du changement de variables donne alors la densité de f_{(U,V)} : \n    f_{(U,V)}\n    = \\dfrac{1}{2 \\pi} e^{- \\frac{u^2 + u^2v^2}{2}} |u|\\,.\n On obtient alors la densité de V en intégrant par rapport à u : \n\\begin{align*}\n    f_V(v)\n    & = \\dfrac{1}{2 \\pi} \\int_\\mathbb{R} e^{- \\frac{u^2 + u^2v^2}{2}} |u| \\, \\mathrm du \\\\\n    & = \\dfrac{1}{\\pi} \\int_0^\\infty e^{- \\frac{u^2(1 + v^2)}{2}} u \\, \\mathrm du\\\\\n    & = \\dfrac{1}{\\pi} \\bigg[ -\\dfrac{e^{- \\frac{u^2(1 + v^2)}{2}}}{1+v^2} \\bigg]_0^\\infty\\\\\n    & = \\dfrac{1}{\\pi(1+v^2)}\\,.\n\\end{align*}\n\n\nOn obtient ainsi une autre manière de simuler une loi de Cauchy, en prenant le ratio de deux gaussiennes indépendantes. Cependant, la simulation via la méthode d’inversion peut-être moins coûteuse puisqu’elle ne fait appel qu’à une variable aléatoire uniforme et à la fonction tangente.",
    "crumbs": [
      "Cours",
      "Loi normale: cas univarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale_multi.html",
    "href": "Courses/loi_normale_multi.html",
    "title": "Loi normale: cas multivarié",
    "section": "",
    "text": "On considère ici \\mathbb{R}^d muni du produit scalaire euclidien \\langle \\cdot, \\cdot \\rangle et de la norme euclidienne \\|\\cdot\\| associée.",
    "crumbs": [
      "Cours",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale_multi.html#rappel-sur-les-vecteurs-aléatoires",
    "href": "Courses/loi_normale_multi.html#rappel-sur-les-vecteurs-aléatoires",
    "title": "Loi normale: cas multivarié",
    "section": "Rappel sur les vecteurs aléatoires",
    "text": "Rappel sur les vecteurs aléatoires\nSi \\mathbf{X} = (X_1, \\dots, X_d) \\in \\mathbb{R}^d est un vecteur aléatoire, son espérance est définie coordonnée par coordonnée : \n    \\mathbb{E}[\\mathbf{X}] = (\\mathbb{E}[X_1], \\dots, \\mathbb{E}[X_d]) \\in \\mathbb{R}^d\\\n quantité qui existe dès que chaque espérance est bien définie. De plus, si \\mathbb{E}[X_j^2] &lt; \\infty pour tout j\\in \\llbracket 1, d\\rrbracket, on peut alors définir les covariances pour tout (i,j) \\in \\llbracket 1, d\\rrbracket^2 : \n    \\textrm{cov}(X_i, X_j) = \\mathbb{E}[(X_i- \\mathbb{E}[X_i]) (X_j - \\mathbb{E}[X_j])] \\enspace,\n quantités que l’on rassemble dans une matrice appelée matrice de variance-covariance : \n    \\Sigma = (\\textrm{cov}(X_i, X_j))_{1 \\leq i,j \\leq d} \\in \\mathbb{R}^{d \\times d} \\,.\n On peut montrer que cette matrice est symétrique et semi-définie positive. En particulier, si les X_j sont indépendants, alors \\Sigma est une matrice diagonale.\n\n\n\n\n\n\nNote\n\n\n\nUn point important. Si (X,Y) est un vecteur aléatoire, il ne suffit pas de connaître les marginales X et Y pour caractériser entièrement le vecteur. Par exemple, si X et Y suivent toutes les deux une loi normale, alors on peut avoir par exemple X=Y, ou bien X indépendant de Y, et ces deux cas modélisent clairement deux vecteurs aléatoires de lois distinctes.",
    "crumbs": [
      "Cours",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale_multi.html#vecteurs-gaussiens",
    "href": "Courses/loi_normale_multi.html#vecteurs-gaussiens",
    "title": "Loi normale: cas multivarié",
    "section": "Vecteurs gaussiens",
    "text": "Vecteurs gaussiens\n\nDéfinition 1 (Vecteur gaussien) Un vecteur aléatoire \\mathbf{X} = (X_1, \\dots, X_d)^\\top \\in \\mathbb{R}^d est un vecteur gaussien si pour tout \\bm{\\alpha} = (\\alpha_1, \\dots, \\alpha_d)^\\top, la variable aléatoire réelle \n  \\langle \\bm{\\alpha}, \\mathbf{X} \\rangle = \\alpha_1 X_1 + \\cdots + \\alpha_d X_d \\enspace,\n suit une loi normale.\n\nEn particulier chaque (loi marginale) X_j suit alors une loi gaussienne (choisir ci-dessus \\alpha = e_j, les autres égaux à 0).\nCependant, il ne suffit pas que les X_j soient des gaussiennes pour que le vecteur X soit un vecteur gaussien. Par exemple, si X suit une loi normale centrée réduite et \\varepsilon une loi uniforme (discrète) sur \\{-1,1\\}, alors on peut montrer que \\varepsilon X suit encore une loi normale centrée réduite. En effet, pour tout t \\in \\mathbb{R}, on a \n\\begin{align*}\n  \\mathbb{P}(\\varepsilon X \\leq t)\n  & =  \\mathbb{P}(X \\leq t) \\mathbb{P}(\\varepsilon = 1) + \\mathbb{P}(-X \\leq t) \\mathbb{P}(\\varepsilon = -1)\\\\\n  & = \\tfrac{1}{2} \\mathbb{P}(X \\leq t) + \\tfrac{1}{2} \\mathbb{P}(-X \\leq t) = \\mathbb{P}(X \\leq t) \\enspace.\n\\end{align*}\n Cependant, X + \\varepsilon X prend la valeur 0 avec probabilité 1/2 donc ne suit pas une loi normale. Ainsi le vecteur (X, \\varepsilon X)^{\\top} n’est pas un vecteur gaussien bi-dimensionnel.\nSoit \\mathbf{X} un vecteur gaussien. Notons \\bm{\\mu} son espérance et \\Sigma sa matrice de variance-covariance. En reprenant les notations de la définition, la variable aléatoire \\langle \\bm{\\alpha}, \\mathbf{X} \\rangle vérifie \n\\begin{align*}\n  \\mathbb{E}[\\langle \\bm{\\alpha}, \\mathbf{X} \\rangle]\n  & = \\mathbb{E}[\\alpha_1 X_1 + \\cdots + \\alpha_d X_d] \\\\\n  & =  \\alpha_1 \\mathbb{E}[X_1] + \\cdots + \\alpha_d \\mathbb{E}[X_d]\n  & = \\langle \\bm{\\alpha}, \\bm{\\mu} \\rangle\\,,\n\\end{align*}\n et \n\\begin{align*}\n  \\mathrm{var}(\\langle \\bm{\\alpha}, \\mathbf{X} \\rangle)\n    & = \\mathrm{var}(\\alpha_1 X_1 + \\cdots + \\alpha_d X_d)\\\\\n    & = \\mathrm{cov}(\\alpha_1 X_1 + \\cdots + \\alpha_d X_d, \\alpha_1 X_1 + \\cdots + \\alpha_d X_d) \\\\\n    & = \\sum_{1 \\leq i,j \\leq d} \\alpha_i \\mathrm{cov}(X_i, X_j) \\alpha_j\n  = \\bm{\\alpha}^\\top \\Sigma \\bm{\\alpha}\n\\end{align*}\n Ainsi, \\langle \\bm{\\alpha}, \\mathbf{X} \\rangle \\sim \\mathcal{N}\\left(\\langle \\bm{\\alpha}, \\bm{\\mu} \\rangle, \\bm{\\alpha}^\\top \\Sigma \\bm{\\alpha}\\right).\n\nFonction caractéristique d’un vecteur gaussien\nLa fonction caractéristique d’un vecteur gaussien d’espérance \\bm{\\mu} et de matrice de variance-covariance \\Sigma est donnée par \n    \\phi_\\mathbf{X}(\\bm{\\alpha})\n    = \\mathbb{E}[e^{i \\langle \\bm{\\alpha}, \\mathbf{X} \\rangle}]\n    = \\exp\\Big(i \\langle \\bm{\\alpha}, \\bm{\\mu} \\rangle - \\frac{\\bm{\\alpha}^\\top \\Sigma \\bm{\\alpha}}{2}\\Big)\\,,\n    \\quad \\bm{\\alpha} \\in \\mathbb{R}^d\\,.\n où on a utilisé l’expression de la fonction caractéristique d’une variable aléatoire de loi normale \\mathcal{N}(\\langle \\bm{\\alpha}, \\bm{\\mu} \\rangle, \\bm{\\alpha}^\\top \\Sigma \\bm{\\alpha}). Ainsi, \\phi_\\mathbf{X} est entièrement déterminée par les quantités \\bm{\\mu} et \\Sigma. Comme cette fonction caractérise la loi de \\mathbf{X}, on en déduit que la loi d’un vecteur gaussien est entièrement caractérisée par son espérance et sa matrice de variance-covariance. On note alors \n    \\mathbf{X} \\sim \\mathcal{N}(\\bm{\\mu}, \\Sigma)\\,.\n En particulier, si les variables aléatoires X_1, \\dots, X_d sont indépendantes de loi \\mathcal{N}(0,1), alors \\bm{\\mu} = (0,\\ldots,0)^\\top et \\Sigma = \\mathrm{Id}_d.\n\n\nDensité de probabilité\nCommençons par le cas \\bm{\\mu}=0 et \\Sigma = \\mathrm{Id}_d correspond à la loi gaussienne centrée réduite \\mathcal{N}(0, \\mathrm{Id}_d). La loi de (X_1,\\dots,X_n)^\\top correspond alors à la loi produit de n lois gaussiennes centrées réduites indépendantes (pour les gaussiennes la décorrélation implique l’indépendance). Sa densité est donc donnée par \n\\varphi_{0,\\mathrm{Id}_d}(x) = \\frac{1}{ \\sqrt{(2\\pi)^d}} \\exp\\left( -\\tfrac{1}{2}x^\\top x   \\right) \\enspace.\n\n\nProposition 1 (Densité de la loi gaussienne multivariée) Soient \\bm{\\mu} \\in \\mathbb{R}^d et \\Sigma \\in \\mathbb{R}^{d \\times d} (symétrique et définie positive) et supposons que X \\sim \\mathcal{N}(\\bm{\\mu},\\Sigma). Alors la densité de probabilité de X est donnée pour tout x \\in \\mathbb{R}^d par\n\n\\varphi_{\\bm{\\mu},\\Sigma}(x) = \\frac{1}{ \\sqrt{(2\\pi)^d |\\det(\\Sigma)|}}  \\exp\\Big( -\\tfrac{1}{2}(x-\\bm{\\mu})^\\top\\Sigma^{-1}(x - \\bm{\\mu})   \\Big) \\enspace.\n\n\n\nPreuve. Prenons une matrice L\\in \\mathbb{R}^{d \\times d} telle que LL^\\top = \\Sigma (par exemple, la décomposition de Cholesky, que nous reverrons ci-dessous). Calculons alors la loi de \\mathbf{Y} = \\psi(X) \\triangleq L \\mathbf{X} + \\bm{\\mu}, pour X\\sim \\mathcal{N}(0,\\mathrm{Id_d}). Pour appliquer la formule du changement de variable nous donne, on calcule \\psi^{-1} et son jacobien: \\psi^{-1}(y) = L^{-1}(y-\\bm{\\mu}), et \\det(J_{\\psi^{-1}}) = \\det(L^{-1}) = \\det(L)^{-1} = |\\det(\\Sigma)|^{-1/2}.\nEn notant que LL^\\top \\left(L^{-1}\\right)^\\top L^{-1}=\\mathrm{Id}_d, et donc que \\left(L^{-1}\\right)^\\top L^{-1}=\\Sigma^{-1}, on en déduit que la densité de \\mathbf{Y} est donnée par \n\\begin{align*}\n\\varphi_{\\bm{\\mu},\\Sigma}(y)\n& = \\varphi_{0,\\mathrm{Id}_d}(\\psi^{-1}(y)) |\\det(J_{\\psi^{-1}})| \\\\\n& = \\frac{|\\det(\\Sigma)|^{-1/2}}{ \\sqrt{(2\\pi)^d }}  \\exp\\left( -\\tfrac{1}{2}(y-\\bm{\\mu})^\\top \\left(L^{-1}\\right)^\\top L^{-1}(y - \\bm{\\mu})\\right)\\\\\n& = \\frac{1}{ \\sqrt{(2\\pi)^d |\\det(\\Sigma)|}}  \\exp\\Big( -\\tfrac{1}{2}(y-\\bm{\\mu})^\\top\\Sigma^{-1}(y - \\bm{\\mu})   \\Big) \\enspace.\n\\end{align*}\n\n\n\nProposition 2 (Transformation affine de vecteurs gaussiens) Soit \\mathbf{X} \\sim \\mathcal{N}(\\bm{\\mu}, \\Sigma) un vecteur gaussien sur \\mathbb{R}^d, \\Omega \\in \\mathbb{R}^{d' \\times d} et \\bm{\\nu}\\in \\mathbb{R}^{d'}. Alors, le vecteur aléatoire \\mathbf{Y} = \\Omega \\mathbf{X} + \\bm{\\nu} est un vecteur gaussien vérifiant \n  \\mathbf{Y} \\sim \\mathcal{N}(\\Omega \\bm{\\bm{\\mu}} + \\bm{\\nu}, \\Omega \\Sigma \\Omega^\\top)\\,.\n\n\nCette proposition se prouve sans peine en utilisant la fonction caractéristique On retrouve en particulier la stabilité par transformation affine établie en dimension 1.",
    "crumbs": [
      "Cours",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale_multi.html#la-factorisation-de-cholesky",
    "href": "Courses/loi_normale_multi.html#la-factorisation-de-cholesky",
    "title": "Loi normale: cas multivarié",
    "section": "La factorisation de Cholesky",
    "text": "La factorisation de Cholesky\nPour rappel, la factorisation de Cholesky1 d’une matrice symétrique définie positive est donnée ci-dessous.\n1 André-Louis Cholesky, dit René: (1875-1918) ingénieur topographe et géodésien dans l’armée française, mort des suites de blessures reçues au champs de bataille. \nThéorème 1 (Factorisation de Cholesky) Soit \\Sigma \\in \\mathbb{R}^{d \\times d} une matrice symétrique définie positive. Alors il existe une matrice triangulaire inférieure L \\in \\mathbb{R}^{d \\times d} telle que \\Sigma = LL^\\top. La décomposition est unique si l’on impose que les éléments diagonaux de L soient strictement positifs.\n\n\nPreuve. La factorisation de Cholesky est une conséquence directe de la méthode du pivot de Gauss. Le détail est donné par exemple dans (Th. 4.4.1, Ciarlet 2006).\n\nCiarlet, P. G. 2006. Introduction à l’analyse numérique matricielle et à l’optimisation. Cours et exercices corrigés. Dunod.",
    "crumbs": [
      "Cours",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale_multi.html#simulation-de-vecteurs-gaussiens",
    "href": "Courses/loi_normale_multi.html#simulation-de-vecteurs-gaussiens",
    "title": "Loi normale: cas multivarié",
    "section": "Simulation de vecteurs gaussiens",
    "text": "Simulation de vecteurs gaussiens\nLa simulation d’un vecteur gaussien de paramètres \\bm{\\mu} = (0,\\ldots,0)^\\top et \\Sigma = \\mathrm{Id}_d ne pose pas de problème : il suffit de simuler X_1,\\dots, X_d, d variables aléatoires indépendantes de loi normale centrée réduite. En effet, le vecteur \\mathbf{X} = (X_1,\\dots, X_d)^\\top est alors un vecteur gaussien de loi \\mathcal{N}(0, \\mathrm{Id}_d).\nSupposons maintenant que l’on veuille simuler un vecteur gaussien de loi \\mathcal{N}(\\bm{\\mu}, \\Sigma) dans \\mathbb{R}^d, \\bm{\\mu} et \\Sigma symétrique définie positive donnés.\n\nApproche par la factorisation de Cholesky\nLa matrice \\Sigma étant symétrique, elle peut s’écrire comme \\Sigma = LL^\\top où L est une matrice triangulaire inférieure de taille d \\times d. Grâce à la décomposition de Cholevsky et en reprenant les éléments de la preuve de la Proposition 1, on peut écrire \\mathbf{Y} = L \\mathbf{X} + \\bm{\\mu} où \\mathbf{X} \\sim \\mathcal{N}(0, \\mathrm{Id}_d) et vérifier que \\mathbf{Y} \\sim \\mathcal{N}(\\bm{\\mu}, \\Sigma).\n\n\nApproche par la décomposition spectrale de \\Sigma\nLa matrice \\Sigma étant symétrique, elle se diagonalise en base orthonormée : il existe une matrice orthogonale P telle que \n    \\Sigma\n    = P \\mathrm{diag}(\\lambda_1 \\ldots, \\lambda_d) P^{-1}\n    = P \\mathrm{diag}(\\lambda_1 \\ldots, \\lambda_d) P^\\top\\,,\n où \\lambda_1, \\ldots, \\lambda_d \\geq 0 sont les valeurs propres de \\Sigma qui est semi-définie positive. On pose alors R = P \\mathrm{diag}(\\sqrt \\lambda_1 \\ldots, \\sqrt \\lambda_d) qui est une racine carrée matricielle de \\Sigma au sens où \\Sigma = R R ^\\top. On part alors d’un vecteur gaussien centrée réduit \\mathbf{X}_0 \\sim \\mathcal{N}(0, \\mathrm{Id}_d) que l’on sait simuler (par exemple avec la méthode de Box-Müller). La proposition Proposition 2 assure alors que le vecteur \\mathbf{X} = R \\mathbf{X}_0 + \\bm{\\mu} est un vecteur gaussien de loi \\mathcal{N}(\\bm{\\mu}, \\Sigma).",
    "crumbs": [
      "Cours",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Courses/loi_normale_multi.html#vecteurs-gaussiens-cas-bidimensionnel",
    "href": "Courses/loi_normale_multi.html#vecteurs-gaussiens-cas-bidimensionnel",
    "title": "Loi normale: cas multivarié",
    "section": "Vecteurs gaussiens : cas bidimensionnel",
    "text": "Vecteurs gaussiens : cas bidimensionnel\nEn dimension p=2, la matrice de covariance \\Sigma peut toujours s’écrire comme suit, et la visualisation suivante montre l’impact des différents paramètres sur la densité de probabilité. \n\\Sigma =\n\\begin{pmatrix}\\cos(\\theta) & - \\sin(\\theta)\\\\  \\sin(\\theta)& \\cos(\\theta)\n\\end{pmatrix} \\cdot\n\\begin{pmatrix}\\sigma_1 & 0\\\\ 0 & \\sigma_2\n\\end{pmatrix}\\cdot\n\\begin{pmatrix}\n\\cos(\\theta) &\\sin(\\theta)\\\\  -\\sin(\\theta)& \\cos(\\theta)\\end{pmatrix}\n où \\theta est l’angle de rotation et \\sigma_1 et \\sigma_2 les écarts-types des marginales (dans le repère orthonormal après rotation).\nPlotly = require('plotly.js-dist');\ndists = require( 'https://cdn.jsdelivr.net/gh/stdlib-js/stats-base-dists@umd/browser.js' );\njstat = require('jstat');\nmath = require(\"mathjs\");\n// see source here: https://github.com/stdlib-js/stats-base-dists/tree/umd\n// continuous case\n\nviewof inputs = Inputs.form([\n  Inputs.range([-1, 1], {label: tex`\\mu_1`, step: 0.1}, {value: 0}),\n  Inputs.range([-1, 1], {label: tex`\\mu_2`, step: 0.1}, {value: 0}),\n  Inputs.range([0.1, 2], {label: tex`\\sigma_1`, step: 0.1, value: 1}),\n  Inputs.range([0.1, 2], {label: tex`\\sigma_2`, step: 0.1, value: 1}),\n  Inputs.range([0, 6.29], {label: tex`\\theta`, step: 0.01, value: 0}),\n  Inputs.range([0, 1000], {label: tex`n`, step: 1, value: 10}),\n  Inputs.button(\"Re-Tirage\")\n])\n\n\nmu1 = inputs[0];\nmu2 = inputs[1];\nsigma1 = inputs[2];\nsigma2 = inputs[3];\ntheta = inputs[4];\nn_samples = inputs[5];\n\n\nfunction create_sigma(theta, sigma1, sigma2){\n  const mat_rot = math.matrix([[math.cos(theta), -math.sin(theta)], [math.sin(theta), math.cos(theta)]]);\n  const mat_sigma = math.matrix([[sigma1**2, 0], [0, sigma2**2]]);\n  return math.multiply(mat_rot, math.multiply(mat_sigma, math.transpose(mat_rot)));\n}\n\n\nfunction mvnpdf(x, mu, Sigma){\n  const p = 2;\n    return (2*math.pi)**(-p/2)*math.det(Sigma)**(-0.5)*\n      math.exp(-0.5*math.multiply(math.multiply( math.transpose(math.subtract(x,mu)), math.inv(Sigma)), math.subtract(x, mu)));\n}\n\n{\n\n\nfunction normal_rng(mu, Sigma, n=100) {\n    // Compute the Cholesky decomposition of Sigma\n    var cholesky = jstat.cholesky(Sigma);\n\n    // Generate the samples\n    var samples = Array.from({length: n}, () =&gt; {\n        var x = jstat.normal.sample(0, 1);\n        var y = jstat.normal.sample(0, 1);\n        // Transform the standard normal random variables using the Cholesky decomposition\n        var transformedX = mu[0] + cholesky[0][0] * x + cholesky[0][1] * y;\n        var transformedY = mu[1] + cholesky[1][0] * x + cholesky[1][1] * y;\n        return [transformedX, transformedY];\n    });   \n\n    return samples;\n}\nvar Sigma = create_sigma(theta, sigma1, sigma2).toArray();\nvar mu = [mu1, mu2];\n\nvar samples = normal_rng(mu, Sigma, 1000);\nvar npoints=100, mini = -5, maxi=5, x = new Array(npoints), y = new Array(npoints), z = new Array(npoints), i, j;\n\n//  Densité:\nfor(var i = 0; i &lt; npoints; i++) {\n    x[i] = mini + i * (maxi - mini) / (npoints - 1);\n    y[i] = mini + i * (maxi - mini) / (npoints - 1);\n    z[i] = new Array(npoints);\n    }\n\nfor(var i = 0; i &lt; npoints; i++) {\n    for(j = 0; j &lt; npoints; j++) {\n\n        z[j][i] = mvnpdf([x[i], x[j]], mu, Sigma);\n    }\n\n}\n  \n\n{\n\nvar trace1 = {\n        x: samples.slice(0, n_samples).map(sample =&gt; sample[0]),\n        y: samples.slice(0, n_samples).map(sample =&gt; sample[1]),\n        mode: 'markers',\n        type: 'scatter',\n        marker: {\n            color: 'rgba(0,0,0,0.5)',\n            size: 5,\n        },\n\n        xaxis: 'x2',\n}\n\nvar trace22 = {\n        x: x,\n        y: y,\n        z: z,\n        type: 'surface',\n        colorscale: 'Oranges',\n        showscale: false,\n        color: {\n            legend: false,\n            label: \"pdf\",\n        },\n\n}\n\nvar trace21 = {\n        x: x,\n        y: y,\n        z: z,\n        type: 'contour',\n        colorscale: 'Oranges',\n        color: {\n            legend: true,\n            label: \"pdf\",\n        },\n        blur: 4,\n        xlim: [-5, 5],\n        ylim: [-5, 5],\n        xaxis: 'x2',\n}\n\n\nvar data = [\n  trace21,\n  trace22,\n  trace1,\n  ];\n\n\n  var layout = {\n       yaxis2: {\n          range: [-5, 5],\n          autorange: false,\n        },\n       xaxis2: {\n          range: [-5, 5],\n          autorange: false,\n        },\n\n      scene: {\n          camera: {\n              eye: {\n                  x: 0.5,\n                  y: 1.2,\n                  z: 1.5,\n              }\n          }\n      },\n    grid: {\n      rows: 1,\n      columns: 2,\n      subplots: [['xy','x2y']],\n    },\n    showlegend: false,\n\n  };\n\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.newPlot(div, data, layout, config);\n    return div;\n  }\n\n}",
    "crumbs": [
      "Cours",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Courses/matterjs-inverse-vizu.html",
    "href": "Courses/matterjs-inverse-vizu.html",
    "title": "inverse-vizu",
    "section": "",
    "text": "viewof dist = Inputs.select(['normal','cauchy','laplace','bimodal'], {value: \"bimodal\", label: \"Distribution type\"})\nviewof replay = html`&lt;button&gt;replay`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninvcdfboard = require(await FileAttachment(\"../inverse-vizu/dist/invcdfboard.umd.cjs\").url())\n\n{\n  replay\n  const canvas = DOM.canvas(500, 500);\n  const galton = invcdfboard.galton(canvas,dist);\n  \n  return html`${galton.canvas}`\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "Courses/notations.html",
    "href": "Courses/notations.html",
    "title": "Notations et rappels",
    "section": "",
    "text": "On considère un espace probabilisé (\\Omega, {\\mathcal{F}}, \\mathbb{P}), composé d’un ensemble \\Omega, d’une tribu \\mathcal{F}, et d’une mesure de probabilité \\mathbb{P}.\nCette définition permet de transposer l’aléa qui provient de \\Omega dans l’espace E. L’hypothèse \\{X \\in B\\} \\in \\mathcal{F} assure que cet ensemble est bien un évènement et donc que l’on peut calculer sa probabilité.\nUne fois que l’aléa a été transposé de \\Omega vers E, on souhaite également transposer la probabilité \\mathbb{P} sur E. Ceci motive l’introduction de la notion de loi.\nLes propriétés de \\mathbb{P} assurent que \\mathbb{P}_X est bien une loi de probabilité sur l’espace mesurable (E, \\mathcal{E}).",
    "crumbs": [
      "Cours",
      "Notations et rappels"
    ]
  },
  {
    "objectID": "Courses/notations.html#loi-discrètes",
    "href": "Courses/notations.html#loi-discrètes",
    "title": "Notations et rappels",
    "section": "Loi discrètes",
    "text": "Loi discrètes\nLes variables aléatoires discrètes sont celles à valeurs dans un ensemble E discret, le plus souvent \\mathbb{N}, muni de la tribu pleine \\mathcal{F} = \\mathcal{P}(E).\n\nExemple 1 (Loi de Bernoulli) La loi la plus simple est la loi de Bernoulli de paramètre p \\in [0,1], définie sur \\{0,1\\} par \\mathbb{P}(X=1) = 1-\\mathbb{P}(X=0) = p qui modélise une expérience aléatoire à deux issues (succès = 1 et échec = 0).\n\n\nExemple 2 (Loi binomiale) En sommant des variables aléatoires indépendantes de loi de Bernoulli on obtient une loi binomiale : \\mathbb{P}(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}, pour k \\in \\{0,\\ldots,n\\}, qui modélise le nombre de succès parmi n lancers.\n\n\nExemple 3 (Loi géométrique) En observant le nombre d’expériences nécessaires avant d’obtenir un succès, on obtient une loi géométrique : \\mathbb{P}(X=k) = p (1-p)^{k-1}, pour k \\geq 1. C’est une loi de probabilité discrète qui décrit le comportement du nombre d’événements se produisant dans un intervalle de temps fixé, si ces événements se produisent avec une fréquence moyenne ou espérance connue, et indépendamment du temps écoulé depuis l’événement précédent (e.g., nombre de clients dans une file d’attente, nombre de mutations dans un gène, etc.).\n\n\nExemple 4 (Loi de Poisson) La loi de Poisson de paramètre \\lambda &gt; 0 est définie par \\mathbb{P}(X=k) = e^{-\\lambda} \\lambda^k / k!, pour k \\in \\mathbb{N}",
    "crumbs": [
      "Cours",
      "Notations et rappels"
    ]
  },
  {
    "objectID": "Courses/notations.html#lois-continues",
    "href": "Courses/notations.html#lois-continues",
    "title": "Notations et rappels",
    "section": "Lois continues",
    "text": "Lois continues\nParmi les variables aléatoires réelles non discrètes, beaucoup peuvent se représenter avec une densité, c’est-à-dire qu’il existe une fonction mesurable f : \\mathbb{R} \\to [0, \\infty[ d’intégrale 1. La loi d’une telle variable aléatoire X est alors donnée pour tout A \\in \\mathcal{B}(\\mathbb{R}) par \n    \\mathbb{P}(X \\in A) = \\int_A f(x) \\, \\mathrm d x \\enspace.\n Les propriétés de l’intégrale de Lebesgue assure que cette formule définit bien une loi de probabilité.\n\nExemple 5 (Loi uniforme) La loi uniforme sur un ensemble B \\in \\mathcal{B}(\\mathbb{R}), s’obtient avec la densité définie par \nf(x) = {1\\hspace{-3.8pt} 1}_B(x) / \\lambda (B) \\enspace,\n où \\lambda (B) représente la mesure de Lebesgue de l’ensemble B. En particulier pour la loi uniforme sur le segment [0,1] on obtient la fonction suivante: \nf(x) = {1\\hspace{-3.8pt} 1}_{[0,1]}(x)\\enspace.\n Si une variable aléatoire U suit une telle loi on note U \\sim \\mathcal{U}([0,1]).\n\n\nExemple 6 (Loi exponentielle) La loi exponentielle de paramètre \\gamma &gt; 0 est obtenue avec la densité donnée par \nf(x) = \\gamma e^{-\\gamma x} {1\\hspace{-3.8pt} 1}_{\\mathbb{R}_+}(x)\\enspace.\n Si une variable aléatoire X suit cette loi on note X \\sim \\mathcal{Exp}(\\gamma).\n\n\nExemple 7 (Loi normale/gaussienne univariée) On obtient la loi normale de paramètre \\mu \\in \\mathbb{R} et \\sigma^2 &gt; 0 correspond à loi dont la densité est donnée par la fonction réelle: \nf(x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma}e^{-\\frac{1}{2 \\sigma^2}(x-\\mu)^2} \\enspace.\n Si une variable aléatoire X suit une telle loi on note X \\sim \\mathcal{N}(\\mu,\\sigma^2), \\mu correspondant à l’espérance de la loi, et \\sigma^2 à sa variance. On nomme loi normale centrée réduite le cas correspondant à \\mu = 0 et \\sigma^2 = 1.\n\n\nExemple 8 (Loi normale multivariée) On peut étendre les lois normales au cas multi-dimensionnel. Fixons d\\in\\mathbb{N}^* un entier non nul. Pour un vecteur \\mu \\in \\mathbb{R}^d et une matrice symétrique-définie positive \\Sigma\\in \\mathbb{R^{d\\times d}}, la densité normale mutlivariée associée est donnée par la fonction: \nf(x) = \\frac{1}{{(2 \\pi)}^{\\frac{d}{2}} {\\rm det}(\\Sigma)} e^{-\\frac{1}{2}(x-\\mu)^\\top \\Sigma ^{-1}(x-\\mu)}\n Notons que \\mu est l’espérance de la loi et \\Sigma la matrice de variance-covariance.",
    "crumbs": [
      "Cours",
      "Notations et rappels"
    ]
  },
  {
    "objectID": "Courses/notations.html#fonction-de-répartition",
    "href": "Courses/notations.html#fonction-de-répartition",
    "title": "Notations et rappels",
    "section": "Fonction de répartition",
    "text": "Fonction de répartition\nLa notion de variable aléatoire n’est pas facile à manipuler puisqu’elle part d’un espace \\Omega dont on ne sait rien. On souhaite donc caractériser la loi d’une variable aléatoire en ne considérant que l’espace d’arrivée (E, \\mathcal{E}) .\nPlusieurs outils existent : la fonction de répartition (pour des variables aléatoires réelles), la fonction caractéristique (pour des variables aléatoires dans \\mathbb{R}^d), la fonction génératrice des moments (pour des variables aléatoires discrètes), etc. On se contente ici de la fonction de répartition qui nous sera utile pour simuler des variables aléatoires, ainsi que son inverse au sens de Levy.\n\nDéfinition 3 (Fonction de répartition 🇬🇧: cumulative distribution function) \nSoit X une variable aléatoire sur (\\mathbb{R}, \\mathcal{B}(\\mathbb{R})). La fonction de répartition de X est la fonction F_X définie sur \\mathbb{R} par \n\\begin{align*}\n    F_X(x) & = \\mathbb{P}(X \\leq x)\\\\\n           & = \\mathbb{P}(X \\in ]-\\infty, x]) \\enspace.\n\\end{align*}\n\n\n\nExemple 9 (Cas discret) Soit (x_i)_{i \\in I} une suite ordonnée de réels, avec I \\subset \\mathbb{N}. Si X est une variable aléatoire discrète prenant les valeurs (x_i)_{i \\in I} et de loi (p_i = \\mathbb{P}(X=x_i))_{i \\in I}, alors \n    F_X(x) = \\sum_{i \\in I} p_i {1\\hspace{-3.8pt} 1}_{[x_i, \\infty[}(x) \\enspace.\n\n\n\nExemple 10 (Cas continu) Si X est une variable aléatoire de densité f, alors \n    F_X(x) = \\int_{-\\infty}^x f(t) \\, \\mathrm dt \\enspace.\n\n\nLe graphe des fonctions de répartition des loi de Bernoulli, uniforme et normale sont représentées dans le widget ci-dessous. Notons que la fonction de répartition de la loi normale \\mathcal{N}(0,1), souvent notée \\Phi, n’admet pas d’expression explicite autre que \n\\Phi(x) = \\dfrac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^x e^{-\\frac{t^2}{2}}\\, \\mathrm d t\\enspace,\n Les valeurs numériques de \\Phi(x) étaient autrefois reportées dans des tables1. Par transformation affine, si X \\sim \\mathcal{N}(\\mu, \\sigma^2) — ce que l’on peut aussi écrire : X=\\mu + \\sigma Y, avec Y\\sim \\mathcal{N}(0,1) — alors sa fonction de répartition est donnée par F_X(x)=\\Phi((x-\\mu)/\\sigma).\n1 Wikipedia: loi normale\nProposition 1 (Propriétés de la fonction de répartition) Soit X une variable aléatoire de fonction de répartition F_X.\n\nF_X est une fonction croissante, de limite 0 en -\\infty et de limite 1 en +\\infty.\nF_X est continue à droite en tout point.\nPour tout x \\in \\mathbb{R}, on a \\mathbb{P}(X=x) = F_X(x) - F_X(x-), où F_X(x-) = \\lim_{\\epsilon \\to 0+} F_X(x- \\epsilon).\nSi X a pour densité f, alors F_X est dérivable \\lambda-presque partout de dérivée f.\n\n\nPour les démonstrations, voir par exemple [@Barbe_Ledoux06].\nLa propriété 3. est utile dans le cas discret : les valeurs prises par X correspondent aux points de discontinuité de F_X et les probabilités associées correspondent à la hauteur du saut.\nLa propriété 4. donne le lien entre la fonction de répartition d’une variable aléatoire à densité et sa densité. On peut donc retrouver la loi de X à partir de sa fonction de répartition. Le théorème suivant généralise ce résultat à toute variable aléatoire réelle (pas nécessairement discrète ou à densité).\n\nThéorème 1 (Caractérisation de la loi d’une variable aléatoire réelle) La fonction de répartition d’une variable aléatoire caractérise sa loi : deux variables aléatoires ont même loi si et seulement si elles ont même fonction de répartition.\n\nDémonstration: voir Wikipedia\nOn rappelle que la tribu des boréliens est engendrée par la famille d’ensembles \\{]-\\infty,x], x \\in \\mathbb{R}\\}. Le théorème précédent assure que si on connaît la mesure \\mathbb{P}_X sur cette famille d’ensembles alors on la connaît partout.\n\nExemple 11 (Loi exponentielle depuis une loi uniforme) On considère une variable aléatoire U de loi uniforme sur [0,1] et on pose X = -\\ln(1-U). Déterminons la loi de X en calculant sa fonction de répartition. Pour tout x \\in \\mathbb{R}, \n\\begin{align*}\nF_X(x) = & \\mathbb{P}(X \\leq x) \\\\\n       = & \\mathbb{P}(-\\ln(1-U) \\leq x) \\\\\n       = & \\mathbb{P}(U \\leq 1-e^{-x}) \\\\\n       = &\n    \\begin{cases}\n        0           & \\text{ si }x &lt; 0\\,,    \\\\\n        1 - e^{-x} & \\text{ si }x \\geq 0\\,,\n    \\end{cases}\n\\end{align*}\n\noù on a utilisé l’égalité \\mathbb{P}(U \\leq t) = t pour tout t \\in [0,1]. Ainsi la variable aléatoire X a la même fonction de répartition qu’une loi exponentielle de paramètre 1. On en conclut que X \\sim \\mathcal{Exp}(1). Notons que l’on peut aussi montrer que -\\ln(X)\\sim\\mathcal{E}(1), sachant que U et 1-U ont la même loi.",
    "crumbs": [
      "Cours",
      "Notations et rappels"
    ]
  },
  {
    "objectID": "Courses/notations.html#fonction-quantile-inverse-généralisée-à-gauche",
    "href": "Courses/notations.html#fonction-quantile-inverse-généralisée-à-gauche",
    "title": "Notations et rappels",
    "section": "Fonction quantile, inverse généralisée à gauche",
    "text": "Fonction quantile, inverse généralisée à gauche\nLa fonction de répartition étant une fonction croissante on peut donner un sens à son inverse généralisée de la manière suivante.\n\nDéfinition 4 (Fonction quantile/ inverse généralisée 🇬🇧: quantile distribution function) \nSoit X une variable aléatoire sur (\\mathbb{R}, \\mathcal{B}(\\mathbb{R})) et F_X sa fonction de répartition. La fonction quantile associée F_X^\\leftarrow:  ]0,1[ \\rightarrow \\mathbb{R} est définie par \n  F_X^\\leftarrow(p)=  \\inf\\{ x \\in \\mathbb{R} \\colon F_X(x)\\geq p\\} \\enspace.\n\n\nOn parle parfois aussi d’inverse au sens de Levy pour cette inverse généralisée.\nDans le cas où la fonction de répartition F_X est bijective, alors l’inverse de la fonction de répartition coincide avec la fonction quantile.\nLa médiane est égale à F_X^\\leftarrow(1/2), les premiers et troisièmes quartiles sont égaux à F_X^\\leftarrow(1/4) et F_X^\\leftarrow(3/4). Enfin, les déciles sont les quantiles F_X^\\leftarrow(k/10) pour k=1,\\dots, 9.",
    "crumbs": [
      "Cours",
      "Notations et rappels"
    ]
  },
  {
    "objectID": "Courses/notations.html#visualisation-densité-fonction-de-répartition-quantiles-etc.",
    "href": "Courses/notations.html#visualisation-densité-fonction-de-répartition-quantiles-etc.",
    "title": "Notations et rappels",
    "section": "Visualisation: densité, fonction de répartition, quantiles, etc.",
    "text": "Visualisation: densité, fonction de répartition, quantiles, etc.\n\nCas des variables continues\n\nObservablePython / Shiny\n\n\n\nPlotly = require('plotly.js-dist');\ndists = require( 'https://cdn.jsdelivr.net/gh/stdlib-js/stats-base-dists@umd/browser.js' );\n// see source here: https://github.com/stdlib-js/stats-base-dists/tree/umd\n// continuous case\njstatPDFs = () =&gt; {\n  const distributions = Object.keys(dists);\n  // Get in continuousDistributions the distributions whose pdf, cdf and quantile are defined\n    const continuousDistributions = distributions.filter(name =&gt; dists[name].pdf && dists[name].cdf && dists[name].quantile);\n  return continuousDistributions\n};\noutput = jstatPDFs();\n\nexcludedPDFs = [];\npdfNames_unsorted = output.filter(name =&gt; !excludedPDFs.includes(name));\npdfNames=pdfNames_unsorted.toSorted();\nviewof inputs = Inputs.form([\n      Inputs.range([-10, 10], {value: 0.1, step: 0.001, label: tex`\\mu`}),\n      Inputs.range([0.01, 5], {value: 1.01, step: 0.001, label: tex`\\sigma`}),\n      Inputs.range([0.001, 0.999], {value: 0.75, step: 0.001, label:tex`\\alpha`}),\n    ]);\n\nviewof distrib_name = Inputs.select(pdfNames, {value: \"normal\", label: \"Distribution\"});\n\n\n{\n  const x = d3.range(-5, 5, 0.01);\n  const pdf = x.map(x =&gt; dists[distrib_name].pdf(x, mu, sigma));\n  const cdf = x.map(x =&gt; dists[distrib_name].cdf(x, mu, sigma));\n  const inv = x.map(x =&gt; dists[distrib_name].quantile(x, mu, sigma));\n  const quantile = dists[distrib_name].quantile(alpha, mu, sigma);\n  const filteredX = x.filter(coord =&gt; coord &lt;= quantile);\n  const filteredPdf = pdf.filter((_, i) =&gt; x[i] &lt;= quantile);\n  const filteredCdf = cdf.filter(coord =&gt; coord &lt;= quantile);\n\n\n{\nvar trace1 = {\n      type: \"scatter\",\n      name: 'Quantile',\n      x : cdf,\n      y : x,\n      line: {color: 'black'},\n      xaxis: 'x1',\n      yaxis: 'y3',\n\n\n};\n\nvar trace12 = {\n        x : [alpha, alpha],\n        y : [x[0], quantile],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y3',\n\n\n};\n\n\n\nvar trace13 = {\n    x: [0, alpha],\n    y: [quantile, quantile],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x1',\n    yaxis: 'y3'\n}\n\n\nvar trace2 = {\nx: cdf,\ny: cdf,\ntype: 'scatter',\nname: 'identity',\nline: {color: 'black'},\nxaxis: 'x1',\nyaxis: 'y2'\n\n};\n\n\nvar trace21 = {\n        x : [alpha, 1],\n        y : [alpha, alpha],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y2'\n}\n\nvar trace22 = {\n        x : [alpha, alpha],\n        y : [alpha, 1],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y2'\n}\n\n\n\nvar trace23 = {\n    x: [alpha],\n    y: [alpha],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x1',\n    yaxis: 'y2'\n}\n\n\nvar trace31 = {\n      type: \"scatter\",\n      mode: \"lines\",\n      name: 'PDF2',\n      x: x,\n      y: cdf,\n      line: {color: 'black'},\n      xaxis: 'x2',\n      yaxis: 'y2',\n};\n\nvar trace32 = {\n        x : filteredX,\n        y : filteredX.map(x =&gt; alpha),\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n          },\n      xaxis: 'x2',\n      yaxis: 'y2'\n}\n\nvar trace33 = {\n        x : [quantile, quantile],\n        y : [0, alpha],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n          },\n\n      xaxis: 'x2',\n      yaxis: 'y2'\n}\n\nvar trace34 = {\n    x: [quantile],\n    y: [alpha],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x2',\n    yaxis: 'y2'\n}\n\n\nvar trace41 = {\n\n  type: \"scatter\",\n  name: 'Quantile2',\n  fill: 'tozeroy',\n  x : filteredX,\n  y : filteredPdf,\n  opacity: 0.9,\n  line: {color: ' #428BCA'},\n  xaxis: 'x2',\n  yaxis: 'y1'\n\n};\n\n\nvar trace42 = {\n\n  type: \"scatter\",\n  mode: \"lines\",\n  name: 'PDF2',\n  x: x,\n  y: pdf,\n  line: {color: 'black'},\n  xaxis: 'x2',\n  yaxis: 'y1'\n\n};\n\nvar data = [\n  trace1,\n  trace12, trace13,\n  trace2, trace21, trace22, trace23,\n  trace31, trace32, trace33, trace34,\n  trace41, trace42];\n\n\nvar layout = {\n\n  title: 'Distribution et quantile',\n  xaxis: {\n    domain: [0, 0.32],\n    anchor: 'y1'\n  },\n  yaxis: {\n    domain: [0, 0.24],\n    anchor: 'x1'\n\n  },\n  xaxis2: {\n    domain: [0.35, 1],\n    anchor: 'y'\n  },\n\n  yaxis2: {\n    domain: [0.26, 0.49],\n    anchor: 'x1'\n  },\n\n  yaxis3: {\n    domain: [0.5, 1],\n    anchor: 'x1'\n  },\n\n// legend offset\n  showlegend: false,\n  height: 680,\n  annotations: [\n\n    {\n      x: 1/4,\n      y: quantile - (x[0]-x.slice(-1))/20,\n      xref: 'x1',\n      yref: 'y3',\n      text: 'q= ' + quantile.toFixed(2),\n      font: {\n        size: 12,\n        color: '#428BCA',\n\n      },\n      showarrow: false,\n      arrowhead: 0,\n      ax: 25,\n      ay: -10,\n\n    },\n    {\n      x: 1/4,\n      y: alpha,\n      xref: 'x1',\n      yref: 'y2',\n      text: 'alpha= ' + alpha.toFixed(2),\n      font: {\n        size: 12,\n        color: '#428BCA',\n\n      },\n      showarrow: false,\n      arrowhead: 0,\n      ax: 25,\n      ay: -10,\n\n    },\n    {\n        text: \"Fonction quantile\",\n      font: {\n      size: 15,\n      color: 'black',\n    },\n    showarrow: false,\n    align: 'center',\n    x: -0.01,\n    y: 1.05,\n    xref: 'paper',\n    yref: 'paper',\n    },\n    {\n      text: \"Fonction de répartition\",\n      font: {\n      size: 15,\n      color: 'black',\n            },\n    showarrow: false,\n    align: 'center',\n    x: 0.65,\n    y: 0.52,\n    xref: 'paper',\n    yref: 'paper',\n    },\n    {\n      text: \"Fonction de densité\",\n      font: {\n      size: 15,\n      color: 'black',\n            },\n    showarrow: false,\n    align: 'center',\n    x: 0.65,\n    y: 0.225,\n    xref: 'paper',\n    yref: 'paper',\n    },\n  ]\n\n};\n// XXX: TODO: put the xticks labels on the middle plot for x and on the right plot for y\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.newPlot(div, data, layout, config);\n    return div;\n  }\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmu = inputs[0];\nsigma = inputs[1];\nalpha = inputs[2]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| standalone: true\n#| viewerHeight: 830\nimport numpy as np\nfrom scipy import stats\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom shiny import ui, render, App\nfrom shinywidgets import output_widget, render_widget\n\n\ndef keep_no_param_distribution():\n    distributions = stats._continuous_distns._distn_names\n    distributions_0 = []\n    for _, name in enumerate(distributions):\n        dist = getattr(stats, name)\n        if not dist.shapes or len(dist.shapes) == 0:\n            distributions_0.append(name)\n    distributions_0_val = [\n        getattr(stats.distributions, string) for string in distributions_0\n    ]\n    distributions_0_dict = dict(zip(distributions_0, distributions_0_val))\n    return distributions_0_dict\n\n\ndistributions_0_dict = keep_no_param_distribution()\n\nmu = 0\nsigma = 1\n\napp_ui = ui.page_fluid(\n    ui.div(\n        ui.input_slider(\"alpha\", \"Quantile\", 0.01, 0.99, value=0.5, step=0.01),\n        ui.input_slider(\"xrange\", \"x-range\", -10, 10, value=(-5, 5), step=0.2),\n        ui.input_select(\n            \"distrib\",\n            \"Distribution\",\n            list(distributions_0_dict.keys()),\n            selected='norm'\n        ),\n        class_=\"d-flex gap-3\",\n    ),\n    output_widget(\"my_widget\"),\n)\n\n\ndef server(input, output, session):\n    @output\n    @render_widget\n    def my_widget():\n        fig = make_subplots(\n            rows=3,\n            cols=2,\n            vertical_spacing=0.1,\n            horizontal_spacing=0.15,\n            subplot_titles=(\n                \"Fonction quantile\",\n                \"\",\n                \"\",\n                \"Fonction de répartition\",\n                \"\",\n                \"Densité et quantile\",\n            ),\n            column_widths=[0.2, 0.5],\n            row_heights=[0.35, 0.17, 0.17],\n        )\n\n        alpha = input.alpha()\n        distribution = distributions_0_dict[input.distrib()]\n        x = np.linspace(input.xrange()[0], input.xrange()[1], num=400)\n        cdf_data = distribution.cdf(x, loc=mu, scale=sigma)\n        pdf_data = distribution.pdf(x, loc=mu, scale=sigma)\n        q_alpha = distribution.ppf(alpha, loc=mu, scale=sigma)\n\n        fig.update_layout(autosize=True, height=700)\n\n        # Quantile plot\n        fig.add_trace(\n            go.Scatter(\n                x=cdf_data, y=x, mode=\"lines\", marker={\"color\": \"black\"}\n            ),\n            row=1,\n            col=1,\n        )\n        # Diagonal\n        fig.add_trace(\n            go.Scatter(\n                x=cdf_data, y=cdf_data, mode=\"lines\", marker={\"color\": \"black\"}\n            ),\n            row=2,\n            col=1,\n        )\n        # Cdf part\n        fig.add_trace(\n            go.Scatter(\n                x=x, y=cdf_data, mode=\"lines\", marker={\"color\": \"black\"}\n            ),\n            row=2,\n            col=2,\n        )\n        # pdf part\n        fig.add_scatter(\n            x=x[x &lt; q_alpha],\n            y=pdf_data[x &lt; q_alpha],\n            fill=\"tozeroy\",\n            mode=\"none\",\n            fillcolor=\"rgb(66, 139, 202)\",\n            row=3,\n            col=2,\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=x, y=pdf_data, mode=\"lines\", marker={\"color\": \"black\"}\n            ),\n            row=3,\n            col=2,\n        )\n\n        # Dots\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha],\n                y=[q_alpha],\n                mode=\"markers\",\n                marker={\"color\": \"rgb(66, 139, 202)\"},\n                marker_symbol=\"x\",\n                marker_size=8,\n            ),\n            row=1,\n            col=1,\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha],\n                y=[alpha],\n                mode=\"markers\",\n                marker={\"color\": \"rgb(66, 139, 202)\"},\n                marker_symbol=\"x\",\n                marker_size=8,\n            ),\n            row=2,\n            col=1,\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=[q_alpha],\n                y=[alpha],\n                mode=\"markers\",\n                marker={\"color\": \"rgb(66, 139, 202)\"},\n                marker_symbol=\"x\",\n                marker_size=8,\n            ),\n            row=2,\n            col=2,\n        )\n\n        # Lines\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha, alpha],\n                y=[x[0], q_alpha],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=1,\n            col=1\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha, alpha],\n                y=[alpha, 1.],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=2,\n            col=1\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha, 1],\n                y=[alpha, alpha],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=2,\n            col=1\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=[x[0], q_alpha],\n                y=[alpha, alpha],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=2,\n            col=2\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=[x[0], q_alpha],\n                y=[x[0], 0],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=2,\n            col=2\n        )\n        # Axes ranges\n        fig.update_xaxes(range=[0, 1.], row=1, col=1)\n        fig.update_yaxes(matches=\"x6\", row=1, col=1)\n\n        fig.update_yaxes(range=[0, 1.], row=2, col=1)\n        fig.update_xaxes(matches=\"x1\", row=2, col=1)\n\n        fig.update_yaxes(rangemode=\"tozero\", row=3, col=2)\n        fig.update_xaxes(range=[x[0], x[-1]], row=3, col=2)\n\n        fig.update_xaxes(matches=\"x6\", row=2, col=2)\n        fig.update_yaxes(matches=\"y3\", row=2, col=2)\n\n        # Add dropdown\n        fig.update_layout(\n            showlegend=False,\n            template=\"simple_white\",\n        )\n        return fig\n\n\napp = App(app_ui, server)\n\n\n\n\n\n\nCas des variables discrètes\n\nObservablePython / Shiny\n\n\n\ndiscretePDFs = () =&gt; {\n  const distributions = Object.keys(dists);\n  // Get in continuousDistributions the distributions whose pdf, cdf and quantile are defined\n    const continuousDistributions = distributions.filter(name =&gt; dists[name].pmf && dists[name].cdf && dists[name].quantile);\n  return continuousDistributions\n};\noutput_discr = discretePDFs();\n\npmfNames_unsorted = output_discr.filter(name =&gt; !excludedPDFs.includes(name));\npmfNames=pmfNames_unsorted.toSorted();\nviewof inputs_disc = Inputs.form([\n      Inputs.range([-10, 10], {value: 0.1, step: 0.001, label: tex`\\mu `}),\n      Inputs.range([0.01, 5], {value: 1.01, step: 0.001, label: tex`\\sigma `}),\n      Inputs.range([0.001, 0.999], {value: 0.75, step: 0.001, label:tex`\\alpha`}),\n    ]);\n\nviewof distrib_name_discr = Inputs.select(pmfNames, {value: \"normal\", label: \"Distribution\"});\n\n\n{\n  const z = d3.range(-5, 5, 0.01);\n  const pmf = z.map(z =&gt; dists[distrib_name_discr].pmf(z, mu_disc, sigma_disc));\n  const cdf = z.map(z =&gt; dists[distrib_name_discr].cdf(z, mu_disc, sigma_disc));\n  const inv = z.map(z =&gt; dists[distrib_name_discr].quantile(z, mu_disc, sigma_disc));\n  const quantile = dists[distrib_name_discr].quantile(alpha_disc, mu_disc, sigma_disc);\n  const filteredX = z.filter(coord =&gt; coord &lt;= quantile);\n  const filteredPmf = pmf.filter((_, i) =&gt; z[i] &lt;= quantile);\n  const filteredCdf = cdf.filter(coord =&gt; coord &lt;= quantile);\n\n\n{\nvar trace1 = {\n      type: \"scatter\",\n      name: 'Quantile',\n      x : cdf,\n      y : z,\n      line: {color: 'black'},\n      xaxis: 'x1',\n      yaxis: 'y3',\n\n\n};\n\nvar trace12 = {\n        x : [alpha_disc, alpha_disc],\n        y : [z[0], quantile],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y3',\n\n\n};\n\n\n\nvar trace13 = {\n    x: [0, alpha_disc],\n    y: [quantile, quantile],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x1',\n    yaxis: 'y3'\n}\n\n\nvar trace2 = {\nx: cdf,\ny: cdf,\ntype: 'scatter',\nname: 'identity',\nline: {color: 'black'},\nxaxis: 'x1',\nyaxis: 'y2'\n\n};\n\n\nvar trace21 = {\n        x : [alpha_disc, 1],\n        y : [alpha_disc, alpha_disc],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y2'\n}\n\nvar trace22 = {\n        x : [alpha_disc, alpha_disc],\n        y : [alpha_disc, 1],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n\n          },\n      xaxis: 'x1',\n      yaxis: 'y2'\n}\n\nvar trace23 = {\n    x: [alpha_disc],\n    y: [alpha_disc],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x1',\n    yaxis: 'y2'\n}\n\n\nvar trace31 = {\n      type: \"scatter\",\n      mode: \"lines\",\n      name: 'PDF2',\n      x: z,\n      y: cdf,\n      line: {color: 'black'},\n      xaxis: 'x2',\n      yaxis: 'y2',\n};\n\nvar trace32 = {\n        x : filteredX,\n        y : filteredX.map(z =&gt; alpha_disc),\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n          },\n      xaxis: 'x2',\n      yaxis: 'y2'\n}\n\nvar trace33 = {\n        x : [quantile, quantile],\n        y : [0, alpha_disc],\n        mode: 'lines',\n        line: {\n            dash: 'dash',\n            width: 1,\n            color: ' #428BCA',\n            marks: {\n                size: 0,\n                color: ' #428BCA',\n            }\n          },\n\n      xaxis: 'x2',\n      yaxis: 'y2'\n}\n\nvar trace34 = {\n    x: [quantile],\n    y: [alpha_disc],\n    mode: 'scatter',\n    line: {\n        dash: 'dash',\n        width: 1,\n        color: ' #428BCA',\n        marks: {\n            size: 0,\n        }\n    },\n    xaxis: 'x2',\n    yaxis: 'y2'\n}\n\n\nvar trace41 = {\n\n  type: \"scatter\",\n  name: 'Quantile2',\n  fill: 'tozeroy',\n  x : filteredX,\n  y : filteredPmf,\n  opacity: 0.9,\n  line: {color: ' #428BCA'},\n  xaxis: 'x2',\n  yaxis: 'y1'\n\n};\n\n\nvar trace42 = {\n\n  type: \"scatter\",\n  mode: \"lines\",\n  name: 'PDF2',\n  x: z,\n  y: pmf,\n  line: {color: 'black'},\n  xaxis: 'x2',\n  yaxis: 'y1'\n\n};\n\nvar data = [\n  trace1,\n  trace12, trace13,\n  trace2, trace21, trace22, trace23,\n  trace31, trace32, trace33, trace34,\n  trace41, trace42];\n\n\nvar layout = {\n\n  title: 'Distribution et quantile',\n  xaxis: {\n    domain: [0, 0.32],\n    anchor: 'y1'\n  },\n  yaxis: {\n    domain: [0, 0.24],\n    anchor: 'x1'\n\n  },\n  xaxis2: {\n    domain: [0.35, 1],\n    anchor: 'y'\n  },\n\n  yaxis2: {\n    domain: [0.26, 0.49],\n    anchor: 'x1'\n  },\n\n\n\n  yaxis3: {\n    domain: [0.5, 1],\n    anchor: 'x1'\n\n  },\n\n  showlegend: false,\n  height: 680,\n\n  annotations: [\n\n    {\n      x: 1/4,\n      y: quantile - (z[0]-z.slice(-1))/20,\n      xref: 'x1',\n      yref: 'y3',\n      text: 'q=' + quantile.toFixed(2),\n      font: {\n        size: 12,\n        color: '#428BCA',\n\n      },\n      showarrow: false,\n      arrowhead: 0,\n      ax: 25,\n      ay: -10,\n\n    },\n    {\n      x: 1/4,\n      y: alpha_disc,\n      xref: 'x1',\n      yref: 'y2',\n      text: 'alpha=' + alpha_disc.toFixed(2),\n      font: {\n        size: 12,\n        color: '#428BCA',\n\n      },\n      showarrow: false,\n      arrowhead: 0,\n      ax: 25,\n      ay: -10,\n\n    },\n    {\n        text: \"Fonction quantile\",\n      font: {\n      size: 15,\n      color: 'black',\n    },\n    showarrow: false,\n    align: 'center',\n    x: -0.01,\n    y: 1.05,\n    xref: 'paper',\n    yref: 'paper',\n    },\n    {\n      text: \"Fonction de répartition\",\n      font: {\n      size: 15,\n      color: 'black',\n            },\n    showarrow: false,\n    align: 'center',\n    x: 0.65,\n    y: 0.52,\n    xref: 'paper',\n    yref: 'paper',\n    },\n    {\n      text: \"Fonction de densité\",\n      font: {\n      size: 15,\n      color: 'black',\n            },\n    showarrow: false,\n    align: 'center',\n    x: 0.65,\n    y: 0.225,\n    xref: 'paper',\n    yref: 'paper',\n    },\n  ]\n\n};\n// XXX: TODO: put the xticks labels on the middle plot for x and on the right plot for y\n\n    var config = {responsive: true}\n    const div = DOM.element('div');\n    Plotly.newPlot(div, data, layout, config);\n    return div;\n  }\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmu_disc = inputs_disc[0];\nsigma_disc = inputs_disc[1];\nalpha_disc = inputs_disc[2];\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| standalone: true\n#| viewerHeight: 830\nimport numpy as np\nfrom scipy import stats\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom shiny import ui, render, App\nfrom shinywidgets import output_widget, render_widget\n\n\ndef keep_no_param_distribution_disc():\n    distributions = stats._discrete_distns._distn_names\n    distributions_0 = [name for name in distributions if not getattr(stats, name).shapes or len(getattr(stats, name).shapes) in [1, 2]]\n    distributions_0_val = [getattr(stats.distributions, string) for string in distributions_0]\n    distributions_0_dict = dict(zip(distributions_0, distributions_0_val))\n    return distributions_0_dict\n\ndef cdf_tool(x, dtype='int64'):\n    y = np.zeros(2*(len(x)), dtype=dtype)\n    y[::2]=x\n    y[1::2]=x\n    return y[1::], y[:-1], y\n\ndef pmf_tool(x, dtype='int64'):\n    y = np.zeros(2*(len(x)), dtype=dtype)\n    y[::2]=x\n    return y[1::], y[:-1], y\n\ndef insert_nones(my_list):\n    for i, val in enumerate(my_list):\n        if i % 3 == 2:\n            my_list.insert(i, None)\n    return my_list\n\ndistributions_0_dict = keep_no_param_distribution_disc()\n\napp_ui = ui.page_fluid(\n    ui.div(\n        ui.input_slider(\"alpha\", \"Quantile\", 0.01, 0.99, value=0.5, step=0.01),\n        ui.input_slider(\"xrange\", \"x-range\", -10, 10, value=(-5.5, 5.5), step=0.2),\n        ui.input_select(\n            \"distrib\",\n            \"Distribution\",\n            list(distributions_0_dict.keys()),\n            selected='poisson'\n        ),\n        class_=\"d-flex gap-3\",\n    ),\n    output_widget(\"my_widget\"),\n)\n\n\ndef server(input, output, session):\n    @output\n    @render_widget\n    def my_widget():\n        fig = make_subplots(\n            rows=3,\n            cols=2,\n            vertical_spacing=0.1,\n            horizontal_spacing=0.15,\n            subplot_titles=(\n                \"Fonction quantile\",\n                \"\",\n                \"\",\n                \"Fonction de répartition\",\n                \"\",\n                \"Fonction de masse et quantile\",\n            ),\n            column_widths=[0.2, 0.5],\n            row_heights=[0.35, 0.17, 0.17],\n        )\n\n\n        alpha = input.alpha()\n        # alpha=0.5\n\n        mu = 0.5  # Param needed for some distribution\n        if input.distrib()=='zipf':\n            mu = 2\n        distribution = distributions_0_dict[input.distrib()]\n        # distribution=distributions_0_dict['poisson']\n        x = np.arange(np.floor(input.xrange()[0]), np.ceil(input.xrange()[1]))\n        # x = np.arange(np.floor(-5.5), np.ceil(5.5))\n\n        cdf_data = distribution.cdf(x, mu)\n        pmf_data = distribution.pmf(x, mu)\n        q_alpha = distribution.ppf(alpha, mu)\n        support = pmf_data.nonzero()[0]\n        fig.update_layout(autosize=True, height=700)\n\n        # Quantile plot\n        new_x, new_y, new_z = cdf_tool(support)\n        _, _, new_pmf = pmf_tool(support)\n\n        fig.add_trace(\n            go.Scatter(\n                x=insert_nones(list(np.append(cdf_data[new_y[::-1]], distribution.cdf(x[0], mu)))),\n                y=insert_nones(list(np.append(x[new_x[::-1]], x[new_x[0]]))),\n                mode=\"lines\",\n                line=dict(color=\"black\")\n            ),\n            row=1,\n            col=1,\n        )\n        fig.add_trace(\n             go.Scatter(\n                x=cdf_data[support], y=x[support],\n                mode=\"markers\", marker={\"color\": \"black\"}\n            ),\n            row=1,\n            col=1,\n        )\n        # Diagonal\n        fig.add_trace(\n            go.Scatter(\n                x=cdf_data, y=cdf_data, mode=\"lines\", marker={\"color\": \"black\"}\n            ),\n            row=2,\n            col=1,\n        )\n        # Cdf part\n        fig.add_trace(\n            go.Scatter(\n                x=x[support], y=cdf_data[support],\n                mode=\"markers\", marker={\"color\": \"black\"}\n            ),\n            row=2,\n            col=2,\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=insert_nones(list(np.append(np.insert(x[new_x], 0, [x[0], x[new_x[0]]]),x[-1]))),\n                y=insert_nones(list(np.append(np.insert(cdf_data[new_y], 0, [0,0]), cdf_data[-1]))),\n                mode=\"lines\",\n                line=dict(color=\"black\")\n            ),\n            row=2,\n            col=2\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=x, y=pmf_data, mode=\"markers\", marker={\"color\": \"black\"}\n            ),\n            row=3,\n            col=2,\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=x, y=pmf_data, mode=\"markers\", marker={\"color\": \"black\"}\n            ),\n            row=3,\n            col=2,\n        )\n        x_bar = insert_nones(list(x[new_z]))\n        y_bar = insert_nones(list(pmf_data[new_pmf]))\n        fig.add_trace(\n            go.Scatter(\n                x=x_bar,\n                y=y_bar,\n                mode=\"lines\",\n                line=dict(color=\"black\")\n            ),\n            row=3,\n            col=2\n        )\n        _,_, devil_x = cdf_tool(x[x&lt;=q_alpha])\n        _,_, devil_y = cdf_tool(pmf_data[x&lt;q_alpha], dtype='float64')\n\n        x_bar_blue = insert_nones(list(devil_x))\n        y_bar_blue = np.array(insert_nones(list(devil_y)))\n        y_bar_blue[::-3]=0.\n        y_bar_blue = list(y_bar_blue)\n        fig.add_trace(\n            go.Scatter(\n                x=x_bar_blue,\n                y=y_bar_blue,\n                mode=\"lines\",\n                line=dict(color=\"rgb(66, 139, 202)\")\n            ),\n            row=3,\n            col=2\n        )\n        # pdf part\n        fig.add_scatter(\n            x=x[x &lt;= q_alpha],\n            y=pmf_data[x &lt;= q_alpha],\n            mode=\"markers\",\n            marker={\"color\":\"rgb(66, 139, 202)\"},\n            row=3,\n            col=2,\n        )\n\n        # Dots\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha],\n                y=[q_alpha],\n                mode=\"markers\",\n                marker={\"color\": \"rgb(66, 139, 202)\"},\n                marker_symbol=\"x\",\n                marker_size=8,\n            ),\n            row=1,\n            col=1,\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha],\n                y=[alpha],\n                mode=\"markers\",\n                marker={\"color\": \"rgb(66, 139, 202)\"},\n                marker_symbol=\"x\",\n                marker_size=8,\n            ),\n            row=2,\n            col=1,\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=[q_alpha],\n                y=[alpha],\n                mode=\"markers\",\n                marker={\"color\": \"rgb(66, 139, 202)\"},\n                marker_symbol=\"x\",\n                marker_size=8,\n            ),\n            row=2,\n            col=2,\n        )\n\n        # Lines\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha, alpha],\n                y=[x[0], q_alpha],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=1,\n            col=1\n        )\n\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha, alpha],\n                y=[alpha, 1.],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=2,\n            col=1\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=[alpha, 1],\n                y=[alpha, alpha],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=2,\n            col=1\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=[x[0], q_alpha],\n                y=[alpha, alpha],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=2,\n            col=2\n        )\n        fig.add_trace(\n            go.Scatter(\n                x=[x[0], q_alpha],\n                y=[x[0], 0],\n                mode=\"lines\",\n                line=dict(dash=\"dash\", color=\"rgb(66, 139, 202)\")\n            ),\n            row=2,\n            col=2\n        )\n        # Axes ranges\n        fig.update_xaxes(range=[0, 1.05], row=1, col=1)\n        fig.update_yaxes(matches=\"x6\", row=1, col=1)\n\n        fig.update_yaxes(range=[0, 1.05], row=2, col=1)\n        fig.update_xaxes(matches=\"x1\", row=2, col=1)\n\n        fig.update_yaxes(rangemode=\"tozero\", row=3, col=2)\n        fig.update_xaxes(range=[x[0], x[-1]], row=3, col=2)\n\n        fig.update_xaxes(matches=\"x6\", row=2, col=2)\n        fig.update_yaxes(matches=\"y3\", row=2, col=2)\n\n        # Add dropdown\n        fig.update_layout(\n            showlegend=False,\n            template=\"simple_white\",\n        )\n        return fig\n\n\napp = App(app_ui, server)",
    "crumbs": [
      "Cours",
      "Notations et rappels"
    ]
  },
  {
    "objectID": "Courses/simulation.html",
    "href": "Courses/simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Dans ce chapitre on se demande comment simuler en pratique des variables aléatoires i.i.d. L’idée est de commencer par le cas de variables aléatoires de loi uniforme et d’en déduire les autres lois.",
    "crumbs": [
      "Cours",
      "Simulation"
    ]
  },
  {
    "objectID": "Courses/simulation.html#variables-aléatoires-uniformes",
    "href": "Courses/simulation.html#variables-aléatoires-uniformes",
    "title": "Simulation",
    "section": "Variables aléatoires uniformes",
    "text": "Variables aléatoires uniformes\nOn rappelle qu’une variable aléatoire U suit une loi uniforme sur [0,1], noté \\mathcal{U}([0,1]) si sa fonction de répartition F_U est donnée par \nF_U(x)\n=\n\\begin{cases}\n    0, & \\text{si }x &lt; 0\\,,        \\\\\n    x, & \\text{si }x \\in [0,1]\\,,  \\\\\n    1, & \\text{si }x &gt; 1\\,.        \\\\\n\\end{cases}\n\n\n\n\n\n                                                \n\n\nFigure 1: Fonction de répartition de la loi uniforme\n\n\n\n\nL’objectif est de simuler sur machine une suite U_1, \\ldots, U_n de variables aléatoires i.i.d. de loi \\mathcal{U}([0,1]). Plusieurs problèmes apparaissent alors :\n\nUne machine est déterministe.\nLes nombres entre 0 et 1 donnés par la machine sont de la forme k/2^p, pour k \\in \\{0, \\ldots, 2^{p-1}\\}. On ne pourra donc jamais générer des nombres qui ne sont pas de cette forme.\nVérifier qu’une suite est bien i.i.d. est un problème difficile.\n\n\nDéfinition 1 (Générateur de nombres pseudo-aléatoires) \nUn générateur de nombres pseudo-aléatoires (🇬🇧: Pseudo Random Number Generator, PRNG), est un algorithme déterministe récursif qui renvoie une suite U_1, \\ldots, U_n dans [0,1] qui a un “comportement similaire” à une suite i.i.d. de loi \\mathcal{U}([0,1]). Pour être plus rigoureux, ces nombres sont en fait des nombres entiers générés uniformément sur un certain interval. Dans un second temps, une transformation simple (normalisation) permet d’obtenir des nombres flottants (🇬🇧: floats) entre 0 et 1.\n\n\n\n\n\n\n\nPour aller plus loin\n\n\n\nParfois il est utile d’aller chercher dans le code source certaines information pour savoir comment les fonctions sont codées dans les packages que l’on utiliser. Par exemple, pour numpy que l’on utilise fréquement, on peut voir l’opération choisie ici: Random: int -&gt; float en numpy.\n\n\nUn tel algorithme se construit de la manière suivante :\n\nOn part d’une graine (🇬🇧: seed) U_0 qui détermine la première valeur de manière la plus arbitraire possible.\nLa procédure récursive s’écrit U_{n+1} = f(U_n), où f est une transformation déterministe, de sorte que U_{n+1} est le plus indépendant possible de U_1, \\dots, U_n.\n\n\nLa fonction f est déterministe et prend ses valeurs dans un ensemble fini, donc l’algorithme est périodique. Le but est donc d’avoir la plus grande période possible.\nNotons qu’une fois que la graine est fixée, alors l’algorithme donne toujours les mêmes valeurs. Fixer la graine peut donc être très utile pour répéter des simulations dans des conditions identiques et ainsi repérer des erreurs.\n\n\n\n\n\n\n\nExercice: bug ou feature?\n\n\n\nReprendre les widgets du chapitre Théorèmes asymptotiques et faites varier doucement le paramètre p (de Bernoulli). Que constatez-vous? Proposer une explication potentielle.\n\n\n\nGénérateur congruentiel linéaire\nLa plupart des PRNG s’appuient sur des résultats arithmétiques. Un des plus connus est celui appelé Générateur congruentiel linéaire (🇬🇧 Linear congruential generator, LCG). Il est défini comme suit: on construit récursivement une suite d’entiers X_i via la congruence \n  X_{n+1} = a X_n + b \\quad \\text{mod } m \\enspace,\n où a,b,m sont des entiers bien choisis pour que la suite obtenue ait de bonnes propriétés. Il suffit alors de considérer X_n/m. Par exemple, la fonction rand sur scilab utilise cette congruence avec m=2^{31}, a=843\\; 314\\; 861, et b=453\\; 816\\; 693.\n\n\nGénérateurs alternatifs\nLes langages Python et R utilisent par défaut le générateur Mersenne-Twister qui s’appuie sur la multiplication vectorielle, mais d’autres générateurs sont aussi disponibles. Ce générateur a pour période m =2^{19937}-1, nombre qu’on peut raisonnablement considérer comme grand.\nPour numpy la méthode par défaut est PCG64 (cf. documentation de numpy), qui dispose de meilleures garanties statistiques (Voir le site https://www.pcg-random.org pour cela).\n\n\nUsage en numpy\nOn suppose désormais disposer d’un générateur pseudo-aléatoire sur [0,1]. En numpy depuis la version 1.17, une bonne manière d’utiliser des éléments aléatoires est d’utiliser un générateur que l’on définit soi-même:\n\nseed = 12345  # Toujours être conscient qu'une graine existe\nrng = np.random.default_rng(seed)  #\nprint(rng.random())  ##  un tirage uniforme sur [0,1]\nprint(rng.random(size=5))  ## cinq tirages uniformes sur [0,1]\nprint(rng.random(size=(3, 2)))  ## matrice 3x2, à entrées unif. sur [0,1]\n\n0.22733602246716966\n[0.31675834 0.79736546 0.67625467 0.39110955 0.33281393]\n[[0.59830875 0.18673419]\n [0.67275604 0.94180287]\n [0.24824571 0.94888115]]\n\n\nDans la suite on va voir comment générer d’autres lois à partir de la loi uniforme, mais il est clair que les logiciels modernes proposent un large éventail de distribution classique (gaussienne, exponentielle, etc.). Une liste exhaustive est donnée ici pour numpy.\n\n\n\n\n\n\nPour aller plus loin\n\n\n\nUne excellent discussion sur les bonnes pratiques aléatoires en numpy, et l’usage de np.random.default_rng est donnée dans ce blog post d’Albert Thomas.\n\n\n\n\nPropriété de la loi uniforme\nOn verra souvent apparaître la variable aléatoire 1-U où U \\sim \\mathcal{U}([0,1]). Il se trouve que 1-U suit aussi une loi uniforme sur [0,1] comme le montre le calcul de sa fonction de répartition. Ainsi pour tout x \\in [0,1] on obtient \n\\begin{align*}\n\\mathbb{P}(1-U \\leq x) & = \\mathbb{P}(U \\geq 1-x),\\\\\n                       & = 1-(1-x), \\\\\n                       & = x\\,.\n\\end{align*}\n On peut démontrer facilement la même relation pour x&lt;0 et x&gt;1, d’où le résultat.",
    "crumbs": [
      "Cours",
      "Simulation"
    ]
  },
  {
    "objectID": "Courses/simulation.html#méthode-dinversion",
    "href": "Courses/simulation.html#méthode-dinversion",
    "title": "Simulation",
    "section": "Méthode d’inversion",
    "text": "Méthode d’inversion\nL’idée de la méthode d’inversion repose sur le résultat suivant :",
    "crumbs": [
      "Cours",
      "Simulation"
    ]
  },
  {
    "objectID": "Courses/simulation.html#rappel-sur-la-fonction-quantile",
    "href": "Courses/simulation.html#rappel-sur-la-fonction-quantile",
    "title": "Simulation",
    "section": "Rappel sur la fonction quantile",
    "text": "Rappel sur la fonction quantile\nRappel : Pour F une fonction définie sur \\mathbb{R} à valeurs dans [0, 1], croissante, on note\n\n\\forall q \\in ]0,1[, \\quad F^\\leftarrow(q) = \\inf\\{ x \\in \\mathbb{R} : F(x)\\geq q\\}\n\\tag{1}\n\nThéorème 1 (Caratérisation des quantiles) Soit F une fonction définie sur \\mathbb{R} à valeurs dans [0, 1], croissante et continue à droite, alors pour tout q \\in ]0, 1[, on a \n\\begin{align}\n   \\{x \\in \\mathbb{R} :  F(x) \\geq q) \\} & =\n   \\{x \\in \\mathbb{R} : x \\geq F^\\leftarrow(q)  \\}\n\\end{align}\n\n\n\nPreuve. \n\nCas \\subset: Soit x \\in \\mathbb{R} t.q. F(x) \\geq q, alors par définition de l’inf dans Équation 1, x \\geq F^\\leftarrow(q).\nCas \\supset: Soit x \\in \\mathbb{R} t.q. x \\geq F_X^\\leftarrow(q) alors pour tout \\epsilon &gt; 0, x + \\epsilon &gt; F^\\leftarrow(q), donc F(x + \\epsilon) \\geq q. Puis, par continuité à droite de F, F(x) \\geq q.",
    "crumbs": [
      "Cours",
      "Simulation"
    ]
  },
  {
    "objectID": "Courses/simulation.html#méthode-dinversion-1",
    "href": "Courses/simulation.html#méthode-dinversion-1",
    "title": "Simulation",
    "section": "Méthode d’inversion",
    "text": "Méthode d’inversion\n\nThéorème 2 (Méthode d’inversion) Soit X une v.a réelle, et U \\sim\\mathcal{U}([0,1]), alors la variable aléatoire F_X^{\\leftarrow}(U) a même loi que X.\n\n\nPreuve. En utilisant le théorème précédent, on a \\mathbb{P}(F_X^{\\leftarrow}(U) \\leq x) = \\mathbb{P}(U \\leq F_X(x)) pour tout x\\in\\mathbb{R}. Puis, comme U est une loi uniforme sur [0,1],  \\mathbb{P}(U\\leq F_X(x))=F_X(x).\nOn en déduit donc que la loi de F_X^{-1}(U) est la même que celle de X, car les deux v.a. ont la même fonction de répartition.\n\n\n\nExemple 1 (Simulation d’une loi exponentielle) On rappelle que la loi exponentielle de paramètre \\lambda &gt; 0 a pour densité \nf_{\\lambda}(x) = \\lambda e^{-\\lambda x} {1\\hspace{-3.8pt} 1}_{\\mathbb{R}_+}(x)\\enspace.\n et donc pour fonction de répartition \nF_{\\lambda}(x) = (1 - e^{-\\lambda x}) {1\\hspace{-3.8pt} 1}_{\\mathbb{R}_+}(x)\\enspace.\n On vérifie que F_{\\lambda} est bijective de \\mathbb{R}_+ dans ]0,1[ et que son inverse est donnée pour tout u \\in ]0,1[ par \nF_{\\lambda}^{-1}(u) = -\\frac{1}{\\lambda} \\log(1-u)\\enspace.\n\n\n\n\nExemple 2 (Simulation d’une loi de Weibull) La loi de Weibull de paramètre \\lambda &gt; 0 et k &gt;0 est caractérisée par la fonction de répartition \nF(x) = (1 - e^{-(x/\\lambda)^k}){1\\hspace{-3.8pt} 1}_{\\mathbb{R}_+}(x)\n C’est une loi utilisée dans différents domaines, notamment en gestion des risques (hydrologie, finance, assurance, etc.). Le calcul de l’inverse généralisée F^\\leftarrow est immédiat car F est bijective sur ]0, \\infty[ : \n    F^\\leftarrow (u) = \\lambda (-\\ln(1-u))^{\\frac{1}{k}}\\,, \\quad u \\in ]0,1[\\,.\n La méthode d’inversion s’applique : si U \\sim \\mathcal{U}([0,1]), alors la variable aléatoire X = \\lambda (-\\ln(U))^{\\frac{1}{k}} suit une loi de Weibull de paramètres \\lambda et k.\n\nMalheureusement, la fonction F n’est pas toujours inversible (penser aux lois discrètes) c’est donc pourquoi on utilise l’inverse l’inverse généralisée ou fonction quantile introduite dans la section Notations: \n\n  F^\\leftarrow(p)=  \\inf\\{ x \\in \\mathbb{R} \\colon F(x)\\geq p\\} \\enspace.\n\nInterprétation: Définir l’inverse d’une fonction de répartition F revient à résoudre l’équation F(x) = \\alpha d’inconnue x pour un \\alpha fixé. Si F n’est pas bijective, deux problèmes apparaissent :\n\nl’équation n’a aucune solution ce qui revient à dire que F n’est pas surjectif (graphiquement, F présente des sauts) ;\nl’équation a plusieurs solutions ce qui revient à dire que F n’est pas injective (graphiquement cela se matérialise par un plateau à la hauteur \\alpha). Un exemple classique est celui où F est la fonction de répartition d’une variable aléatoire discrète.\n\nLe passage à l’inéquation F(x) \\geq u permet de contourner la non-surjectivité : on ne regarde non plus les droites horizontales y=u mais la région \\{y \\geq \\alpha\\}. Le choix de l’\\inf dans la définition de F^{\\leftarrow} permet de contourner la non-injectivité : vu qu’il y a possiblement plusieurs x tels que F(x) \\geq u, on choisit le “premier”. Ces considérations sont illustrées en Figure Figure 2.\n\n\n\n\n                                                \n\n\nFigure 2\n\n\n\n\nRemarques additionnelles:\n\nLa fonction F étant croissante, la quantité F^\\leftarrow(u) correspond au premier instant où F dépasse \\alpha. Si F est bijective (ce qui équivaut dans ce cas à strictement croissante et injective), alors F^\\leftarrow = F^{-1}.\nLa fonction F^\\leftarrow n’est rien d’autre que la fonction quantile : si 0 &lt; \\alpha &lt; 1, q_{1-\\alpha} = F^\\leftarrow(1-\\alpha) est le quantile d’ordre (1-\\alpha) de F. Par exemple, F^\\leftarrow(1/2) correspond à la médiane.\nNotons que si u=0, on peut alors naturellement poser F^{\\leftarrow}(0) = -\\infty. De même, avec la convention la convention \\inf \\emptyset = +\\infty, on peut alors étendre la définition de F^\\leftarrow à u=1 (mais F^\\leftarrow(1) n’est pas toujours égal à \\infty, voir les exemples ci-dessous).\n\n\nExemple 3 (Simulation d’une loi de Bernoulli) La fonction de répartition F d’une loi de Bernoulli de paramètre p \\in ]0,1[ est donnée par \n    F(x) =\n    \\Bigg\\{ \\begin{array}{ll}\n        0   & \\text{ si } x &lt; 0\\,,        \\\\\n        1-p & \\text{ si } 0 \\leq x &lt; 1\\,, \\\\\n        1   & \\text{ si } x \\leq 1\\,.\n    \\end{array}\n L’inverse généralisée de F peut ainsi être calculée via la formule de l’exemple : \n    F^\\leftarrow(u) =\n    \\bigg\\{ \\begin{array}{ll}\n        0 & \\text{ si } 0 &lt; u \\leq 1-p\\,, \\\\\n        1 & \\text{ si } 1-p &lt; u \\leq 1\\,.\n    \\end{array}\n ce qui se réécrit plus simplement F^\\leftarrow(u) = {1\\hspace{-3.8pt} 1}_{\\{1-p &lt; u\\}}.\nAinsi, si U suit une loi uniforme sur [0,1] alors {1\\hspace{-3.8pt} 1}_{\\{1-p &lt; U\\}} suit une loi de Bernoulli de paramètre p. Comme 1-U suit aussi une loi uniforme sur [0,1], on en déduit que {1\\hspace{-3.8pt} 1}_{\\{U &lt; p\\}} suit une loi de Bernoulli de paramètre p. Notons que l’on peut remplacer l’inégalité stricte par une inégalité large.\n\n\n\nProposition 1 (Loi à support fini) \nSoit X une variable aléatoire discrète prenant uniquement les valeurs x_1 &lt; \\dots &lt; x_r (r modalité possibles) avec probabilité p_1, \\dots, p_r (donc p_1 + \\dots + p_r=1). On vérifie que pour tout u \\in ]0,1[, \n        F^\\leftarrow(u) =\n        \\begin{cases}\n            x_1 & \\text{si } 0 &lt; u \\leq p_1\\,,                  \\\\\n            x_2 & \\text{si } p_1 &lt; u \\leq p_1+p_2\\,,            \\\\\n                & \\vdots                                        \\\\\n            x_r & \\text{si }  \\sum_{i=1}^{r-1} p_i &lt; u &lt; 1\\,.\n        \\end{cases}\n\nSur cet exemple, on peut prolonger la définition de F^\\leftarrow à u=1 en posant F^\\leftarrow(1) = x_r. L’inverse généralisée se réécrit alors sous la forme \n        F^\\leftarrow(u) = \\sum_{k=1}^r x_k {1\\hspace{-3.8pt} 1}_{ \\{  \\sum_{i=1}^{k-1}p_i &lt; u \\leq \\sum_{i=1}^{k}p_i \\} }\\enspace,\n où on a posé p_0=0.\n\nL’expression précédente s’étend directement au cas où X prend un nombre (infini) dénombrable de valeurs, la somme devenant alors une série.\nLa méthode est illustré ci-dessous pour quelques lois intéressantes:\n\nviewof dist = Inputs.select(['normal','cauchy','laplace','bimodal'], {value: \"bimodal\", label: \"Loi\"})\nviewof replay = html`&lt;button&gt;Relancer`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninvcdfboard = require(await FileAttachment(\"../inverse-vizu/dist/invcdfboard.umd.cjs\").url())\n\n{\n  replay\n  const canvas = DOM.canvas(500, 500);\n  const galton = invcdfboard.galton(canvas,dist);\n  \n  return html`${galton.canvas}`\n}",
    "crumbs": [
      "Cours",
      "Simulation"
    ]
  },
  {
    "objectID": "Courses/simulation.html#méthode-de-rejet",
    "href": "Courses/simulation.html#méthode-de-rejet",
    "title": "Simulation",
    "section": "Méthode de rejet",
    "text": "Méthode de rejet\nL’idée de la méthode de rejet est la suivante. On souhaite simuler une variable aléatoire X de densité f, appelée loi cible, mais f est trop compliquée pour que la simulation puisse se faire directement. On dispose cependant d’une autre densité g possédant les propriétés suivantes :\n\non sait simuler Y de loi g,\nil existe m &gt; 0 tel que f(x) \\leq m \\cdot g(x),\non sait évaluer le rapport d’acceptation r(x) = \\frac{f(x)}{mg(x)}.\n\nRemarquons d’ores et déjà que la constante m est nécessairement plus grande que 1 car \n    1 = \\int_\\mathbb{R} f(x) \\, dx \\leq m \\int_\\mathbb{R} g(x)\\, dx = m\\,.\n\nL’idée est alors de considérer deux suites i.i.d. de variables aléatoires indépendantes entre elles:\n\n(Y_n)_{n \\geq 1} de loi g,\n(U_n)_{n \\geq 1} de loi uniforme sur [0,1].\n\nEn pratique, Y_n correspond à une proposition et U_n permettra de décider si on accepte la proposition ou non. Si oui, alors on conserve Y_n, sinon on simule Y_{n+1}. Le rapport d’acceptation, c’est-à-dire la proportion de Y_n acceptées, correspond à r(x).\nAutrement dit, pour simuler X de densité f, il suffit de simuler Y de densité g et U uniforme jusqu’à ce que U \\leq r(Y). La proposition suivante assure que cette méthode donne bien le résultat voulu.\n\nProposition 2 (Méthode de rejet) \nSoit T = \\inf \\{n \\geq 1 : U_n \\leq r(Y_n)\\} le premier instant où le tirage est accepté. Alors :\n\nT suit une loi géométrique de paramètre 1/m,\nla variable aléatoire X = Y_T a pour densité f et est indépendante de T.\n\n\n\nPreuve. Il s’agit d’étudier la loi du couple (X,T). Pour x \\in \\mathbb{R} et n \\in \\mathbb{N}^{*}, on écrit \\mathbb{P}(X \\leq x, T=n)= \\mathbb{P}(U_1 &gt; r(Y_1), \\dots, U_{n-1} &gt; r(Y_{n-1}), U_n \\leq r(Y_n), Y_n \\leq x). Les n tirages étant iid, on obtient \n    \\mathbb{P}(X \\leq x, T=n) = \\mathbb{P}(U_1 &gt; r(Y_1))^{n-1} \\mathbb{P}(U_n \\leq r(Y_n), Y_n \\leq x)\\,.\n\nConcernant le premier terme, les variables aléatoires Y_1 et U_1 sont indépendantes donc leur loi jointe correspond au produit des densités : \\begin{align*}\n        \\mathbb{P}(U_1 &gt; r(Y_1))\n         & = \\mathbb{P}((U_1, Y_1) \\in \\{(u,y) \\in \\mathbb{R}^2 : u &gt; r(y)\\})                             \\\\\n         & = \\int_{\\mathbb{R}^2} {1\\hspace{-3.8pt} 1}_{\\{u &gt; r(y)\\}} ({1\\hspace{-3.8pt} 1}_{[0,1]}(u) g(y)) \\, du dy  \\\\\n         & = \\int_\\mathbb{R} \\bigg( \\int_0^1 {1\\hspace{-3.8pt} 1}_{\\{u &gt; r(y)\\}} \\, du\\bigg) g(y)\\, d y \\\\\n         & =  \\int_\\mathbb{R} (1-r(y)) \\, g(y)\\, d y\\,,\n    \\end{align*}\n ce qui se réécrit, comme f et g sont des densités et que r(y) = f(y)/(m \\cdot g(y)): \\begin{align*}\n        \\mathbb{P}(U_1 &gt; r(Y_1))\n        & = \\int_\\mathbb{R} g(y)\\, d y - \\int_\\mathbb{R} \\dfrac{f(y)}{m}\\, dy \\\\\n        & = 1 - \\dfrac{1}{m}\\,.\n    \\end{align*}\n Le deuxième terme se calcule de manière analogue : \n\\begin{align*}\n    \\mathbb{P}(U_n \\leq r(Y_n), Y_n \\leq x)\n        & = \\int_{\\mathbb{R}^2} {1\\hspace{-3.8pt} 1}_{\\{u \\leq r(y)\\}} {1\\hspace{-3.8pt} 1}_{\\{y \\leq x\\}} ({1\\hspace{-3.8pt} 1}_{[0,1]}(u) g(y)) \\, du dy       \\\\\n        & = \\int_\\mathbb{R} \\bigg( \\int_0^1  {1\\hspace{-3.8pt} 1}_{\\{u \\leq r(y)\\}} \\, du\\bigg) {1\\hspace{-3.8pt} 1}_{\\{y \\leq x\\}}  g(y)\\, d y\\,,\n\\end{align*}\n c’est-à-dire \n\\begin{align*}\n        \\mathbb{P}(U_n \\leq r(Y_n), Y_n \\leq x)\n        & = \\int_\\mathbb{R} r(y) {1\\hspace{-3.8pt} 1}_{\\{y \\leq x\\}}  g(y)\\, d y \\\\\n        & = \\int_{-\\infty}^x \\dfrac{f(y)}{m}\\, d y \\\\\n        & = \\dfrac{F(x)}{m}\\,,\n\\end{align*}\n où F est la fonction de répartition de la loi de densité f. On peut ainsi conclure que \n    \\mathbb{P}(X \\leq x, T=n)\n    =\n    \\bigg(1 - \\dfrac{1}{m}\\bigg)^{n-1} \\dfrac{F(x)}{m}\\,.\n Il ne reste plus qu’à étudier les lois marginales. D’une part, par continuité monotone croissante, \n    \\mathbb{P}(T=n)\n    = \\lim_{q \\to \\infty} \\mathbb{P}(X \\in ]-\\infty, q], T=n)\\,,\n ce qui donne \n\\begin{align*}\n    \\mathbb{P}(T=n)\n    & = \\lim_{q \\to \\infty} \\bigg(1 - \\dfrac{1}{m}\\bigg)^{n-1} \\dfrac{F(q)}{m}\\\\\n    & = \\bigg(1 - \\dfrac{1}{m}\\bigg)^{n-1} \\dfrac{1}{m}\\,.\n\\end{align*}\n On en déduit que T suit une loi géométrique de paramètre 1/m. D’autre part, par \\sigma-additivité, \n\\begin{align*}\n    \\mathbb{P}(X \\leq x)\n    & = \\mathbb{P}(X \\leq x, T \\in \\mathbb{N}^*)\\\\\n    & = \\sum_{n=1}^\\infty \\mathbb{P}(X \\leq x, T=n)\\,,\n\\end{align*}\n ce qui donne \n\\begin{align*}\n    \\mathbb{P}(X \\leq x)\n    & = \\sum_{n=1}^\\infty \\bigg(1 - \\dfrac{1}{m}\\bigg)^{n-1} \\dfrac{F(x)}{m}\\\\\n    & = \\dfrac{1}{1-(1-1/m)} \\dfrac{F(x)}{m}\\\\\n    & = F(x)\\,,\n\\end{align*}\n ce qui prouve que X a pour loi F.\nEnfin, la loi du couple (X,T) est égale au produit des lois \n\\begin{align*}\n    \\mathbb{P}(X \\leq x, T=n)\n    & = \\bigg(1 - \\dfrac{1}{m}\\bigg)^{n-1} \\dfrac{F(x)}{m}\\\\\n    & = \\mathbb{P}(T=n) \\mathbb{P}(X \\leq x)\\,,\n\\end{align*}\n\n\n\ndef accept_reject(n, f, g, g_sampler, m):\n    \"\"\"\n    n: nombre de simulations\n    f: densité cible\n    g: densité des propositions, g_sampler: simulateur selon g\n    m: constante pour la majoration\n    \"\"\"\n    x_samples = np.zeros(n)\n    u_samples = np.zeros(n)\n    accepted = np.zeros(n)\n    n_accepted = 0\n    while n_accepted &lt; n:\n        x = g_sampler()\n        u = np.random.uniform()\n        alpha = u * m * g(x)\n        u_samples [n_accepted] = alpha\n        x_samples[n_accepted] = x\n        if  alpha &lt;= f(x):\n            accepted[n_accepted] = 1\n        n_accepted += 1\n    return x_samples, u_samples, accepted\n\n\n\n\n\n\n\nEn pratique…\n\n\n\nOn simule U_1 et Y_1. Si U_1 \\leq r(Y_1) c’est gagné, on pose X=Y_1. Sinon, on simule U_2 et Y_2 et on teste à nouveau l’inégalité U_2 \\leq r(Y_2). Et ainsi de suite. Comme T suit une loi géométrique de paramètre 1/m, son espérance vaut m : il faut en moyenne m tentatives pour obtenir une simulation de la loi de densité f. L’objectif est alors de choisir un couple (g, m) de sorte que m soit le plus proche possible de 1.\n\n\n\nExemple 4 (Rejet d’une loi polynomiale) Donnons un exemple jouet (on étudiera des exemples plus pertinents en TD). On considère la densité f(x) = 4x^3 {1\\hspace{-3.8pt} 1}_{[0,1]}(x). Comme f est majorée par 4, on peut choisir pour g la densité de la loi uniforme sur [0,1] et m=4. Alors, r(x) =f(x) / (mg(x)) = x^3, pour x \\in [0,1]. On simule donc (Y_1, U_1) et on teste si U_1 \\leq Y_1^3, etc.\nBien évidemment, on privilégiera ici une simulation via F^\\leftarrow qui permet de générer des variables aléatoires de loi f plus rapidement.\n\n\n\n\n                                                \n\n\nFigure 3: Visualisation des zones d’acceptations/rejet (g uniforme)\n\n\n\n\nNous pouvons facilement améliorer la proportion de point acceptés en proposant par exemple g définie par g(x) = 2x {1\\hspace{-3.8pt} 1}_{[0, 1]}(x), et m=2.\n\n\n\n\n                                                \n\n\nFigure 4: Visualisation des zones d’acceptations/rejet (g triangulaire)\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`Le taux d'acceptation est passé de **${ratio1}** à\n**${ratio2}** en utilisant une loi triangulaire au lieu d'une loi uniforme.`\n\n\n\n\n\n\n\n\n\nExemple 5 (Rejet d’une loi de densité d’Andrews) Considérons la densité d’Andrews définie par f(x) = \\frac{1}{S} \\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}  {1\\hspace{-3.8pt} 1}_{[-1,1]}(x), avec S = \\int_{-1}^{1}\\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}dx. Dans ce contexte, on ne connait pas la valeur exacte de S, et on va donc utiliser la méthode de rejet pour simuler des variables aléatoires de loi f sans cette information. On peut l’adapter le test de la manière suivante: si l’on prend m=2/S et g(x) = \\frac{1}{2} {1\\hspace{-3.8pt} 1}_{[-1,1]}(x), on observe que tester u\\leq \\frac{f(x)}{m \\cdot g(x)} est équivalent à tester u \\leq r(x)=\\frac{1}{S} \\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}  \\cdot \\frac{1}{\\frac{2}{S} g(x)} = \\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}  \\cdot \\frac{1}{2 \\cdot g(x)}, ce qui peut se faire sans connaissance de S. De plus on peut vérifier que g(x) = \\frac{1}{2} {1\\hspace{-3.8pt} 1}_{[-1,1]}(x) définit une densité et que f(x) \\leq m \\cdot g(x) pour tout x\\in \\mathbb{R}.\n\nn = 10000\ng = lambda x: np.ones_like(x) / 2\ng_sampler = lambda: 2 * np.random.uniform() - 1\nm = 2\n\nx_samples, u_samples, accepted = accept_reject(n, np.sinc, g, g_sampler, m)\nratio = np.sum(accepted) / n\n# Note: https://stackoverflow.com/questions/70804891/how-to-vectorize-a-function-in-python-that-includes-a-limit-e-g-sinx-x\n\n\n\n\n\n\nOn peut approcher numériquement la valeur exacte de S en utilisant une méthode de calcul approchée, ce qui permet de comparer ici notre méthode de rejet avec la densité sous-jacente:\n\nfrom scipy import integrate\nS = integrate.quad(np.sinc, -1, 1)[0]\nprint(f\"En utilisant la méthode de rejet, on trouve que S = {S:.3f}\")\n\nEn utilisant la méthode de rejet, on trouve que S = 1.179\n\n\nEnfin, on peut visualiser la qualité l’approximation de la densité par la méthode de rejet en comparant la densité approchée (avec un histogramme) avec la densité exacte:\n\n\n\n\n                                                \n\n\nFigure 5: Méthode de rejet pour simuler une loi de densité de type Andrews, sans connaissance de la valeur exacte de la constante de normalisation.\n\n\n\n\n\nmd`Dans cet example, le taux d'acceptation est ici de **${ratio}**.`\n\n\n\n\n\n\n\n\nCas mutlidimensionnel\nCommençons par un cas de dimension deux.\nPour cela on va utiliser la méthode de rejet pour simuler une loi de densité f sur \\mathbb{R}^2. En particulier, un exemple classique est de tirer des points dans le disque unité, c’est-à-dire de simuler une loi uniforme sur le disque unité. Pour cela, on va utiliser la méthode de rejet avec g la densité de la loi uniforme sur le carré [-1,1]^2.\nMais prenons un autre exemple, à savoir tirer des points uniformément dans la surface délimité par une cardioïde. Pour cela, on va utiliser la méthode de rejet avec g la densité de la loi uniforme sur le carré [-2,2]^2.\n\n\n\n\n                                                \n\n\nFigure 6: Méthode de rejet pour simuler une loi uniforme sur un disque unité.\n\n\n\n\nAire estimée: 3.164\n\n\n\n\n\n\n                                                \n\n\nFigure 7: Méthode de rejet pour simuler une loi uniforme sur une surface délimitée par une cardioïde.\n\n\n\n\nAire estimée: 4.795\n\n\n\n\n\n\n\n\nEXERCICE loi uniforme sur un cylindre\n\n\n\nProposer une méthode pour simuler une loi uniforme sur un cylindre de rayon 1 et de hauteur 10.",
    "crumbs": [
      "Cours",
      "Simulation"
    ]
  },
  {
    "objectID": "Courses/simulation.html#autres-méthodes",
    "href": "Courses/simulation.html#autres-méthodes",
    "title": "Simulation",
    "section": "Autres méthodes",
    "text": "Autres méthodes\n\nSommation de variables aléatoires\nPour simuler une variable aléatoire de loi binomiale \\mathcal{B}(n,p), on peut utiliser la méthode d’inversion. Cependant, cela nécessite le calcul de l’inverse généralisée de F, donc de coefficients binomiaux et de puissances de p et 1-p. À la place, on utilisera plutôt la relation bien connue suivante : si X_1, \\ldots, X_n est une suite iid de variables aléatoires de loi de Bernoulli de paramètre p, alors \n    X = X_1 + \\cdots + X_n \\sim \\mathcal{B}(n,p)\\,.\n\nPour simuler des variables aléatoires de Bernoulli, on utilise la méthode d’inversion (voir Exemple ). Ainsi, si U_1, \\ldots, U_n sont des variables aléatoires iid de loi uniforme sur [0,1], alors \n    \\sum_{i=1}^n {1\\hspace{-3.8pt} 1}_{\\{U_i \\leq p\\}} \\sim \\mathcal{B}(n,p)\\,.\n\n\n\nLoi de Poisson\nRappelons qu’une variable aléatoire X suit une loi de Poisson de paramètre \\lambda &gt; 0, notée X \\sim \\mathcal{P}(\\lambda) si \n    \\mathbb{P}(X = k) = e^{-\\lambda} \\dfrac{\\lambda^k}{k!}\\,, \\quad k \\in \\mathbb{N}\\,.\n Une méthode pour simuler une variable aléatoire de loi de Poisson est donnée par la proposition suivante.\n\nProposition 3 (Génération de v.a. de loi de Poisson) \nSoit (E_n)_{n \\geq 1} des variables aléatoires i.i.d. de loi exponentielle de paramètre \\lambda &gt; 0. On pose S_k = E_1 + \\cdots + E_k. Alors, pour tout n \\in \\mathbb{N} \n    \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1}) =  e^{-\\lambda} \\dfrac{\\lambda^n}{n!}\\enspace .\n Ainsi, la variable aléatoire T définie par \n    T \\triangleq \\sup \\{n \\in \\mathbb{N} : S_n \\leq 1\\}\n suit une loi de Poisson de paramètre \\lambda : T \\sim \\mathcal{P}(\\lambda).\n\nLa preuve repose sur le lemme suivant.\n\nLemme 1 (Loi de Erlang) \nSoit n variables aléatoires E_1, \\dots, E_n i.i.d. de loi exponentielle de paramètre \\lambda &gt;0. La somme E_1+\\dots+E_n suit une loi d’Erlang de paramètres (n,\\lambda), donnée par la fonction de répartition \n    F_{n,\\lambda}(t) = 1 - \\sum_{k=0}^{n-1} e^{-\\lambda t} \\frac{(\\lambda t)^k}{k!}\\,.\n\n\n\nPreuve. On montre le résultat pour n=2. La généralisation à k quelconque se fait par récurrence. Soit t &gt; 0, et f_{\\lambda}(x)={1\\hspace{-3.8pt} 1}_{\\{x \\geq 0 \\}} \\lambda e^{-\\lambda x} la densité d’une loi exponentielle de paramètre \\lambda. Les variables aléatoires E_1 et E_2 étant indépendantes et suivant des lois exponentielles de paramètre \\lambda_1 et \\lambda_2, on a \n\\begin{align*}\n    \\mathbb{P}(E_1+E_2 \\leq t)\n        & = \\int_{\\mathbb{R}^2} {1\\hspace{-3.8pt} 1}_{\\{x_1 + x_2 \\leq t\\}} f_{\\lambda}(x_1) f_{\\lambda}(x_2)\\, d x_1 d x_2 \\\\\n        & = \\int_{\\mathbb{R}^2} {1\\hspace{-3.8pt} 1}_{\\{x_1 + x_2 \\leq t\\}} \\lambda^2 e^{-\\lambda (x_1+x_2)} {1\\hspace{-3.8pt} 1}_{\\{x_1 \\geq 0\\}} {1\\hspace{-3.8pt} 1}_{\\{x_2 \\geq 0\\}}\\, d x_1 d x_2 \\\\\n        & = \\int_{\\mathbb{R}^2} {1\\hspace{-3.8pt} 1}_{\\{0 \\leq x_1 \\leq t\\}} {1\\hspace{-3.8pt} 1}_{\\{0 \\leq x_2 \\leq t-x_1\\}} \\lambda^2 e^{-\\lambda x_1} e^{-\\lambda x_2}\\, d x_1 d x_2             \\\\\n        & = \\int_0^t \\lambda e^{-\\lambda x_1} \\bigg(\\int _0^{t-x_1} \\lambda e^{-\\lambda x_2}\\, d x_2\\bigg)  d x_1\\,.\n\\end{align*}\n La première intégrale se calcule alors facilement : \n    \\int _0^{t-x_1} \\lambda e^{-\\lambda x_2}\\, d x_2 = 1 - e^{-\\lambda(t-x_1)}\\,.\n On obtient alors \n\\begin{align*}\n    \\mathbb{P}(E_1+E_2 \\leq t)\n   & = \\int_0^t \\lambda e^{-\\lambda x_1}dx_1 -  \\int_0^t e^{-\\lambda t} d x_1\\\\\n   & = 1 - e^{-\\lambda t} - \\lambda t e^{-\\lambda t}\\,.\n\\end{align*}\n Si t&lt;0, alors comme les E_i ne prennent que des valeurs positives on trouve \\mathbb{P}(E_1 + E_2 \\leq t) = 0. Ceci prouve le résultat pour n=2.\n\nOn peut désormais prouver le résultat de la Proposition 3.\n\nPreuve. Pour n \\in \\mathbb{N}, on décompose la probabilité \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1}) via \n\\begin{align*}\n    \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1})\n    & = \\mathbb{P}(\\{S_n \\leq 1\\} \\setminus \\{S_{n+1} \\leq 1\\})\\\\\n    & = \\mathbb{P}(S_n \\leq 1) - \\mathbb{P}(S_{n+1} \\leq 1)\\,.\n\\end{align*}\n Le lemme précédent donne \n    \\mathbb{P}(S_n \\leq 1) = 1 - \\sum_{k=0}^{n-1} e^{-\\lambda} \\dfrac{\\lambda^k}{k!}\n et \n    \\mathbb{P}(S_{n+1} \\leq 1) = 1 - \\sum_{k=0}^{n} e^{-\\lambda} \\dfrac{\\lambda^k}{k!}\\,.\n On obtient alors le résultat souhaité : \n    \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1})\n    = e^{-\\lambda} \\dfrac{\\lambda^n}{n!}\\,.\n\nOn conclut la preuve de la proposition en remarquant que \n    \\mathbb{P}(T=n) = \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1})\\,.\n\n\nLa simulation d’une variable aléatoire de Poisson repose donc sur la simulation de lois exponentielles qui se fait via la méthode d’inversion, comme vu dans Exemple 1. En pratique, on simule E_1 et on teste si E_1 &gt; 1. Si oui, on pose alors T=0. Si non, on simule E_2 et on teste si E_1 + E_2 &gt; 1. Si oui, on pose T=1. Sinon on continue la procédure.\n\n\nBibliographie et pour aller plus loin\n\nGenerating Random Floating-Point Numbers by Dividing Integers: a Case Study par Frédéric Goualard\nGenerating Pseudo-random Floating-Point Values par Allen Downey.",
    "crumbs": [
      "Cours",
      "Simulation"
    ]
  },
  {
    "objectID": "Courses/th_asymptotique.html",
    "href": "Courses/th_asymptotique.html",
    "title": "Théorèmes asymptotiques",
    "section": "",
    "text": "Le premier résultat fondamental en probabilités concerne le comportement asymptotique de la moyenne empirique: \n\\bar X_n = \\dfrac{X_1 + \\cdots + X_n}{n} \\enspace.\n quand on observe n variables aléatoires i.i.d X_1,\\dots,X_n, ayant une espérance finie.\n\nThéorème 1 (Loi forte des grands nombres) \nSoit (X_n)_{n \\geq 1} une suite de variables aléatoires indépendantes et identiquement distribuées (i.i.d.) dans L^1(\\Omega, \\mathcal{F}, \\mathbb{P}). Notons \\mu = \\mathbb{E}[X_1]. Alors \\bar X_n converge vers \\mu presque sûrement : \n\\mathbb{P}\\bigg( \\dfrac{X_1 + \\cdots + X_n}{n} \\underset{n \\to \\infty}{\\longrightarrow} \\mu \\bigg) = 1\\,.\n\n\nInterprétation: Intuitivement, la probabilité d’un événement A correspond à la fréquence d’apparition de A quand on répète une expérience qui fait intervenir cet événement. Par exemple, si on dispose une pièce truquée, on estimera la probabilité d’apparition du côté pile en lançant la pièce un grand nombre de fois et en comptant le nombre de pile obtenu. La loi des grands nombres justifie a posteriori cette intuition : si X_1, \\ldots, X_n sont i.i.d. de loi de Bernoulli de paramètre p, alors \n    \\dfrac{X_1 + \\cdots + X_n}{n} \\xrightarrow[n \\to \\infty]{p.s.} p \\enspace.\n Le membre de gauche correspond au nombre empirique de pile obtenu, celui de droite à la valeur théorique.\nRemarque: Bien qu’assez intuitif, ce théorème est difficile à démontrer, cf.[@Ouvrard08;@Barbe_Ledoux06] ou encore [@Williams91] pour une version de preuve avec des martingales.\n#| standalone: true\n#| viewerHeight: 550\nimport numpy as np\nfrom shiny import ui, render, App, reactive\nfrom shinywidgets import output_widget, register_widget\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\n\nn_init = 42\n\n\napp_ui = ui.page_fluid(\n    ui.tags.head(\n        ui.tags.style(\"\"\"\n            .bslib-sidebar-layout &gt; .sidebar &gt; .sidebar-content {\n            display: flex;\n            flex-direction: column;\n            padding: 0.5rem;\n            }\n            .irs--shiny .irs-line {\n            top: 27px;\n            height: 4px;\n            }\n            .irs.irs--shiny .irs-bar {\n            top: 27px;\n            height: 4px;\n            }\n            .irs--shiny .irs-handle {\n            top: 23px;\n            width: 22px;\n            height: 10px;\n        \"\"\")\n    ),\n    ui.panel_title(\"Loi des grands nombres\"),\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_action_button(\"seed\", \"Nouveau tirage\", class_=\"btn-primary\"),\n            ui.input_slider( \"p\", \"Espérance: p\", 0.01, 0.99, value=0.35, step=0.01, ticks=False,\n            ),\n            ui.input_slider( \"n_samples\", \"Échantillons: n\", 2, 1000, value=15, step=1, ticks=False),\n        width=3),\n    ui.panel_main(output_widget(\"my_widget\"), width = 9)\n    )\n)\n\n\n\n\ndef server(input, output, session):\n    seed = reactive.Value(42)\n\n    @reactive.Effect\n    @reactive.event(input.seed)\n    def _():\n        seed.set(np.random.randint(0, 1000))\n\n    subplots = make_subplots(\n        rows=2,\n        cols=1,\n        vertical_spacing=0.45,\n        horizontal_spacing=0.04,\n        row_heights=[5, 1],\n        subplot_titles=(\n            f\"Moyenne empirique: loi de Bernoulli\",\n            \"Tirages aléatoires &lt;span style='color:rgb(66, 139, 202)'&gt;bleu: 0&lt;/span&gt;, &lt;span style='color:rgb(255, 0, 0)'&gt;rouge: 1&lt;/span&gt; (seed=\"\n            + f\"{n_init:03}\"\n            + \")\",\n        ),\n    )\n    fig = go.FigureWidget(subplots) \n    fig.add_trace(\n        go.Scatter(\n            mode=\"lines\",\n            line=dict(color=\"black\", width=3),\n            x=[],\n            y=[],\n            name=r\"Moyenne &lt;br&gt; empirique\",\n        ),\n        row=1,\n        col=1,\n    )\n    fig.add_trace(\n        go.Scatter(\n            mode=\"lines\",\n            line=dict(dash=\"dash\", color=\"black\", width=1),\n            marker={},\n            x=[],\n            y=[],\n            name=r\"p\",\n        ),\n            row=1,\n            col=1,\n    )\n    fig.add_trace(\n        go.Heatmap(\n            x=[],\n            z=[],\n            colorscale=[[0, \"rgb(66, 139, 202)\"], [1, \"rgb(255,0,0)\"]],\n            showscale=False,\n        ),\n        row=2,\n        col=1,\n    )\n\n    fig.update_yaxes(range=[0, 1.1], row=1, col=1)\n    fig.update_xaxes(matches=\"x1\", row=2, col=1)\n    fig.update_yaxes(visible=False, row=2, col=1)\n    fig.update_xaxes(visible=False, row=2, col=1)\n\n    fig.update_layout(\n        template=\"simple_white\",\n        showlegend=True,\n        xaxis_title=\"Échantillons: n\",\n    )\n    fig.update_layout(autosize=True)\n\n    fig.update_layout(\n        legend=dict(\n            yanchor=\"top\",\n            y=0.99,\n            xanchor=\"left\",\n            x=0.65,\n            bgcolor=\"rgba(0,0,0,0)\",\n        )\n    )\n    fig.update_layout(\n        margin=dict(l=0, r=0, b=10, t=70),\n    )\n\n    register_widget(\"my_widget\", fig)\n\n    @reactive.Effect\n    def _():\n        p = input.p()\n        n_samples = input.n_samples()\n\n        rng = np.random.default_rng(seed())\n        iterations = np.arange(1, n_samples + 1)\n        samples = rng.binomial(1, p, size=n_samples)\n        means_samples = np.cumsum(samples) / np.arange(1, n_samples + 1)\n\n        # Update data in fig:\n        fig.data[0].x = iterations\n        fig.data[0].y = means_samples\n\n        fig.data[1].x = iterations\n        fig.data[1].y = np.full((n_samples), p)\n\n        fig.data[2].x = iterations\n        fig.data[2].z = [samples]\n\n        fig.update_xaxes(range=[1, n_samples + 1])\n\n        # Update the subplot titles:\n        fig.layout.annotations[1].update(\n            text=f\"Tirages aléatoires (seed=\"\n            + f\"{seed():03}\"\n            + \") &lt;br&gt; &lt;span style='color:rgb(66, 139, 202)'&gt;bleu: 0&lt;/span&gt;, &lt;span style='color:rgb(255, 0, 0)'&gt;rouge: 1&lt;/span&gt; \"\n        )\n\n\napp = App(app_ui, server)\n\nPour aller plus loin:\nQuant p varie, à n fixé…les signaux générés sont très très proches, ce qui ne devrait pas être le cas sans structuration particulière de la génération. L’aléa est imparfait!",
    "crumbs": [
      "Cours",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Courses/th_asymptotique.html#loi-des-grands-nombres",
    "href": "Courses/th_asymptotique.html#loi-des-grands-nombres",
    "title": "Théorèmes asymptotiques",
    "section": "",
    "text": "Le premier résultat fondamental en probabilités concerne le comportement asymptotique de la moyenne empirique: \n\\bar X_n = \\dfrac{X_1 + \\cdots + X_n}{n} \\enspace.\n quand on observe n variables aléatoires i.i.d X_1,\\dots,X_n, ayant une espérance finie.\n\nThéorème 1 (Loi forte des grands nombres) \nSoit (X_n)_{n \\geq 1} une suite de variables aléatoires indépendantes et identiquement distribuées (i.i.d.) dans L^1(\\Omega, \\mathcal{F}, \\mathbb{P}). Notons \\mu = \\mathbb{E}[X_1]. Alors \\bar X_n converge vers \\mu presque sûrement : \n\\mathbb{P}\\bigg( \\dfrac{X_1 + \\cdots + X_n}{n} \\underset{n \\to \\infty}{\\longrightarrow} \\mu \\bigg) = 1\\,.\n\n\nInterprétation: Intuitivement, la probabilité d’un événement A correspond à la fréquence d’apparition de A quand on répète une expérience qui fait intervenir cet événement. Par exemple, si on dispose une pièce truquée, on estimera la probabilité d’apparition du côté pile en lançant la pièce un grand nombre de fois et en comptant le nombre de pile obtenu. La loi des grands nombres justifie a posteriori cette intuition : si X_1, \\ldots, X_n sont i.i.d. de loi de Bernoulli de paramètre p, alors \n    \\dfrac{X_1 + \\cdots + X_n}{n} \\xrightarrow[n \\to \\infty]{p.s.} p \\enspace.\n Le membre de gauche correspond au nombre empirique de pile obtenu, celui de droite à la valeur théorique.\nRemarque: Bien qu’assez intuitif, ce théorème est difficile à démontrer, cf.[@Ouvrard08;@Barbe_Ledoux06] ou encore [@Williams91] pour une version de preuve avec des martingales.\n#| standalone: true\n#| viewerHeight: 550\nimport numpy as np\nfrom shiny import ui, render, App, reactive\nfrom shinywidgets import output_widget, register_widget\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\n\nn_init = 42\n\n\napp_ui = ui.page_fluid(\n    ui.tags.head(\n        ui.tags.style(\"\"\"\n            .bslib-sidebar-layout &gt; .sidebar &gt; .sidebar-content {\n            display: flex;\n            flex-direction: column;\n            padding: 0.5rem;\n            }\n            .irs--shiny .irs-line {\n            top: 27px;\n            height: 4px;\n            }\n            .irs.irs--shiny .irs-bar {\n            top: 27px;\n            height: 4px;\n            }\n            .irs--shiny .irs-handle {\n            top: 23px;\n            width: 22px;\n            height: 10px;\n        \"\"\")\n    ),\n    ui.panel_title(\"Loi des grands nombres\"),\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_action_button(\"seed\", \"Nouveau tirage\", class_=\"btn-primary\"),\n            ui.input_slider( \"p\", \"Espérance: p\", 0.01, 0.99, value=0.35, step=0.01, ticks=False,\n            ),\n            ui.input_slider( \"n_samples\", \"Échantillons: n\", 2, 1000, value=15, step=1, ticks=False),\n        width=3),\n    ui.panel_main(output_widget(\"my_widget\"), width = 9)\n    )\n)\n\n\n\n\ndef server(input, output, session):\n    seed = reactive.Value(42)\n\n    @reactive.Effect\n    @reactive.event(input.seed)\n    def _():\n        seed.set(np.random.randint(0, 1000))\n\n    subplots = make_subplots(\n        rows=2,\n        cols=1,\n        vertical_spacing=0.45,\n        horizontal_spacing=0.04,\n        row_heights=[5, 1],\n        subplot_titles=(\n            f\"Moyenne empirique: loi de Bernoulli\",\n            \"Tirages aléatoires &lt;span style='color:rgb(66, 139, 202)'&gt;bleu: 0&lt;/span&gt;, &lt;span style='color:rgb(255, 0, 0)'&gt;rouge: 1&lt;/span&gt; (seed=\"\n            + f\"{n_init:03}\"\n            + \")\",\n        ),\n    )\n    fig = go.FigureWidget(subplots) \n    fig.add_trace(\n        go.Scatter(\n            mode=\"lines\",\n            line=dict(color=\"black\", width=3),\n            x=[],\n            y=[],\n            name=r\"Moyenne &lt;br&gt; empirique\",\n        ),\n        row=1,\n        col=1,\n    )\n    fig.add_trace(\n        go.Scatter(\n            mode=\"lines\",\n            line=dict(dash=\"dash\", color=\"black\", width=1),\n            marker={},\n            x=[],\n            y=[],\n            name=r\"p\",\n        ),\n            row=1,\n            col=1,\n    )\n    fig.add_trace(\n        go.Heatmap(\n            x=[],\n            z=[],\n            colorscale=[[0, \"rgb(66, 139, 202)\"], [1, \"rgb(255,0,0)\"]],\n            showscale=False,\n        ),\n        row=2,\n        col=1,\n    )\n\n    fig.update_yaxes(range=[0, 1.1], row=1, col=1)\n    fig.update_xaxes(matches=\"x1\", row=2, col=1)\n    fig.update_yaxes(visible=False, row=2, col=1)\n    fig.update_xaxes(visible=False, row=2, col=1)\n\n    fig.update_layout(\n        template=\"simple_white\",\n        showlegend=True,\n        xaxis_title=\"Échantillons: n\",\n    )\n    fig.update_layout(autosize=True)\n\n    fig.update_layout(\n        legend=dict(\n            yanchor=\"top\",\n            y=0.99,\n            xanchor=\"left\",\n            x=0.65,\n            bgcolor=\"rgba(0,0,0,0)\",\n        )\n    )\n    fig.update_layout(\n        margin=dict(l=0, r=0, b=10, t=70),\n    )\n\n    register_widget(\"my_widget\", fig)\n\n    @reactive.Effect\n    def _():\n        p = input.p()\n        n_samples = input.n_samples()\n\n        rng = np.random.default_rng(seed())\n        iterations = np.arange(1, n_samples + 1)\n        samples = rng.binomial(1, p, size=n_samples)\n        means_samples = np.cumsum(samples) / np.arange(1, n_samples + 1)\n\n        # Update data in fig:\n        fig.data[0].x = iterations\n        fig.data[0].y = means_samples\n\n        fig.data[1].x = iterations\n        fig.data[1].y = np.full((n_samples), p)\n\n        fig.data[2].x = iterations\n        fig.data[2].z = [samples]\n\n        fig.update_xaxes(range=[1, n_samples + 1])\n\n        # Update the subplot titles:\n        fig.layout.annotations[1].update(\n            text=f\"Tirages aléatoires (seed=\"\n            + f\"{seed():03}\"\n            + \") &lt;br&gt; &lt;span style='color:rgb(66, 139, 202)'&gt;bleu: 0&lt;/span&gt;, &lt;span style='color:rgb(255, 0, 0)'&gt;rouge: 1&lt;/span&gt; \"\n        )\n\n\napp = App(app_ui, server)\n\nPour aller plus loin:\nQuant p varie, à n fixé…les signaux générés sont très très proches, ce qui ne devrait pas être le cas sans structuration particulière de la génération. L’aléa est imparfait!",
    "crumbs": [
      "Cours",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Courses/th_asymptotique.html#théorème-central-limite-tcl",
    "href": "Courses/th_asymptotique.html#théorème-central-limite-tcl",
    "title": "Théorèmes asymptotiques",
    "section": "Théorème central limite (TCL)",
    "text": "Théorème central limite (TCL)\nUne fois la loi des grands nombres établie, on peut se demander quel est l’ordre suivant dans le développement asymptotique de \\bar X_n - \\mu, ou de manière équivalente de S_n - n \\mu, où S_n = X_1 + \\cdots + X_n. Le théorème suivant répond à cette question, en donnant une convergence en loi d’une transformation affine de la moyenne empirique:\n\nThéorème 2 (Théorème central limite) Soit X_1, \\ldots, X_n une suite de variables aléatoires i.i.d de variance \\sigma^2 = {\\rm var}(X_1) \\in ]0, \\infty[. On note \\mu = \\mathbb{E}[X_1] leur espérance. Alors \n\\sqrt n \\left(\\tfrac{\\bar X_n - \\mu}{\\sigma} \\right) \\xrightarrow[n \\to +\\infty]{\\mathcal{L}} N\\enspace,\n où N suit une loi normale centrée réduite : N \\sim\\mathcal{N}(0,1).\n\nPreuve: cf.[@Ouvrard08;@Barbe_Ledoux06].\nOn peut interpréter ce théorème grossièrement de la façon suivante: la moyenne empirique de variables aléatoires i.i.d de variance \\sigma^2 se comporte asymptotiquement comme une loi normale \\mathcal{N}(\\mu, \\tfrac{\\sigma^2}{n}), ce que l’on écrit avec un abus de notation:\n\n\\bar X_n \\approx \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n}) \\enspace.\n\nEn termes de somme cumulée empirique, la convergence se réécrit\n\n    \\tfrac{S_n - n \\mu}{\\sqrt n \\sigma} \\xrightarrow[n \\to +\\infty]{\\mathcal{L}} N \\enspace.\n\nLes hypothèses de ce théorème sont plutôt faibles (il suffit de supposer une variance finie). Pourtant, le résultat est universel : la loi de départ peut être aussi farfelue que l’on veut, elle se rapprochera toujours asymptotiquement d’une loi normale.\nOn rappelle que la convergence en loi est équivalente à la convergence des fonctions de répartition en tout point de continuité de la limite. Ainsi, le théorème central limite se réécrit de la manière suivante : pour tout a &lt; b, notons \\alpha_n=\\mathbb{P} \\left(\\bar X_n \\notin [ \\mu + \\tfrac{a \\sigma}{\\sqrt{n}}, \\mu + \\tfrac{ b \\sigma}{\\sqrt{n}}] \\right). Ainsi\n\n\\mathbb{P} \\left(\\tfrac{\\bar X_n - \\mu}{\\sigma}\\in [ \\tfrac{a}{\\sqrt{n}},\\tfrac{b}{\\sqrt{n}}] \\right)\\\\\n\\begin{align}\n    1-\\alpha_n& = \\mathbb{P} \\left(\\bar X_n \\in [ \\mu + \\tfrac{a \\sigma}{\\sqrt{n}}, \\mu + \\tfrac{ b \\sigma}{\\sqrt{n}}] \\right)\\nonumber\\\\\n    & =\n    \\mathbb{P} \\left(\\tfrac{\\bar X_n - \\mu}{\\sigma} \\in [ \\tfrac{a}{\\sqrt{n}},\\tfrac{b}{\\sqrt{n}}]\\right) \\nonumber\\\\\n    & =\n    \\mathbb{P} \\bigg( a \\leq \\sqrt n \\left(\\tfrac{\\bar X_n - \\mu}{\\sigma} \\right) \\leq b\\bigg) \\nonumber\\\\\n    & \\underset{n \\to \\infty}{\\longrightarrow}  \\int_a^b \\varphi(x) \\,  dx\\,. \\nonumber\\\\\n\\end{align}\n où l’on note \\varphi (resp. \\Phi) la densité (resp. la fonction de répartition) d’une loi normale centrée réduite, définie pour tout x\\in\\mathbb{R} par \\varphi(x)=\\tfrac{e^{-\\frac{x^2}{2}}}{\\sqrt{2\\pi}} (resp. \\Phi(x)= \\int_{-\\infty}^{x}\\varphi(u) du).\nDans le cas classique d’un intervalle de confiance à 95%, c’est-à-dire quand \\alpha_n=0.05, et en prenant un intervalle de confiance symétrique (alors a=-t et b=q) on obtient 1-\\alpha_n= \\int_{-q}^q \\varphi(x) \\,  dx=\\Phi(q)-\\Phi(-q)=2 \\Phi(q)-1 \\implies \\boxed{q=\\Phi^{-1}(1-\\tfrac{\\alpha_n}{2})} et q est donc le quantile de niveau 1-\\tfrac{\\alpha_n}{2} de la loi normale centrée réduite. Numériquement on peut facilement évaluer q et vérifier que q\\approx 1.96 avec scipy:\n\nfrom scipy.stats import norm\nq = norm.ppf(1-0.05/2)\nprint(f\"Gaussienne centrée réduite,\\nQuantile de niveau (1-α/2):\\nq = {q:.2f}\")\n\nGaussienne centrée réduite,\nQuantile de niveau (1-α/2):\nq = 1.96\n\n\n\nExemple 1 (Loi de Bernoulli) On considère des variables aléatoires X_1, \\ldots, X_n i.i.d. suivant une loi de Bernoulli de paramètre p \\in ]0,1[, dont l’espérance et la variance sont respectivemenbt p et p(1-p). Le théorème central limite donne alors \n    \\sqrt n \\left(\\frac{\\bar X_n - p}{p (1-p)} \\right) \\xrightarrow[n \\to +\\infty]{\\mathcal{L}} N\\,,\n avec N \\sim \\mathcal{N}(0,1). Cette convergence est illustrée dans le widget ci-dessous. Le contexte est le suivant. On répète t fois le processus, qui consiste à afficher (\\bar{X}_k)_{k \\in [n]}, où les n variables aléatoires sont i.i.d. et suivent une loi de Bernoulli de paramètre p.\n\n#| standalone: true\n#| viewerHeight: 600\nimport numpy as np\nfrom scipy.stats import norm\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom shiny import ui, render, App, reactive\nfrom shinywidgets import output_widget, render_widget\n\n\napp_ui = ui.page_fluid(\n    ui.tags.head(\n        ui.tags.style(\"\"\"\n            .bslib-sidebar-layout &gt; .sidebar &gt; .sidebar-content {\n            display: flex;\n            flex-direction: column;\n            padding: 0.1rem;\n            }\n            .irs--shiny .irs-line {\n            top: 27px;\n            height: 4px;\n            }\n            .irs.irs.irs--shiny .irs-bar {\n            top: 27px;\n            height: 4px;\n            }\n            .irs--shiny .irs-handle {\n            top: 23px;\n            width: 22px;\n            height: 10px;\n        \"\"\")\n    ),\n    ui.panel_title(\"TCL\"),\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_action_button(\"seed\", \"Nouveau tirage\",class_=\"btn-primary\"),\n            ui.input_slider(\"p\", \"Espérance: p\", 0.01, 0.99, value=0.5, step=0.01, ticks=False),\n            ui.input_slider(\"n_samples\", \"Échantillons: n\", 1, 200, value=100, step=1, ticks=False),\n            ui.input_slider(\"n_repetitions\", \"Répétitions: t\", 1, 300, value=200, step=1, ticks=False),\n        width=3\n        ),\n    ui.panel_main(output_widget(\"my_widget\"), width = 9)\n    )\n)\n\n\n\ndef server(input, output, session):\n    seed = reactive.Value(42)\n\n\n    @reactive.Effect\n    @reactive.event(input.seed)\n    def _():\n        seed.set(np.random.randint(0, 1000))\n\n\n    @output\n    @render_widget\n    def my_widget():\n\n        rng = np.random.default_rng(seed())\n        p = input.p()\n        n_repetitions = input.n_repetitions()\n        n_samples = input.n_samples()\n        iterations = np.arange(1, n_samples + 1)\n        samples = rng.binomial(1, p, size=(n_repetitions, n_samples))\n        means_samples = np.cumsum(samples, axis=1) / np.arange(1, n_samples + 1)\n        x_hist = np.linspace(0, 1, num=300)\n\n        # Create figure\n        fig = make_subplots(\n                    rows=1,\n                    cols=3,\n                    # vertical_spacing=0.5,\n                    horizontal_spacing=0.02,\n                    column_widths=[20, 2, 3],\n                    subplot_titles=(\"t = \" + str(n_repetitions) + \" répétitions\",\"\",\"\")\n                )\n\n\n        for i in range(n_repetitions):\n            fig.add_trace(\n                    go.Scatter(\n                        mode='lines',\n                        line=dict(color=\"rgba(0,0,0,0.05)\", width=1),\n                        x=iterations,\n                        y=means_samples[i,:],\n                        ),\n                        row=1, col=1,\n            )\n        fig.add_trace(\n                go.Scatter(\n                    mode='lines',\n                    line=dict(dash=\"dash\", color=\"blue\", width=1),\n                    marker={},\n                    x=iterations,\n                    y=np.full((n_samples), p),\n                    name='p'),\n                    row=1, col=1,\n        )\n        fig.update_layout(\n            template=\"simple_white\",\n            showlegend=False,\n        )\n        fig.add_trace(\n                go.Scatter(\n                    mode='markers',\n                    marker=dict(color=\"rgba(0,0,0,0.05)\", size=4),\n                    x=np.zeros(n_samples),\n                    y=means_samples[:,-1],\n                ),\n                row=1, col=2,\n\n        )\n        y_hist, bins = np.histogram(means_samples[:,-1], bins=int(np.sqrt(n_repetitions)), density=True)\n        fig.add_trace(\n            go.Bar(x=y_hist, y=bins[:-1] + np.diff(bins)/2,\n                    opacity=0.75,\n                    marker_color = 'black',\n                    orientation='h',\n                    width=np.diff(bins),\n                    name=\"Tirages de moyennes empiriques\",\n                    ),\n                row=1, col=3,\n        )\n        fig.add_trace(\n            go.Scatter(x=norm.pdf(x_hist, p, np.sqrt(p*(1-p) / n_samples)),\n                       y=x_hist,\n                       mode='lines',\n                       line=dict(color=\"red\"),\n                       legendgroup='1',\n                       name=\"TCL\"\n                       ),\n                row=1, col=3,\n        )\n\n        fig.update_xaxes(range=[1, n_samples + 1])\n        fig.update_yaxes(range=[-.05, 1.05], row=1, col=1)\n        fig.update_yaxes(matches=\"y1\",visible = False,  row=1, col=2)\n        fig.update_xaxes(range=[-0.2, 0.2], visible = False, row=1, col=2)\n\n        fig.update_yaxes(matches=\"y1\", row=1, col=3, visible=False)\n        fig.update_xaxes(range=[0, 1.1 / np.sqrt(2*np.pi* p*(1-p) / n_samples)], row=1, col=3)\n        fig.update_xaxes(visible=False, row=1, col=3)\n\n\n\n        for trace in fig['data']:\n            print(trace)\n            if (trace['name'] != 'TCL') and (trace['name'] != 'p'):\n                trace['showlegend'] = False\n        fig.update_layout(\n        margin=dict(l=0, r=0, b=10, t=100),\n        )\n        fig.update_layout(\n            title=dict(text=\"Distribution de la moyenne empirique&lt;br&gt; (cas loi de Bernoulli)\", yanchor=\"top\", y=0.95),\n            title_x=0.5,\n            showlegend=True,\n\n        )\n        fig.update_layout(\n            legend=dict(\n                yanchor=\"top\",\n                y=0.99,\n                xanchor=\"left\",\n                x=0.89,\n                bgcolor=\"rgba(0,0,0,0)\",\n            )\n        )\n        fig['layout']['xaxis']['title']='Échantillons: n'\n\n        fig.update_layout(autosize=True)\n\n        return fig\n\n\napp = App(app_ui, server)\n\nUne autre illustration possible de la convergence donnée par le TCL est celle qui correspond au point de vue donnée par l’analyse. Pour cela supposons que l’on ait une suite de variables aléatoires réelles X_1, \\dots, X_n, i.i.d. dont la fonction de densité commune est notée par f.\nOn rappelle quelques éléments de probabilités concernant les densités. Pour cela on rappelle la définition de la convolution deux fonctions. Pour cela prenons deux fonctions f et g définies sur \\mathbb{R} et qui sont intégrables au sens de Lebesgue. La convolution de f par g est alors la fonction f*g suivante:\n\n\\begin{align}\n\\mathbb{R} &\\mapsto \\mathbb{R} \\nonumber\\\\\nx &\\to \\int_{-\\infty}^{+\\infty} f(x-y)g(y) dy \\enspace.\\nonumber\n\\end{align}\n\n\n\n\n\n\n\nNote\n\n\n\nOn peut aussi obtenir f*g(x) en calculant \\int_{\\mathbb{R}^2} f(u)g(v) {1\\hspace{-3.8pt} 1}_{u+v=x} du dv.\n\n\n\nThéorème 3 (Loi de la somme et convolutions) Soient X et Y des v.a. indépendantes de densités f et g respectivement, la loi de X+Y est donnée par la convolution f*g.\n\nRappel: pour un scalaire \\alpha\\neq 0, la densité de \\alpha X est donnée par la fonction x \\mapsto \\frac{1}{|\\alpha|} \\cdot f(\\frac{x}{\\alpha}).\n\nCorollaire 1 (Loi de la moyenne) Soient X_1,\\dots,X_n des v.a. i.i.d. de densité f, la densité de \\bar{X}_n est donnée par la fonction x \\mapsto n \\cdot [f*\\dots*f](n \\cdot x).\n\nDessous, pour X_1, \\dots, X_n, i.i.d., de densité f, on affiche la densité de la loi de \\bar{X}_n.\n#| standalone: true\n#| viewerHeight: 550\nimport numpy as np\nfrom shiny import ui, render, App, reactive\nfrom shinywidgets import output_widget, register_widget\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nfrom scipy import signal\n\n\napp_ui = ui.page_fluid(\n    ui.tags.head(\n        ui.tags.style(\"\"\"\n            .bslib-sidebar-layout &gt; .sidebar &gt; .sidebar-content {\n            display: flex;\n            flex-direction: column;\n            padding: 0.5rem;\n            }\n            .irs--shiny .irs-line {\n            top: 27px;\n            height: 2px;\n            }\n            .irs.irs--shiny .irs-bar {\n            top: 27px;\n            height: 2px;\n            }\n            .irs--shiny .irs-handle {\n            top: 23px;\n            width: 22px;\n            height: 10px;\n        \"\"\")\n    ),\n    ui.panel_title(\"TCL et convolutions\"),\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_select(\n                \"loi\",\n                \"Loi sous-jacente\",\n                {'uniforme': 'Uniforme', 'laplace' : 'Laplace'},\n            ),\n            ui.input_slider(\n                \"n_iter\",\n                \"Échantillons: n\",\n                1,\n                10,\n                value=1,\n                step=1,\n                ticks=False,\n            ), width = 3\n    ),\n    ui.panel_main(\n        output_widget(\"my_widget\"), width = 9\n    )\n)\n)\n\n\nnnzeros = 10001\nx_min = -20\nx_max = 20\n\nx = np.linspace(x_min, x_max, nnzeros)\ny = np.zeros(nnzeros)\nmask = np.where(np.abs(x) &lt;= 0.5, 1, 0)\ny[mask == 1] = 1\ndelta = (x_max - x_min) / nnzeros\nvar = np.sum(y * x**2 *(delta)) - (np.sum(y * x * delta))**2\n\ndef convolve(signal_in, n_convolutions, delta):\n    output = np.zeros(len(signal_in))\n    if n_convolutions == 0:\n        return output\n    elif n_convolutions == 1:\n        return signal_in\n    else:\n        output = signal_in.copy()\n        for i in range(n_convolutions - 1):\n            output = signal.fftconvolve(\n                output * delta, signal_in, mode=\"same\"\n            )\n        return output\n\n\ndef server(input, output, session):\n\n    fig = go.FigureWidget()\n    fig.add_trace(\n        go.Scatter(\n            mode=\"lines\",\n            line=dict(color=\"black\", width=3),\n            x=[],\n            y=[],\n            name=\"loi de de la moyenne empirique&lt;br&gt;(variance adéquate)\",\n        )\n    )\n\n    fig.add_trace(\n        go.Scatter(\n            x=x,\n            y=np.exp(-(x**2) / (2 * var)) / np.sqrt(2 * var * np.pi),\n            mode=\"lines\",\n            line=dict(dash=\"dash\", color=\"red\", width=2),\n            name=f\"Loi normale&lt;br&gt;(variance adéquate)\",\n        )\n    )\n    fig.update_xaxes(range=[-3, 3], position=0.)\n    fig.update_yaxes(range=[0, 2 * np.max(y)], position=0.5, showticklabels=False)\n\n\n    fig.update_layout(\n        template=\"simple_white\",\n        showlegend=True,\n        autosize=True,\n        title=dict(text=\"Densité : &lt;br&gt; moyenne de n variables aléatoires\", yanchor=\"top\", y=0.95),\n        title_x=0.5,\n    )\n    fig.update_layout(legend=dict(\n        yanchor=\"top\",\n        y=0.95,\n        xanchor=\"left\",\n        x=0.8,\n        font=dict(size= 18)\n    ))\n    fig.update_layout(\n    height=250,\n    margin=dict(l=0, r=0, b=10, t=100),\n    )\n\n    register_widget(\"my_widget\", fig)\n\n    @reactive.Effect\n    def _():\n        if str(input.loi()) == 'uniforme':\n            y = np.zeros(nnzeros)\n            mask = np.where(np.abs(x) &lt;= 0.5, 1, 0)\n            y[mask == 1] = 1\n\n        else:\n            y=np.exp(-np.abs(x)) / 2\n            y = y / (np.sum(y) * delta)\n\n        var = np.sum(y * x**2 * delta) - (np.sum(y * x * delta))**2\n\n        y_display = convolve(y, input.n_iter(), delta)\n        # Update data in fig:\n        fig.data[0].x = x / np.sqrt(input.n_iter())\n        fig.data[0].y = y_display * np.sqrt(input.n_iter())\n        fig.data[1].y = np.exp(-(x**2) / (2 * var)) / np.sqrt(2 * var * np.pi)\n        fig.update_yaxes(range=[0, 2 * np.max(y)], position=0.5, showticklabels=False)\n\n\napp = App(app_ui, server)\nPour aller plus loin sur les convolutions, voir la vidéo de 3Blue1Brown à ce sujet: Convolutions | Why X+Y in probability is a beautiful mess",
    "crumbs": [
      "Cours",
      "Théorèmes asymptotiques"
    ]
  },
  {
    "objectID": "Slides/slides-index.html#test",
    "href": "Slides/slides-index.html#test",
    "title": "Visualisation: inversion",
    "section": "test",
    "text": "test\n\nviewof dist = Inputs.select(['normal','cauchy','laplace','bimodal'], {value: \"bimodal\", label: \"Loi\"})\nviewof replay = html`&lt;button&gt;Relancer`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninvcdfboard = require(await FileAttachment(\"../inverse-vizu/dist/invcdfboard.umd.cjs\").url())\n\n{\n  replay\n  const canvas = DOM.canvas(500, 500);\n  const galton = invcdfboard.galton(canvas,dist);\n  \n  return html`${galton.canvas}`\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualisation: inversion"
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#rappel-sur-les-vecteurs-aléatoires",
    "href": "Slides/slides_loi_normale_multi.html#rappel-sur-les-vecteurs-aléatoires",
    "title": "Loi normale: cas multivarié",
    "section": "Rappel sur les vecteurs aléatoires",
    "text": "Rappel sur les vecteurs aléatoires\n\nVecteur aléatoire: \\(\\mathbf{X} = (X_1, \\dots, X_d) \\in \\mathbb{R}^d\\)\nEspérance: \\(\\mathbb{E}[\\mathbf{X}] = (\\mathbb{E}[X_1], \\dots, \\mathbb{E}[X_d]) \\in \\mathbb{R}^d\\) (\\(\\mathbb{E}[|X_j|] &lt; \\infty\\))\nCovariances: \\(\\textrm{cov}(X_i, X_j) = \\mathbb{E}[(X_i- \\mathbb{E}[X_i]) (X_j - \\mathbb{E}[X_j])] \\enspace,\\)\nMatrice de variance-covariance : \\(\\Sigma = (\\textrm{cov}(X_i, X_j))_{1 \\leq i,j \\leq d} \\in \\mathbb{R}^{d \\times d}\\)",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#vecteurs-gaussiens",
    "href": "Slides/slides_loi_normale_multi.html#vecteurs-gaussiens",
    "title": "Loi normale: cas multivarié",
    "section": "Vecteurs gaussiens",
    "text": "Vecteurs gaussiens\n\nDéfinition 1 (Vecteur gaussien) Un vecteur aléatoire \\(\\mathbf{X} = (X_1, \\dots, X_d)^\\top \\in \\mathbb{R}^d\\) est un vecteur gaussien si pour tout \\({\\alpha} = (\\alpha_1, \\dots, \\alpha_d)^\\top\\), la variable aléatoire réelle \\[\n  \\langle {\\alpha}, \\mathbf{X} \\rangle = \\alpha_1 X_1 + \\cdots + \\alpha_d X_d \\enspace,\n\\] suit une loi normale.\n\n\nConséquence chaque (loi marginale) \\(X_j\\) suit une loi gaussienne (choisir ci-dessus \\(\\alpha = e_j\\), les autres égaux à \\(0\\))\n\n\nContre-exemple: \\(X\\sim \\mathcal{N}(0,1)\\) et \\(\\varepsilon\\) une loi uniforme (discrète) sur \\(\\{-1,1\\}\\), alors \\((X, \\varepsilon X)^{\\top}\\) n’est pas un vecteur gaussien bi-dimensionnel, mais \\(X\\) et \\(\\varepsilon X\\) sont gaussiennes.\n\\[\n\\begin{align*}\n  \\mathbb{P}(\\varepsilon X \\leq t)\n  & =  \\mathbb{P}(X \\leq t) \\mathbb{P}(\\varepsilon = 1) + \\mathbb{P}(-X \\leq t) \\mathbb{P}(\\varepsilon = -1)\\\\\n  & = \\tfrac{1}{2} \\mathbb{P}(X \\leq t) + \\tfrac{1}{2} \\mathbb{P}(-X \\leq t) = \\mathbb{P}(X \\leq t) \\enspace.\n\\end{align*}\n\\] mais \\(X + \\varepsilon X\\) prend la valeur \\(0\\) avec probabilité \\(1/2\\) donc ne suit pas une loi normale.",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#calculs-élémentaires",
    "href": "Slides/slides_loi_normale_multi.html#calculs-élémentaires",
    "title": "Loi normale: cas multivarié",
    "section": "Calculs élémentaires",
    "text": "Calculs élémentaires\nNotation: on note \\(X\\sim\\mathcal{N}(\\mu,\\Sigma)\\) un vecteur gaussien d’espérance \\({\\mu}\\) et de matrice de variance-covariance \\(\\Sigma\\)\nPour un tel \\(\\mathbf{X}\\), on a \\(\\langle {\\alpha}, \\mathbf{X} \\rangle \\sim \\mathcal{N}\\left(\\langle {\\alpha}, {\\mu} \\rangle, {\\alpha}^\\top \\Sigma {\\alpha}\\right)\\) pour tout \\(\\alpha\\in \\mathbb{R}^{d}\\)\nPreuve \\[\n\\begin{align*}\n  \\mathbb{E}[\\langle {\\alpha}, \\mathbf{X} \\rangle] = \\mathbb{E}[\\alpha_1 X_1 + \\dots + \\alpha_d X_d] =  \\alpha_1 \\mathbb{E}[X_1] + \\cdots + \\alpha_d \\mathbb{E}[X_d] = \\langle {\\alpha}, {\\mu} \\rangle\\,,\n\\end{align*}\n\\]\n\net\n\\[\n\\begin{align*}\n  \\mathrm{var}(\\langle {\\alpha}, \\mathbf{X} \\rangle)\n    & = \\mathrm{var}(\\alpha_1 X_1 + \\cdots + \\alpha_d X_d)\\\\\n    & = \\mathrm{cov}(\\alpha_1 X_1 + \\cdots + \\alpha_d X_d, \\alpha_1 X_1 + \\cdots + \\alpha_d X_d) \\\\\n    & = \\sum_{1 \\leq i,j \\leq d} \\alpha_i \\mathrm{cov}(X_i, X_j) \\alpha_j\n  = {\\alpha}^\\top \\Sigma {\\alpha}\n\\end{align*}\n\\]",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#fonction-caractéristique-dun-vecteur-gaussien",
    "href": "Slides/slides_loi_normale_multi.html#fonction-caractéristique-dun-vecteur-gaussien",
    "title": "Loi normale: cas multivarié",
    "section": "Fonction caractéristique d’un vecteur gaussien",
    "text": "Fonction caractéristique d’un vecteur gaussien\n\\[\n    \\phi_\\mathbf{X}({\\alpha})\n    \\triangleq \\mathbb{E}[e^{i \\langle {\\alpha}, \\mathbf{X} \\rangle}]\n    = \\exp\\Big(i \\langle {\\alpha}, {\\mu} \\rangle - \\frac{{\\alpha}^\\top \\Sigma {\\alpha}}{2}\\Big)\\,,\n    \\quad {\\alpha} \\in \\mathbb{R}^d\\,.\n\\] Preuve: utiliser l’expression de la fonction caractéristique d’une variable aléatoire de loi normale \\(\\mathcal{N}(\\langle {\\alpha}, {\\mu} \\rangle, {\\alpha}^\\top \\Sigma {\\alpha})\\).\nConséquence: \\(\\phi_\\mathbf{X}\\) est entièrement déterminée par les quantités \\({\\mu}\\) et \\(\\Sigma\\).\nEn particulier, si les variables aléatoires \\(X_1, \\dots, X_d\\) sont indépendantes de loi \\(\\mathcal{N}(0,1)\\), alors \\({\\mu} = (0,\\ldots,0)^\\top\\) et \\(\\Sigma = \\mathrm{Id}_d\\).",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#densité-de-probabilité",
    "href": "Slides/slides_loi_normale_multi.html#densité-de-probabilité",
    "title": "Loi normale: cas multivarié",
    "section": "Densité de probabilité",
    "text": "Densité de probabilité\nCas \\({\\mu}=0\\) et \\(\\Sigma = \\mathrm{Id}_d\\) : la loi gaussienne centrée réduite \\(\\mathcal{N}(0, \\mathrm{Id}_d)\\)\nLa loi de \\((X_1,\\dots,X_n)^\\top\\) correspond alors à la loi produit de \\(n\\) lois gaussiennes centrées réduites indépendantes (pour les gaussiennes la décorrélation implique l’indépendance), de densité \\[\n\\varphi_{0,\\mathrm{Id}_d}(x) = \\frac{1}{ \\sqrt{(2\\pi)^d}} \\exp\\left( -\\tfrac{1}{2}x^\\top x   \\right) \\enspace.\n\\]\n\nProposition 1 (Densité de la loi gaussienne multivariée) Soient \\({\\mu} \\in \\mathbb{R}^d\\) et \\(\\Sigma \\in \\mathbb{R}^{d \\times d}\\) (symétrique et définie positive) et supposons que \\(X \\sim \\mathcal{N}({\\mu},\\Sigma)\\). Alors la densité de probabilité de \\(X\\) est donnée pour tout \\(x \\in \\mathbb{R}^d\\) par\n\\[\n\\varphi_{{\\mu},\\Sigma}(x) = \\frac{1}{ \\sqrt{(2\\pi)^d |\\det(\\Sigma)|}}  \\exp\\Big( -\\tfrac{1}{2}(x-{\\mu})^\\top\\Sigma^{-1}(x - {\\mu})   \\Big) \\enspace.\n\\]",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#démonstration",
    "href": "Slides/slides_loi_normale_multi.html#démonstration",
    "title": "Loi normale: cas multivarié",
    "section": "Démonstration",
    "text": "Démonstration\nPreuve: Soit \\(L\\in \\mathbb{R}^{d \\times d}\\) t.q. \\(LL^\\top = \\Sigma\\) (décomposition spectrale, de Cholevsky, etc.). Loi de \\(\\mathbf{Y} = \\psi(X) \\triangleq L \\mathbf{X} + {\\mu}\\), pour \\(X\\sim \\mathcal{N}(0,\\mathrm{Id_d})\\).\n\nApplication de la formule du changement de variable avec \\(\\psi^{-1}\\) et son jacobien: \\(\\psi^{-1}(y) = L^{-1}(y-{\\mu})\\), et \\(|\\det(J_{\\psi^{-1}})| = |\\det(L^{-1})| = |\\det(L)|^{-1} = |\\det(\\Sigma)|^{-1/2}\\).\n\n\nDe plus \\(LL^\\top \\left(L^{-1}\\right)^\\top L^{-1}=\\mathrm{Id}_d\\), et donc que \\(\\left(L^{-1}\\right)^\\top L^{-1}=\\Sigma^{-1}\\).\n\n\nOn en déduit la densité de \\(\\mathbf{Y}\\) : \\[\n\\begin{align*}\n\\varphi_{{\\mu},\\Sigma}(y)\n& = \\varphi_{0,\\mathrm{Id}_d}(\\psi^{-1}(y)) |\\det(J_{\\psi^{-1}})| \\\\\n& = \\frac{|\\det(\\Sigma)|^{-1/2}}{ \\sqrt{(2\\pi)^d }}  \\exp\\left( -\\tfrac{1}{2}(y-{\\mu})^\\top \\left(L^{-1}\\right)^\\top L^{-1}(y - {\\mu})\\right)\\\\\n& = \\frac{1}{ \\sqrt{(2\\pi)^d |\\det(\\Sigma)|}}  \\exp\\Big( -\\tfrac{1}{2}(y-{\\mu})^\\top\\Sigma^{-1}(y - {\\mu})   \\Big) \\enspace.\n\\end{align*}\n\\]",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#transformation-de-vecteurs-gaussiens",
    "href": "Slides/slides_loi_normale_multi.html#transformation-de-vecteurs-gaussiens",
    "title": "Loi normale: cas multivarié",
    "section": "Transformation de vecteurs gaussiens",
    "text": "Transformation de vecteurs gaussiens\n\nProposition 2 (Transformation affine de vecteurs gaussiens) Soit \\(\\mathbf{X} \\sim \\mathcal{N}({\\mu}, \\Sigma)\\) un vecteur gaussien sur \\(\\mathbb{R}^d\\), \\(\\Omega \\in \\mathbb{R}^{d' \\times d}\\) et \\({\\nu}\\in \\mathbb{R}^{d'}\\). Alors, le vecteur aléatoire \\(\\mathbf{Y} = \\Omega \\mathbf{X} + {\\nu}\\) est un vecteur gaussien vérifiant \\[\n  \\mathbf{Y} \\sim \\mathcal{N}(\\Omega {{\\mu}} + {\\nu}, \\Omega \\Sigma \\Omega^\\top)\\,.\n\\]\n\nCette proposition se prouve sans peine en utilisant la fonction caractéristique On retrouve en particulier la stabilité par transformation affine établie en dimension \\(1\\).",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#la-factorisation-de-cholesky",
    "href": "Slides/slides_loi_normale_multi.html#la-factorisation-de-cholesky",
    "title": "Loi normale: cas multivarié",
    "section": "La factorisation de Cholesky",
    "text": "La factorisation de Cholesky\n\n\n\nThéorème 1 (Factorisation de Cholesky) Soit \\(\\Sigma \\in \\mathbb{R}^{d \\times d}\\) une matrice symétrique définie positive. Alors il existe une matrice triangulaire inférieure \\(L \\in \\mathbb{R}^{d \\times d}\\) telle que \\(\\Sigma = LL^\\top\\). La décomposition est unique si l’on impose que les éléments diagonaux de \\(L\\) soient strictement positifs.\n\n\nPreuve: la factorisation de Cholesky est une conséquence directe de la méthode du pivot de Gauss; détails (Th. 4.4.1, Ciarlet 2006).\n\n\nUtilité: Résolution de systèmes linéaires “\\(Ax=b\\)” avec \\(A\\) symétrique définie positive (notamment pour résoudre plusieurs systèmes avec la même matrice A)\n\n\n\n\nAlgorithme proposé par André-Louis Cholesky: (1875-1918) ingénieur topographe et géodésien dans l’armée française, mort des suites de blessures reçues au champs de bataille.",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#numérique",
    "href": "Slides/slides_loi_normale_multi.html#numérique",
    "title": "Loi normale: cas multivarié",
    "section": "Numérique",
    "text": "Numérique\nEn numpy, la factorisation de Cholesky est disponible via la fonction linalg.cholesky.\n\nimport numpy as np\nSigma = np.array([[1, 0.5], [0.5, 2]])\nL = np.linalg.cholesky(Sigma)\n\nprint(f\"Sigma:\\n{Sigma}\\n\")\nprint(f\"L:\\n{L}\\n\")\nprint(f\"LL^T:\\n{L@L.T}\\n\")\nprint(f\"L^TL:\\n{L.T@L}\\n\")\n\nSigma:\n[[1.  0.5]\n [0.5 2. ]]\n\nL:\n[[1.         0.        ]\n [0.5        1.32287566]]\n\nLL^T:\n[[1.  0.5]\n [0.5 2. ]]\n\nL^TL:\n[[1.25       0.66143783]\n [0.66143783 1.75      ]]",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#simulation-de-vecteurs-gaussiens",
    "href": "Slides/slides_loi_normale_multi.html#simulation-de-vecteurs-gaussiens",
    "title": "Loi normale: cas multivarié",
    "section": "Simulation de vecteurs gaussiens",
    "text": "Simulation de vecteurs gaussiens\n\nCas centré réduit \\(\\mathcal{N}(0, \\mathrm{Id}_d)\\): vecteur gaussien avec \\({\\mu} = (0,\\ldots,0)^\\top\\) et \\(\\Sigma = \\mathrm{Id}_d\\).\n\nsimuler \\(X_1,\\dots, X_d\\), \\(d\\) variables aléatoires indépendantes de loi normale centrée réduite (par Box-Muller ou autre)\nles concaténer en un vecteur \\(\\mathbf{X} = (X_1,\\dots, X_d)^\\top\\).\n\\(\\mathbf{X}\\) est alors un vecteur gaussien de loi \\(\\mathcal{N}(0, \\mathrm{Id}_d)\\).\n\n\n\n\nCas général \\(\\mathcal{N}({\\mu}, \\Sigma)\\): la méthodologie est la suivante\n\nsimuler un vecteur gaussien \\(\\mathbf{X} \\sim \\mathcal{N}(0, \\mathrm{Id}_d)\\)\ntrouver une “racine carrée” \\(L\\) de la matrice de covariance \\(\\Sigma\\)\nappliquer une transformation affine: \\(\\mathbf{Y} = L \\mathbf{X} + {\\mu}\\)",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#approche-par-la-factorisation-de-cholesky",
    "href": "Slides/slides_loi_normale_multi.html#approche-par-la-factorisation-de-cholesky",
    "title": "Loi normale: cas multivarié",
    "section": "Approche par la factorisation de Cholesky",
    "text": "Approche par la factorisation de Cholesky\nLa matrice \\(\\Sigma\\) étant symétrique, elle peut s’écrire comme \\(\\Sigma = LL^\\top\\) où \\(L\\) est une matrice triangulaire inférieure de taille \\(d \\times d\\). Grâce à la décomposition de Cholevsky et en reprenant les éléments de la preuve de la Proposition 1, on peut écrire \\(\\mathbf{Y} = L \\mathbf{X} + {\\mu}\\) où \\(\\mathbf{X} \\sim \\mathcal{N}(0, \\mathrm{Id}_d)\\) et vérifier que \\(\\mathbf{Y} \\sim \\mathcal{N}({\\mu}, \\Sigma)\\).",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#approche-par-la-décomposition-spectrale-de-sigma",
    "href": "Slides/slides_loi_normale_multi.html#approche-par-la-décomposition-spectrale-de-sigma",
    "title": "Loi normale: cas multivarié",
    "section": "Approche par la décomposition spectrale de \\(\\Sigma\\)",
    "text": "Approche par la décomposition spectrale de \\(\\Sigma\\)\nLa matrice \\(\\Sigma\\) étant symétrique, elle se diagonalise en base orthonormée : il existe une matrice orthogonale \\(P\\) telle que \\[\n    \\Sigma\n    = P \\mathrm{diag}(\\lambda_1 \\ldots, \\lambda_d) P^{-1}\n    = P \\mathrm{diag}(\\lambda_1 \\ldots, \\lambda_d) P^\\top\\\n\\] où \\(\\lambda_1, \\ldots, \\lambda_d \\geq 0\\) sont les valeurs propres de \\(\\Sigma\\) qui est semi-définie positive. On pose alors \\(L = P \\mathrm{diag}(\\sqrt \\lambda_1 \\ldots, \\sqrt \\lambda_d)\\) qui est une racine carrée matricielle de \\(\\Sigma\\) au sens où \\(\\Sigma = L L ^\\top\\). On part alors d’un vecteur gaussien centrée réduit \\(\\mathbf{X} \\sim \\mathcal{N}(0, \\mathrm{Id}_d)\\) que l’on sait simuler\nLa proposition Proposition 2 assure alors que le vecteur \\(\\mathbf{X} = L \\mathbf{X} + {\\mu}\\) est un vecteur gaussien de loi \\(\\mathcal{N}({\\mu}, \\Sigma)\\).",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#vecteurs-gaussiens-cas-bidimensionnel",
    "href": "Slides/slides_loi_normale_multi.html#vecteurs-gaussiens-cas-bidimensionnel",
    "title": "Loi normale: cas multivarié",
    "section": "Vecteurs gaussiens : cas bidimensionnel",
    "text": "Vecteurs gaussiens : cas bidimensionnel\nEn dimension \\(p=2\\), la matrice de covariance \\(\\Sigma\\) peut toujours s’écrire comme suit: \\[\n\\Sigma =\n\\begin{pmatrix}\\cos(\\theta) & - \\sin(\\theta)\\\\  \\sin(\\theta)& \\cos(\\theta)\n\\end{pmatrix} \\cdot\n\\begin{pmatrix}\\sigma_1 & 0\\\\ 0 & \\sigma_2\n\\end{pmatrix}\\cdot\n\\begin{pmatrix}\n\\cos(\\theta) &\\sin(\\theta)\\\\  -\\sin(\\theta)& \\cos(\\theta)\\end{pmatrix}\n\\]\n\n\\(\\theta\\) : l’angle de rotation des axes\n\\(\\sigma_1\\) et \\(\\sigma_2\\) écarts-types des marginales (dans le repère orthonormal après rotation)",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#visualisation-de-la-densité-de-probabilité",
    "href": "Slides/slides_loi_normale_multi.html#visualisation-de-la-densité-de-probabilité",
    "title": "Loi normale: cas multivarié",
    "section": "Visualisation de la densité de probabilité",
    "text": "Visualisation de la densité de probabilité\ncf. cours",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_loi_normale_multi.html#bibliographie",
    "href": "Slides/slides_loi_normale_multi.html#bibliographie",
    "title": "Loi normale: cas multivarié",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\nCiarlet, P. G. 2006. Introduction à l’analyse numérique matricielle et à l’optimisation. Cours et exercices corrigés. Dunod.\n\n\n\n\n\nLoi normale: cas multivarié",
    "crumbs": [
      "Slides",
      "Loi normale: cas multivarié"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#enjeu",
    "href": "Slides/slides_simulation.html#enjeu",
    "title": "Simulation",
    "section": "Enjeu",
    "text": "Enjeu\n \nQuestion: Comment simuler en pratique des variables aléatoires i.i.d?\n \n\nApproche: Commencer par les v.a. uniformes et en déduire les autres lois",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#rappel-sur-les-variables-uniformes",
    "href": "Slides/slides_simulation.html#rappel-sur-les-variables-uniformes",
    "title": "Simulation",
    "section": "Rappel sur les variables uniformes",
    "text": "Rappel sur les variables uniformes\nRappel : \\(U\\) suit une loi uniforme sur \\([0,1]\\): \\(U\\sim\\mathcal{U}([0,1])\\) ssi sa fonction de répartition \\(F_U\\) vaut \\[\nF_U(x)\n=\n\\begin{cases}\n    0, & \\text{si }x &lt; 0\\,,        \\\\\n    x, & \\text{si }x \\in [0,1]\\,,  \\\\\n    1, & \\text{si }x &gt; 1\\,.\n\\end{cases}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#challenges",
    "href": "Slides/slides_simulation.html#challenges",
    "title": "Simulation",
    "section": "Challenges",
    "text": "Challenges\n\nObjectif: simuler sur machine une suite \\(U_1, \\dots, U_n\\) de v.a., i.i.d., de loi \\(\\mathcal{U}([0,1])\\).\n Difficultés:\n\n\nUne machine est déterministe.\nLes nombres flottants entre \\(0\\) et \\(1\\) donnés par la machine sont de la forme \\(k/2^p\\), pour \\(k \\in \\{0, \\ldots, 2^{p-1}\\} \\implies\\) impossibilité de générer certains nombres.\nVérifier qu’une suite est bien i.i.d. est un problème difficile.",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#générateurs-de-nombres-pseudo-aléatoires-1",
    "href": "Slides/slides_simulation.html#générateurs-de-nombres-pseudo-aléatoires-1",
    "title": "Simulation",
    "section": "Générateurs de nombres pseudo-aléatoires",
    "text": "Générateurs de nombres pseudo-aléatoires\n\nDéfinition 1 (Générateur de nombres pseudo-aléatoires) \nUn générateur de nombres pseudo-aléatoires (🇬🇧: Pseudo Random Number Generator, PRNG), est un algorithme déterministe récursif qui renvoie une suite \\(U_1, \\ldots, U_n\\) dans \\([0,1]\\) qui a un “comportement similaire” à une suite i.i.d. de loi \\(\\mathcal{U}([0,1])\\).\n\n\nRemarque: ces nombres sont obtenus depuis des nombres entiers générés aléatoirement et uniformément sur grand interval, puis une transformation simple (normalisation) permet d’obtenir des nombres flottants (🇬🇧: floats) entre 0 et 1.",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#détails-techniques",
    "href": "Slides/slides_simulation.html#détails-techniques",
    "title": "Simulation",
    "section": "Détails techniques",
    "text": "Détails techniques\nUn PRNG se construit ainsi :\n\nInitialisation: une graine (🇬🇧: seed) \\(U_0\\), détermine la première valeur (choix arbitraire)\nOn calcule \\(U_{n+1} = f(U_n)\\), où \\(f\\) est une transformation déterministe, telle que \\(U_{n+1}\\) est “le plus indépendant possible” de \\(U_1, \\dots, U_n\\).\n\n\n\n\\(f\\) : à valeur dans un ensemble fini \\(\\implies\\) périodicité (contrainte: utiliser la plus grande période possible)\nL’algorithme est déterministe (une fois la graine fixée). Utilité de fixer la graine: répéter des simulations dans des conditions identiques et ainsi repérer des erreurs",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#le-générateur-congruentiel-linéaire",
    "href": "Slides/slides_simulation.html#le-générateur-congruentiel-linéaire",
    "title": "Simulation",
    "section": "Le générateur congruentiel linéaire",
    "text": "Le générateur congruentiel linéaire\nLa plupart des PRNG s’appuient sur des résultats arithmétiques.\n\n\nLe plus célèbre: Générateur Congruentiel Linéaire (🇬🇧 Linear Congruential Generator, LCG).\nRécurrence: \\[\nX_{n+1} = a X_n + b \\quad \\text{mod } m \\enspace,\n\\] \\(a,b,m\\), entiers bien choisis pour que la suite obtenue ait de bonnes propriétés\nNormalisation: \\(X_n/m\\).\nExemple: la fonction rand de scilab utilisait cette congruence avec \\(m=2^{31}\\), \\(a=843\\; 314\\; 861\\), et \\(b=453\\; 816\\; 693\\).",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#exemples-de-générateurs-alternatifs",
    "href": "Slides/slides_simulation.html#exemples-de-générateurs-alternatifs",
    "title": "Simulation",
    "section": "Exemples de générateurs alternatifs",
    "text": "Exemples de générateurs alternatifs\n \n\nméthode par défaut pour Python et R: Mersenne-Twister, s’appuie sur la multiplication vectorielle (période du générateur \\(m =2^{19937}-1\\))\n\n\n\nméthode par défaut pour numpy: PCG64 (cf. documentation de numpy), dispose de meilleures garanties statistiques; voir https://www.pcg-random.org\n\n\n\nOn suppose désormais disposer d’un générateur pseudo-aléatoire sur \\([0,1]\\).",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#usage-en-numpy",
    "href": "Slides/slides_simulation.html#usage-en-numpy",
    "title": "Simulation",
    "section": "Usage en numpy",
    "text": "Usage en numpy\nEn numpy (version&gt;1.17): utiliser des éléments aléatoires est d’utiliser un générateur\n\n\nseed = 12345                       #  choix de la graine\nrng = np.random.default_rng(seed)  #  générateur\n\n\n\n\nprint(rng.random())                #  un tirage uniforme sur [0,1]\n\n0.22733602246716966\n\n\n\n\n\n\nprint(rng.random(size=5))          #  5 tirages uniformes sur [0,1]\n\n[0.31675834 0.79736546 0.67625467 0.39110955 0.33281393]\n\n\n\n\n\n\nprint(rng.random(size=(3, 2)))     #  matrice 3x2, à entrées unif. sur [0,1]\n\n[[0.59830875 0.18673419]\n [0.67275604 0.94180287]\n [0.24824571 0.94888115]]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#plus-sur-les-lois-aléatoires-et-python",
    "href": "Slides/slides_simulation.html#plus-sur-les-lois-aléatoires-et-python",
    "title": "Simulation",
    "section": "Plus sur les lois aléatoires et Python",
    "text": "Plus sur les lois aléatoires et Python\n\n\n\nSuite du cours: apprendre à générer de nombreuses lois à partir de la loi uniforme\nEn pratique: les logiciels proposent les distributions classiques (gaussiennes, exponentielles, etc.), utiliser plutôt ces fonctions que de les implémenter soi-même.\nListe exhaustive pour numpy:\nhttps://numpy.org/doc/stable/reference/random/generator.html#distributions\n\n\n\n\n\n\n\n\n\n\nPour aller plus loin\n\n\nUne excellent discussion sur les bonnes pratiques aléatoires en numpy, et l’usage de np.random.default_rng est donnée dans ce blog post d’Albert Thomas.",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#rappel-sur-la-fonction-quantile",
    "href": "Slides/slides_simulation.html#rappel-sur-la-fonction-quantile",
    "title": "Simulation",
    "section": "Rappel sur la fonction quantile",
    "text": "Rappel sur la fonction quantile\nRappel: Pour \\(F\\) une fonction définie sur \\(\\mathbb{R}\\) à valeurs dans \\([0, 1]\\), croissante, on note\n\\[\n\\forall q \\in ]0,1[, \\quad F^\\leftarrow(q) = \\inf\\{ x \\in \\mathbb{R} : F(x)\\geq q\\}\n\\tag{1}\\]\nNote: Si \\(x_0 \\in \\{ x \\in \\mathbb{R} : F(x)\\geq q\\}\\) alors \\([x_0,+\\infty[ \\subset \\{ x \\in \\mathbb{R} : F(x)\\geq q\\}\\)\n\n\nThéorème 1 (Caratérisation des quantiles) Soit \\(F\\) une fonction définie sur \\(\\mathbb{R}\\) à valeurs dans \\([0, 1]\\), croissante et continue à droite, alors pour tout \\(q \\in ]0, 1[\\), on a \\[\n\\begin{align}\n   \\{x \\in \\mathbb{R} :  F(x) \\geq q) \\} & =\n   \\{x \\in \\mathbb{R} : x \\geq F^\\leftarrow(q)  \\}\n\\end{align}\n\\]\n\n\n\nCas \\(\\subset\\): Soit \\(x \\in \\mathbb{R}\\) t.q. \\(F(x) \\geq q\\), alors par définition de l’inf dans Équation 1, \\(x \\geq F^\\leftarrow(q)\\)\n\n\n\nCas \\(\\supset\\): Soient \\(\\epsilon&gt;0\\) et \\(x \\in \\mathbb{R}\\) t.q. \\(x \\geq F^\\leftarrow(q)\\) alors (def. de l’inf) \\(\\exists x_0 \\in \\{ x \\in \\mathbb{R} : F(x)\\geq q\\}\\), t.q. \\(x + \\epsilon &gt; x_0\\). Ainsi, \\(F(x + \\epsilon) \\geq F(x_0) \\geq q\\); par continuité à droite de \\(F\\), \\(F(x) \\geq q\\)",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#méthode-dinversion",
    "href": "Slides/slides_simulation.html#méthode-dinversion",
    "title": "Simulation",
    "section": "Méthode d’inversion",
    "text": "Méthode d’inversion\n\nThéorème 2 (Méthode d’inversion) Soit \\(X\\) une v.a réelle, et \\(U \\sim\\mathcal{U}([0,1])\\), alors la variable aléatoire \\(F_X^\\leftarrow(U)\\) a même loi que \\(X\\).\n\n\n\nPreuve: en utilisant le théorème précédent, on a \\[\n\\forall x\\in\\mathbb{R}, \\quad \\mathbb{P}(x \\geq F_X^\\leftarrow(U)) = \\mathbb{P}(F_X(x) \\geq U)\n\\]\n\n\nPuis, comme \\(U\\) est une loi uniforme sur \\([0,1]\\):\n\\[\n\\mathbb{P}(F_X(x) \\geq U) = F_X(x)\n\\]\n\n\nAinsi, \\(F_X^\\leftarrow(U)\\) et \\(X\\) ont même loi: les deux v.a. ont la même fonction de répartition",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#symétrie-de-la-loi-uniforme",
    "href": "Slides/slides_simulation.html#symétrie-de-la-loi-uniforme",
    "title": "Simulation",
    "section": "Symétrie de la loi uniforme",
    "text": "Symétrie de la loi uniforme\n\nProposition 1 (Symétrie de la loi uniforme) Soit \\(U \\sim \\mathcal{U}([0,1])\\) une variable uniforme sur \\([0,1]\\). Alors, \\(1-U\\) suit aussi une loi uniforme sur \\([0,1]\\).\n\n\nPreuve:\nOn va décrire la fonction de répartition de \\(1-U\\) et montrer qu’elle est égale à celle d’une loi uniforme sur \\([0,1]\\).\n\n\nLe résultat est facile pour \\(x \\notin [0,1]\\), on suppose donc \\(x \\in [0,1]\\).\n\n\\[\n\\begin{align*}\n\\mathbb{P}(1-U \\leq x)} & \\class{fragment}{{}= \\mathbb{P}(U \\geq 1-x) }\\\\\n                       & \\class{fragment}{{} = 1-(1-x)} \\\\\n                       & \\class{fragment}{{} = x}\n\\end{align*}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#exemple-loi-exponentielle",
    "href": "Slides/slides_simulation.html#exemple-loi-exponentielle",
    "title": "Simulation",
    "section": "Exemple : loi exponentielle",
    "text": "Exemple : loi exponentielle\n\n\n\nDensité d’une loi \\(\\mathcal{E}(\\lambda)\\) pour \\(\\lambda &gt; 0\\) : \\(f_{\\lambda}(x) = \\lambda e^{-\\lambda x}{1\\hspace{-3.8pt} 1}_{\\mathbb{R}_+}(x)\\)\nFonction de répartition: \\(F_{\\lambda}(x) = (1 - e^{-\\lambda x}) {1\\hspace{-3.8pt} 1}_{\\mathbb{R}_+}(x)\\)\n\\(F_{\\lambda}\\) est bijective (de \\(\\mathbb{R}_+\\) dans \\(]0,1[\\)) et pour tout \\(u \\in ]0,1[\\), \\(F_{\\lambda}^{-1}(u) = -\\frac{1}{\\lambda} \\log(1-u)\\)\n\n\n\n\nAvec le résultat: \\[\nU \\sim \\mathcal{U}([0,1]) \\iff 1-U \\sim \\mathcal{U}([0,1])\\enspace,\n\\]\n\nPour simuler une loi exponentielle: simuler \\(U\\) uniforme et appliquer \\(-\\tfrac{1}{\\lambda} \\log(\\cdot)\\)\n\\[\n\\boxed{-\\tfrac{1}{\\lambda} \\log(U) \\sim \\mathcal{E}(\\lambda)}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#visualisation",
    "href": "Slides/slides_simulation.html#visualisation",
    "title": "Simulation",
    "section": "Visualisation",
    "text": "Visualisation\nVoir animation dans la section Cours, section “Méthode d’inversion”.",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#méthode-de-rejet-contraintes",
    "href": "Slides/slides_simulation.html#méthode-de-rejet-contraintes",
    "title": "Simulation",
    "section": "Méthode de rejet: contraintes",
    "text": "Méthode de rejet: contraintes\nMotivation: simuler une variable aléatoire \\(X\\) de densité \\(f\\) (loi cible), mais \\(f\\) est trop compliquée pour la méthode de l’inverse.\n\nIdée: tirer suivant une autre loi \\(g\\) (loi des propositions) et rejeter certains tirages.\n\n\non sait simuler \\(Y\\) de loi \\(g\\),\nil existe \\(m &gt; 0\\) tel que \\(f(x) \\leq m \\cdot g(x)\\) (constante de majoration)\non sait évaluer le rapport d’acceptation \\(r(x) = \\frac{f(x)}{m\\cdot g(x)}\\)\n\n\n\n\nRemarque 1: \\(g(x)=0 \\implies f(x)=0\\), ainsi le support de \\(g\\) doit englober celui de \\(f\\)\n\n\nRemarque 2: \\(m \\geq 1\\) car \\(m = m \\displaystyle\\int_\\mathbb{R} g(x)\\, dx \\class{fragment}{{} \\geq \\displaystyle\\int_\\mathbb{R} f(x) dx} \\class{fragment}{{} = 1}\\)",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#méthode-de-rejet-principe",
    "href": "Slides/slides_simulation.html#méthode-de-rejet-principe",
    "title": "Simulation",
    "section": "Méthode de rejet: principe",
    "text": "Méthode de rejet: principe\nConsidérer deux suites i.i.d. de v.a. indépendantes entre elles:\n\n\\((Y_n)_{n \\geq 1}\\) de loi \\(g\\),\n\\((U_n)_{n \\geq 1}\\) de loi uniforme sur \\([0,1]\\).\n\nEn pratique, \\(Y_n\\) correspond à une proposition et \\(U_n\\) permettra de décider l’acceptation/rejet de la proposition:\n\n\nSi oui, alors on conserve \\(Y_n\\)\nSi non, on simule \\(Y_{n+1}\\)\n\nPour simuler \\(X\\) de densité \\(f\\), simuler \\(Y_n\\) (suivant \\(g\\)), \\(U_n\\) (suivant \\(\\mathcal{U}[0,1]\\)) et accepter si \\[\nU_n \\leq r(Y_n) = \\frac{f(Y_n)}{m\\cdot g(Y_n)}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#exemple-simple",
    "href": "Slides/slides_simulation.html#exemple-simple",
    "title": "Simulation",
    "section": "Exemple simple",
    "text": "Exemple simple\n \n\n\n\\(f(x) = 4x^3 {1\\hspace{-3.8pt} 1}_{[0,1]}(x)\\)\n\\(f\\) est majorée par \\(4\\) \\(\\implies\\) \\(g = {1\\hspace{-3.8pt} 1}_{[0,1]}\\) et \\(m=4\\) conviennent\n\\(r(x) =f(x) / (m\\cdot g(x)) = x^3\\), pour \\(x \\in [0,1]\\). On simule donc \\((Y_n, U_n)\\) et on teste si \\(4 \\cdot U_1 \\leq 4 Y_1^3\\), etc.\n\n\n\n\n\n\n\n\n\nNote\n\n\nDans la suite on verra qu’on tire des points \\((Y_n, 4U_n)\\) et qu’on teste si ils sont dans l’ensemble \\(\\{(x,y) \\in \\mathbb{R}^2: y \\leq f(x) \\}\\)",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#code-python",
    "href": "Slides/slides_simulation.html#code-python",
    "title": "Simulation",
    "section": "Code Python",
    "text": "Code Python\n\n\ndef accept_reject(n, f, g, g_sampler, m, rng):\n    \"\"\"\n    n: nombre de simulations\n    f: loi cible\n    g, g_sampler: loi et générateur des propositions                            \n    m: constante pour la majoration\n    rng: générateur pseudo-aléatoire\n    \"\"\"\n    x_samples = np.zeros(n)\n    u_samples = np.zeros(n)\n    accepted = np.zeros(n)\n    for i in range(n):\n        x = g_sampler()\n        u = rng.uniform()\n        alpha = u * m * g(x)  # note: pour le test on peut éviter les divisions\n        u_samples [i] = alpha\n        x_samples[i] = x\n        if  alpha &lt;= f(x):\n            accepted[i] = 1\n    return x_samples, u_samples, accepted",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#visualisation-de-lexemple",
    "href": "Slides/slides_simulation.html#visualisation-de-lexemple",
    "title": "Simulation",
    "section": "Visualisation de l’exemple",
    "text": "Visualisation de l’exemple",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#variante-avec-une-loi-triangulaire",
    "href": "Slides/slides_simulation.html#variante-avec-une-loi-triangulaire",
    "title": "Simulation",
    "section": "Variante avec une loi triangulaire",
    "text": "Variante avec une loi triangulaire\n \nSupposons disposer d’un générateur de loi triangulaire sur \\([0,1]\\) (cf. np.random.triangular(0, 1, 1))\n\n\n\\(f(x) = 4x^3 {1\\hspace{-3.8pt} 1}_{[0,1]}(x)\\)\n\\(f(x)\\) est majorée par \\(4 x \\cdot {1\\hspace{-3.8pt} 1}_{[0,1]}(x)\\) \\(\\implies\\) \\(g = 2x \\cdot {1\\hspace{-3.8pt} 1}_{[0,1]}\\) et \\(m=2\\) conviennent\n\\(r(x)=f(x) / (m\\cdot g(x)) = x^3\\), pour \\(x \\in [0,1]\\).",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#variante-continuée",
    "href": "Slides/slides_simulation.html#variante-continuée",
    "title": "Simulation",
    "section": "Variante (continuée)",
    "text": "Variante (continuée)",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#comparaison-des-deux-majorants",
    "href": "Slides/slides_simulation.html#comparaison-des-deux-majorants",
    "title": "Simulation",
    "section": "Comparaison des deux majorants",
    "text": "Comparaison des deux majorants\n\n\n\n\n\n\n\n\n\n\n\nmd`Taux d'acceptation: avec la loi uniforme **${ratio1.toPrecision(5)}**`\n\n\n\n\n\n\n\nmd`Taux d'acceptation: avec la loi triangulaire **${ratio2.toPrecision(5)}**`\n\n\n\n\n\n\n\nConclusion: plus le majorant est proche de la loi cible, plus le taux d’acceptation est élevé, et moins de simulations sont nécessaires\n\n\n\n\n\n\n\n\nNote\n\n\nL’exemple est pour l’illustration de la méthode, dans le cas présent méthode de l’inverse fonctionnerait aussi (on peut calculer la fonction quantile explicitement).",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#méthode-de-rejet-validation-théorique",
    "href": "Slides/slides_simulation.html#méthode-de-rejet-validation-théorique",
    "title": "Simulation",
    "section": "Méthode de rejet: validation théorique",
    "text": "Méthode de rejet: validation théorique\nRappel:\n\nil existe \\(m &gt; 0\\) tel que \\(f(x) \\leq m \\cdot g(x)\\) et \\(r(x) = \\frac{f(x)}{m\\cdot g(x)}\\)\n\\((Y_n)_{n \\geq 1}\\) i.i.d. de loi \\(g\\)\n\\((U_n)_{n \\geq 1}\\) i.i.d. de loi uniforme sur \\([0,1]\\) (indépendamment des \\(Y_n\\))\n\n\n\nThéorème 3 (Méthode de rejet) \nSoit \\(T = \\inf \\{n \\geq 1 : U_n \\leq r(Y_n)\\}\\) le premier instant où le tirage est accepté. Alors :\n\n\\(T \\sim \\mathcal{G}(\\frac{1}{m})\\) : loi géométrique de paramètre \\(\\frac{1}{m}\\)\n\\(Y_T\\) a pour densité \\(f\\) et est indépendante de \\(T\\)",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#démonstration",
    "href": "Slides/slides_simulation.html#démonstration",
    "title": "Simulation",
    "section": "Démonstration",
    "text": "Démonstration\nPour \\(x \\in \\mathbb{R}\\) et \\(n \\in \\mathbb{N}^{*}\\), et \\(X = Y_T\\), on écrit \\(\\mathbb{P}(X \\leq x, T=n)= \\mathbb{P}(U_1 &gt; r(Y_1), \\dots, U_{n-1} &gt; r(Y_{n-1}), U_n \\leq r(Y_n), Y_n \\leq x)\\)\n\n\\[\n    \\mathbb{P}(X \\leq x, T=n) = {\\color{blue}\\mathbb{P}(U_1 &gt; r(Y_1))}^{n-1} \\cdot {\\color{brown}\\mathbb{P}(U_n \\leq r(Y_n), Y_n \\leq x)}, \\quad \\textsf{( tirages i.i.d.)}\n\\]\n\n\nPremier terme: \\(Y_1\\) et \\(U_1\\) sont indépendantes, leur loi jointe correspond au produit des densités :\n\n\n\\[\n{\\color{blue}\n\\begin{align*}\n        \\mathbb{P}(U_1 &gt; r(Y_1))\n         & \\class{fragment}{{} = \\mathbb{P}((U_1, Y_1) \\in \\{(u,y) \\in \\mathbb{R}^2 : u &gt; r(y)\\})}                             \\\\\n         & \\class{fragment}{{} = \\int_{\\mathbb{R}^2} \\left( {1\\hspace{-3.8pt} 1}_{\\{u &gt; r(y)\\}} \\right) \\cdot \\left({1\\hspace{-3.8pt} 1}_{[0,1]}(u) g(y)\\right) \\,  du  dy}  \\\\\n         & \\class{fragment}{{} = \\int_\\mathbb{R} \\left( \\int_0^1 {1\\hspace{-3.8pt} 1}_{\\{u &gt; r(y)\\}} \\,  du\\right) g(y)\\,  d y}\n         \\class{fragment}{{} =  \\int_\\mathbb{R} (1-r(y)) \\, g(y)\\,  d y}\\\\\n         & \\class{fragment}{{} =  \\int_\\mathbb{R} g(y) -  \\int_\\mathbb{R}\\frac{f(y)}{m} d y, \\quad\\quad \\text{car }  r(y) = \\frac{f(y)}{m \\cdot g(y)}}\\\\\n     & \\class{fragment}{{} = 1-\\tfrac{1}{m}}\n\\end{align*}\n}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#démonstration-suite",
    "href": "Slides/slides_simulation.html#démonstration-suite",
    "title": "Simulation",
    "section": "Démonstration (suite)",
    "text": "Démonstration (suite)\nSecond terme: \\[\n{\\color{brown}\n\\begin{align*}\n    \\mathbb{P}(U_n \\leq r(Y_n), Y_n \\leq x)\n    & \\class{fragment}{{ = \\int_{\\mathbb{R}^2} {1\\hspace{-3.8pt} 1}_{\\{u \\leq r(y)\\}} {1\\hspace{-3.8pt} 1}_{\\{y \\leq x\\}} ({1\\hspace{-3.8pt} 1}_{[0,1]}(u) g(y)) \\,  du  dy  }} \\\\\n    & \\class{fragment}{{} = \\int_\\mathbb{R} \\left( \\int_0^1  {1\\hspace{-3.8pt} 1}_{\\{u \\leq r(y)\\}} \\,  du\\right) {1\\hspace{-3.8pt} 1}_{\\{y \\leq x\\}}  g(y)\\,  d y} \\\\\n        & \\class{fragment}{{} = \\int_\\mathbb{R} r(y) {1\\hspace{-3.8pt} 1}_{\\{y \\leq x\\}}  g(y)\\,  d y } \\\\\n        & \\class{fragment}{{} = \\int_{-\\infty}^x \\dfrac{f(y)}{m}\\,  d y } \\\\\n        & \\class{fragment}{{} = \\dfrac{F(x)}{m} , \\quad F \\textsf{ fonction de répartition associée à} f}\n\\end{align*}\n}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#démonstration-suite-1",
    "href": "Slides/slides_simulation.html#démonstration-suite-1",
    "title": "Simulation",
    "section": "Démonstration (suite)",
    "text": "Démonstration (suite)\n\\[\n    \\mathbb{P}(X \\leq x, T=n)\n    =\n    {\\color{blue}\\left(1 - \\tfrac{1}{m}\\right)^{n-1}} \\cdot {\\color{brown}\\tfrac{F(x)}{m}}\n\\]\n\nOn peut alors obtenir les lois marginales: \\[\n\\begin{align*}\n    \\mathbb{P}(T=n)\n    & = \\lim_{q \\to \\infty} \\mathbb{P}(X \\in ]-\\infty, q], T=n) = \\lim_{q \\to \\infty} \\left(1 - \\tfrac{1}{m}\\right)^{n-1} \\tfrac{F(q)}{m}\\\\\n    & = \\left(1 - \\tfrac{1}{m}\\right)^{n-1} \\tfrac{1}{m}\n\\end{align*}\n\\] Ainsi, \\(T\\) suit une loi géométrique de paramètre \\(1/m\\), puis \\(X\\) a pour loi \\(F\\):\n\n\n\\[\n\\begin{align*}\n    \\mathbb{P}(X \\leq x)\n    & = \\mathbb{P}(X \\leq x, T \\in \\mathbb{N}^*)\n      = \\sum_{n=1}^\\infty \\mathbb{P}(X \\leq x, T=n) \\\\\n    & = \\sum_{n=1}^\\infty \\left(1 - \\tfrac{1}{m}\\right)^{n-1} \\tfrac{F(x)}{m}\n      = \\tfrac{1}{1-(1-1/m)} \\tfrac{F(x)}{m} = F(x) \\enspace.\n\\end{align*}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#fin-de-la-démonstration",
    "href": "Slides/slides_simulation.html#fin-de-la-démonstration",
    "title": "Simulation",
    "section": "Fin de la démonstration",
    "text": "Fin de la démonstration\nOn obtient l’indépendance de \\(T\\) et \\(X\\) car on peut alors écrire: \\[\n    \\forall x \\in \\mathbb{R}, \\forall n \\in \\mathbb{N}^*, \\quad\n    \\mathbb{P}(X \\leq x, T=n)\n    =\n    \\mathbb{P}(X \\leq x) \\cdot \\mathbb{P}(T=n)\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#cas-de-densité-connue-à-une-constante-près-exemple",
    "href": "Slides/slides_simulation.html#cas-de-densité-connue-à-une-constante-près-exemple",
    "title": "Simulation",
    "section": "Cas de densité connue à une constante près : exemple",
    "text": "Cas de densité connue à une constante près : exemple\nLoi de Andrews (densité proportionnelle à \\(\\mathrm{sinc}\\), sinus cardinal): \\[\n\\forall x \\in \\mathbb{R},\\quad f(x) = \\frac{1}{S} \\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}  {1\\hspace{-3.8pt} 1}_{[-1,1]}(x)\n\\] avec \\(S = \\int_{-1}^{1}\\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}dx\\) non explicite. On note parfois: \\(f(x) \\propto \\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}  {1\\hspace{-3.8pt} 1}_{[-1,1]}(x)\\)\n\n\nMéthode du rejet: prendre \\(m=2/S\\) et \\(g(x) = \\frac{1}{2} {1\\hspace{-3.8pt} 1}_{[-1,1]}(x)\\):\n\\[\nu \\leq r(x) = \\frac{f(x)}{m \\cdot g(x)} \\iff u \\leq \\frac{1}{S} \\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}  \\cdot \\frac{1}{\\frac{2}{S} g(x)} = \\frac{\\sin(\\pi\\cdot x)}{\\pi \\cdot x}  \\cdot \\frac{1}{2 \\cdot g(x)}\n\\]\n\n\nAinsi l’évaluation de \\(r(x)\\) est possible sans connaître \\(S\\)!",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#loi-de-andrews-visualisation",
    "href": "Slides/slides_simulation.html#loi-de-andrews-visualisation",
    "title": "Simulation",
    "section": "Loi de Andrews: visualisation",
    "text": "Loi de Andrews: visualisation\n\nn = 300\nm = 2\nrng = np.random.default_rng(seed)\ng = lambda x: np.ones_like(x) / 2\ng_sampler = lambda: 2 * rng.uniform() - 1\nx_samples, u_samples, accepted = accept_reject(n, np.sinc, g, g_sampler, m, rng)\n\n\n\n\n\n\n\n\n\n\n\n\nmd`Le taux d'acceptation est ici de **${ratio_andrews.toPrecision(3)}**.`\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n\n\n\n\nmd`Pour la visualization, on approxime S=**${s_int.toPrecision(3)}** en utilisant une méthode de calcul numérique.`",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#cas-de-densité-connue-à-une-constante-près-cas-général",
    "href": "Slides/slides_simulation.html#cas-de-densité-connue-à-une-constante-près-cas-général",
    "title": "Simulation",
    "section": "Cas de densité connue à une constante près (cas général)",
    "text": "Cas de densité connue à une constante près (cas général)\nSoit \\(\\tilde{f}: \\mathbb{R} \\to [0,+\\infty[\\) connue et \\(S \\triangleq \\int_{\\mathbb{R}} \\tilde{f}(x) \\,  d x  &lt; + \\infty\\) inconnue (ou dure à évaluer)\nDensité cible: \\(\\quad f(x) = \\frac{\\tilde{f}(x)}{S}\\)\n\nMéthode du rejet pour \\(f\\), en utilisant seulement \\(\\tilde{f}\\): soit \\(\\tilde{m}&gt;0\\) un majorant de \\(\\tilde{f}\\) t.q. \\[\n\\begin{align*}\n\\tilde{f}(x) \\leq  \\tilde{m} \\cdot g(x)\n\\end{align*}\n\\]\nApplication avec \\(m=\\tilde{m}/S\\) (sans connaître \\(S\\)), le test d’acceptation donne:\n\n\\[\n\\begin{align*}\nU_n & \\leq \\frac{f(Y_n)}{m \\cdot g(Y_n)}\\\\\n  & \\class{fragment}{{}\\leq \\frac{\\frac{\\tilde{f}(Y_n)}{S}}{\\frac{\\tilde{m}}{S} \\cdot g(Y_n)}} \\class{fragment}{{}= \\frac{\\tilde{f}(Y_n)}{\\tilde{m} \\cdot g(Y_n)}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#cas-multidimensionnel",
    "href": "Slides/slides_simulation.html#cas-multidimensionnel",
    "title": "Simulation",
    "section": "Cas multidimensionnel",
    "text": "Cas multidimensionnel\n\n\n\nimpossibilité de la méthode de l’inverse: fonction de répartition non disponible (en général)\nla méthode de rejet : généralisable au cas multidimensionnel\n\n“fléau de la dimension”: plus la dimension est grande, plus la méthode est inefficace (penser au nombre de points nécessaires pour quadriller un hypercube…)\ndifficulté d’écrire une fonction de majoration en toute généralité",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#exemple-loi-uniforme-sur-le-disque-unité-2d",
    "href": "Slides/slides_simulation.html#exemple-loi-uniforme-sur-le-disque-unité-2d",
    "title": "Simulation",
    "section": "Exemple: loi uniforme sur le disque unité (2D)",
    "text": "Exemple: loi uniforme sur le disque unité (2D)\n\nLoi cible: loi uniforme sur le disque unité, \\(f(x)\\propto {1\\hspace{-3.8pt} 1}_{x_1^2+x_2^2 \\leq 1}(x)\\) pour \\(x=(x_1,x_2)\\in\\mathbb{R}^2\\)\n\nLoi majorante: loi uniforme sur le carré \\([-1,1]^2\\), \\(g(x)\\triangleq \\tfrac{1}{2} {1\\hspace{-3.8pt} 1}_{[-1, 1]^2}(x)\\) et \\(m=2\\)\n\n\n\n\n\n\n\nNote\n\n\nLa loi uniforme sur le carré est une loi produit: il suffit de savoir générer une loi uniforme sur un segment 1D pour l’obtenir",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#exemple-loi-uniforme-sur-le-disque-visualisation",
    "href": "Slides/slides_simulation.html#exemple-loi-uniforme-sur-le-disque-visualisation",
    "title": "Simulation",
    "section": "Exemple: loi uniforme sur le disque (visualisation)",
    "text": "Exemple: loi uniforme sur le disque (visualisation)\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`Ratio estimée: **${ratio.toPrecision(5)}**`\nmd`Aire (bleue) estimé: **${aire.toPrecision(5)}**`",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#exemple-loi-uniforme-sur-une-cardioïde-2d",
    "href": "Slides/slides_simulation.html#exemple-loi-uniforme-sur-une-cardioïde-2d",
    "title": "Simulation",
    "section": "Exemple: loi uniforme sur une cardioïde (2D)",
    "text": "Exemple: loi uniforme sur une cardioïde (2D)\n\nLoi cible: loi uniforme sur le disque unité, \\(f(x)\\triangleq{1\\hspace{-3.8pt} 1}_{(x_1^2+x_2^2 - x_2)^2 \\leq x_1^2+ x_2^2}(x)\\) pour \\(x=(x_1,x_2)\\in\\mathbb{R}^2\\) \nLoi majorante: loi uniforme sur le rectangle \\([-2,3]\\times [-1.5,1.5]\\), \\(g(x)\\triangleq \\tfrac{1}{15}{1\\hspace{-3.8pt} 1}_{[-2,3]\\times [-1.5,1.5]}(x)\\) et \\(m=15\\)\n\n\n\n\n\n\n\nNote\n\n\nLa loi uniforme sur un rectangle est une loi produit: il suffit de savoir générer une loi uniforme sur un segment 1D pour l’obtenir",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#exemple-loi-uniforme-sur-une-cardioïde-2d-1",
    "href": "Slides/slides_simulation.html#exemple-loi-uniforme-sur-une-cardioïde-2d-1",
    "title": "Simulation",
    "section": "Exemple: loi uniforme sur une cardioïde (2D)",
    "text": "Exemple: loi uniforme sur une cardioïde (2D)\n\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`Ratio estimée: **${ratio_cardioid.toPrecision(5)}**`\nmd`Aire (bleue) estimé: **${aire_cardioid.toPrecision(5)}**`",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#théorie",
    "href": "Slides/slides_simulation.html#théorie",
    "title": "Simulation",
    "section": "Théorie",
    "text": "Théorie\n\nThéorème 4 (Géneration uniforme sur un ensemble) Soient \\(A\\subset B \\subset \\mathbb{R}^d\\), deux ensembles mesurables pour la mesure de Lebesgue. Pour générer selon \\(\\mathcal{U}(A)\\), connaissant un générateur selon \\(\\mathcal{U}(B)\\), la méthode du rejet consiste ici à tirer \\(Y_i \\sim \\mathcal{U}(B)\\) (i.i.d) et à garder \\(Y_i\\) si \\(Y_i \\in A\\).\n\n\nPreuve: On note \\(f\\triangleq \\frac{1}{|A|} {1\\hspace{-3.8pt} 1}_{A}\\), \\(g\\triangleq \\frac{1}{|B|}{1\\hspace{-3.8pt} 1}_{B}\\) et \\(m\\triangleq\\frac{|B|}{|A|}\\). Comme \\(A \\subset B\\), pour tout \\(x\\in \\mathbb{R}^{d}\\): \\[\n\\begin{align*}\n\\class{fragment}{{}f(x)} \\class{fragment}{{}= \\frac{1}{|A|} {1\\hspace{-3.8pt} 1}_{A}(x)} \\class{fragment}{{}\\leq \\frac{1}{|B|} {1\\hspace{-3.8pt} 1}_{B}(x) \\cdot \\frac{|B|}{|A|}} \\class{fragment}{{}\\leq g(x) \\cdot m}\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n&\\class{fragment}{{}Y \\sim \\mathcal{U}(B),} \\quad \\class{fragment}{{} U \\sim \\mathcal{U}([0,1])} \\\\\n&\\class{fragment}{{}r(Y)} \\class{fragment}{{}= \\frac{f(Y)}{m\\cdot g(Y)}}\n\\class{fragment}{{}=\n\\frac{ \\frac{1}{|A|} {1\\hspace{-3.8pt} 1}_{A}(Y)}\n{\\frac{|B|}{|A|}\\cdot \\frac{1}{|B|} {1\\hspace{-3.8pt} 1}_{B}(Y)}}\n\\class{fragment}{{}=\n\\frac{  {1\\hspace{-3.8pt} 1}_{A}(Y)}\n{ {1\\hspace{-3.8pt} 1}_{B}(Y)}}\n\\class{fragment}{{}= {1\\hspace{-3.8pt} 1}_{A}(Y)}\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\class{fragment}{{}\\text{Enfin}, U \\leq {1\\hspace{-3.8pt} 1}_{A}(Y) \\iff {1\\hspace{-3.8pt} 1}_{A}(Y)=1}\\class{fragment}{{}\\iff Y \\in A}\n\\end{align*}\n\\]",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#remarque-sur-les-constantes",
    "href": "Slides/slides_simulation.html#remarque-sur-les-constantes",
    "title": "Simulation",
    "section": "Remarque sur les constantes",
    "text": "Remarque sur les constantes\n\nDans l’exemple précédent, on a pu appliquer la méthode de rejet sans la connaissance de \\(m\\)\n\nPoint important: parfois la connaissance de \\(m\\) est difficile à obtenir, et il est préférable de ne pas l’utiliser (notamment quand les constantes de normalisation des densités sont difficiles à calculer).\n Exemples: statistiques bayesiennes, modèles graphiques, etc.",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#sommes-de-variables-aléatoires",
    "href": "Slides/slides_simulation.html#sommes-de-variables-aléatoires",
    "title": "Simulation",
    "section": "Sommes de variables aléatoires",
    "text": "Sommes de variables aléatoires\nLoi de Bernoulli: avec \\(U_1, \\ldots, U_n\\) i.i.d uniformes sur \\([0,1]\\) (méthode d’inversion): \\[\nX_i \\triangleq {1\\hspace{-3.8pt} 1}_{\\{U_i \\leq p\\}} \\sim \\mathcal{B}(p)\n\\]\n\nLoi binomiale: \\[\n    \\sum_{i=1}^n {1\\hspace{-3.8pt} 1}_{\\{U_i \\leq p\\}} \\sim \\mathcal{B}(n,p)\n\\] en rappelant que \\[\n    X = X_1 + \\cdots + X_n \\sim \\mathcal{B}(n,p)\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\nLa méthode d’inversion marche aussi, mais nécessite le calcul de l’inverse généralisée de \\(F\\), donc de coefficients binomiaux…",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#loi-de-poisson",
    "href": "Slides/slides_simulation.html#loi-de-poisson",
    "title": "Simulation",
    "section": "Loi de Poisson",
    "text": "Loi de Poisson\nRappel: \\(\\quad X \\sim \\mathcal{P}(\\lambda) \\iff \\mathbb{P}(X = k) = e^{-\\lambda} \\dfrac{\\lambda^k}{k!}\\,, \\quad  \\forall k \\in \\mathbb{N}.\\)\n\nProposition 2 (Génération de v.a. de loi de Poisson) \nSoit \\((E_n)_{n \\geq 1}\\) des variables aléatoires i.i.d. de loi exponentielle de paramètre \\(\\lambda &gt; 0\\). On pose \\(S_k = E_1 + \\cdots + E_k\\). Alors pour tout \\(n \\in \\mathbb{N}\\) \\[\n    \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1}) =  e^{-\\lambda} \\dfrac{\\lambda^n}{n!}\\enspace .\n\\] Ainsi, \\(T \\triangleq \\sup \\{n \\in \\mathbb{N} : S_n \\leq 1\\}\\) suit une loi de Poisson de paramètre \\(\\lambda\\) : \\(T \\sim \\mathcal{P}(\\lambda)\\).\n\n\n\n\n\n\n\n\nPoint numérique\n\n\nMéthode adaptée par numpy.random.poisson, cf. code source, qui fut proposée par D. Knuth; Source: Wikipedia",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#loi-de-poisson-suite",
    "href": "Slides/slides_simulation.html#loi-de-poisson-suite",
    "title": "Simulation",
    "section": "Loi de Poisson (suite)",
    "text": "Loi de Poisson (suite)\nLa preuve repose sur le résultat suivant:\n\nLemme 1 (Loi de Erlang) \nSoient \\(E_1, \\dots, E_n\\) des v.a., i.i.d. de loi exponentielle de paramètre \\(\\lambda &gt;0\\). La somme \\(S_n=E_1+\\dots+E_n\\) suit une loi d’Erlang de paramètres \\((n,\\lambda)\\), de fonction de répartition \\[\n    F_{n,\\lambda}(t) = 1 - \\sum_{k=0}^{n-1} e^{-\\lambda t} \\frac{(\\lambda t)^k}{k!}\\,.\n\\]\n\n\nPreuve partielle: Transformée de Laplace de \\(\\mathcal{E}(\\lambda)\\): \\(\\mathbb{E}\\left(e^{-tE_1}\\right) = \\int_0^{+\\infty} e^{-t x} \\lambda e^{-\\lambda x} \\,  d x = \\frac{\\lambda}{\\lambda+t}\\)\n\n\nDensité d’une loi \\(\\Gamma(\\alpha,\\beta): \\quad f(x) = \\tfrac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x}\\)\n\n\nTransformée de Laplace d’une loi \\(\\Gamma(\\alpha,\\beta): \\quad \\mathbb{E}\\left(e^{-tX}\\right) = \\left(\\tfrac{\\beta}{\\beta+t}\\right)^\\alpha\\)\n\n\nEnfin, \\(\\mathbb{E}\\left(e^{-t S_n}\\right) = \\left(\\mathbb{E}\\left(e^{-t E_1}\\right)\\right)^n=\\left(\\tfrac{\\lambda}{\\lambda+t}\\right)^n\\)",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "Slides/slides_simulation.html#démonstration-avec-le-lemme",
    "href": "Slides/slides_simulation.html#démonstration-avec-le-lemme",
    "title": "Simulation",
    "section": "Démonstration avec le lemme",
    "text": "Démonstration avec le lemme\nPour \\(n \\in \\mathbb{N}^*\\), on décompose la probabilité \\(\\mathbb{P}(S_n \\leq 1 &lt; S_{n+1})\\) via \\[\n\\begin{align*}\n    \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1})\n    & = \\mathbb{P}(\\{S_n \\leq 1\\} \\setminus \\{S_{n+1} \\leq 1\\})\\\\\n    & = \\mathbb{P}(S_n \\leq 1) - \\mathbb{P}(S_{n+1} \\leq 1)\\,.\n\\end{align*}\n\\]\n\nDu lemme précédent : \\(\\mathbb{P}(S_n \\leq 1) = 1 - \\displaystyle\\sum_{k=0}^{n-1} e^{-\\lambda} \\dfrac{\\lambda^k}{k!}\\) et \\(\\mathbb{P}(S_{n+1} \\leq 1) = 1 - \\displaystyle\\sum_{k=0}^{n} e^{-\\lambda} \\dfrac{\\lambda^k}{k!}\\).\n\n\nPuis, \\[\n    \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1})\n    = e^{-\\lambda} \\dfrac{\\lambda^n}{n!}\\,.\n\\]\n\n\nOn conclut la preuve de la proposition en remarquant que pour \\(T \\triangleq \\sup \\{k \\in \\mathbb{N}^* : S_k \\leq 1\\}\\) \\[\n    \\mathbb{P}(T=n) = \\mathbb{P}(S_n \\leq 1 &lt; S_{n+1})\\,.\n\\]\n\n\n\nSimulation",
    "crumbs": [
      "Slides",
      "Simulation"
    ]
  },
  {
    "objectID": "TD/TD1.html#test2",
    "href": "TD/TD1.html#test2",
    "title": "TD1:…",
    "section": "test2",
    "text": "test2",
    "crumbs": [
      "TD",
      "TD1:..."
    ]
  },
  {
    "objectID": "TP/TP2.html",
    "href": "TP/TP2.html",
    "title": "TP2: Simulation de lois élémentaires",
    "section": "",
    "text": "Objectifs de ce TP\n\n\n\n\nUtiliser les générateurs aléatoires en Python et numpy, savoir afficher un histogramme, une densité, etc.\nComprendre au mieux comment utiliser les fonctions aléatoires (principalement les générateurs) en numpy.",
    "crumbs": [
      "TP",
      "TP2: Simulation de lois élémentaires"
    ]
  },
  {
    "objectID": "TP/TP2.html#loi-uniforme-et-graine.",
    "href": "TP/TP2.html#loi-uniforme-et-graine.",
    "title": "TP2: Simulation de lois élémentaires",
    "section": "Loi uniforme et graine.",
    "text": "Loi uniforme et graine.\nAvec numpy, la fonction numpy.random.uniform permet la génération de réalisations pseudo-aléatoires de la loi uniforme sur [0,1].\nOn peut modifier la taille de l’échantillon généré en modifiant l’argument de la fonction. Pour obtenir n=4 réalisations i.i.d. de loi uniforme, essayez par exemple\n\nimport numpy as np\nnp.random.uniform(size=4)\n\narray([0.80707097, 0.37447255, 0.9741228 , 0.72934639])\n\n\nPour rappel, l’algorithme de génération de v.a. est récursif et s’appuie sur une graine. La graine peut être modifiée avec la création d’un générateur, et il suffit d’entrer un nombre en argument pour fixer cette graine.\n\nrng = np.random.default_rng(seed=34)\nprint(rng.uniform())\nrng = np.random.default_rng(34)\nprint(rng.uniform())\n\n0.004028243493043537\n0.004028243493043537\n\n\nChanger les valeurs de seed et vérifier que les tirages ont bien changé.",
    "crumbs": [
      "TP",
      "TP2: Simulation de lois élémentaires"
    ]
  },
  {
    "objectID": "TP/TP2.html#exercice-1-simulation-de-loi-uniforme-et-histogramme",
    "href": "TP/TP2.html#exercice-1-simulation-de-loi-uniforme-et-histogramme",
    "title": "TP2: Simulation de lois élémentaires",
    "section": "Exercice 1: Simulation de loi uniforme et histogramme",
    "text": "Exercice 1: Simulation de loi uniforme et histogramme\nCréez un vecteur de taille 1000 composé de réalisations i.i.d. de v.a.uniformes sur [-1,1]. Dans la suite on supposera que l’on a chargé matplotlib pour l’affichage graphique avec la commande:\n\nimport matplotlib.pylab as plt\nfrom scipy import stats\n\nÀ l’aide de la fonction plt.hist, représentez l’histogramme de cet échantillon:\nfig, ax = plt.subplots()\nvect = rng.uniform(-1, 1, 1000)\nax.hist(vect, label=\"Histogramme\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nOn utilisera l’aide de hist de matplotlibs pour préciser les options graphiques suivantes:\n\nAnalysez en particulier ce que fait l’option bins en entrant l’option bins=30 et bins=10.\nModifiez également votre histogramme avec l’option density=True, de sorte que l’aire soit de 1 (on représente donc une densité qui est constante par morceaux)\nAjoutez un titre à l’histogramme grâce à la commande plt.title (avec une chaîne de caractères entre guillemets). On peut également ajouter un nom aux axes avec l’option plt.xlabel et plt.ylabel.\nLes options ax.set_xlim et ax.set_ylim permettent de préciser l’échelle de axes: il faut préciser un tuple (a,b) où a&lt;b sont les deux bornes choisies pour votre axe.\nOn modifiera aussi les options fill et histtype de hist pour obtenir le résultat suivant, en affichant sur un même graphique trois tirages, de tailles 1000, 5000 et 10000.\nLa densité de la loi uniforme est obtenue avec la fonction pdf du module scipy.stats. Créer un vecteur équiréparti sur [-2, 2] de longueur 300 évaluer la fonction sur la même figure: on souhaite superposer cette densité à l’histogramme. On utilisera la fonction plot pour tracer la densité, et on pourra utiliser l’option alpha pour rendre la densité plus transparente.\n\nUn exemple de figure de qualité acceptable est par exemple celle qui suit:\n\n\n\n\n\n\n\n\n\n\nAttention quand vous tracez des histogrammes pour des réalisation de la v.a. non bornées: pour la gaussienne, les histogrammes sont bons\n\nCode\nvectGauss = np.random.randn(1000)\n\nfig, ax = plt.subplots()\n\nxx = np.linspace(vectGauss.min() - 1, vectGauss.max() + 1, 100)\nax.plot(xx, stats.norm.pdf(xx, loc=0, scale=1),'--', color='k', label=\"Loi théorique\", alpha=0.5)\n\nax.hist(vectGauss, histtype='step', density=True, bins=30, label=\"Histogramme 10000\", fill=False, color=colors[0])\n# plot density\n\nplt.title('Histogramme: tirage Gaussien')\nplt.show()\n\n\n\n\n\n\n\n\nPour la Cauchy, les histogrammes se comportent mal\n\nCode\nvectCauchy = np.random.standard_cauchy(10000)\n\nfig, ax = plt.subplots()\n\nxx = np.linspace(vectCauchy.min() - 1, vectCauchy.max() + 1, 100)\nax.plot(xx, stats.cauchy.pdf(xx, loc=0, scale=1),'--', color='k', label=\"Loi théorique\", alpha=0.5)\n\nax.hist(vectCauchy, histtype='step', density=True, bins=30, label=\"Histogramme 10000\", fill=False, color=colors[0])\nplt.title('Histogramme naïf: tirage Cauchy...')\nplt.show()\n# plot density\n\n\n\n\n\n\n\n\nIl faut tronquer pour retrouver une représentation fidèle:\n\nCode\nxmax = 11\nfig, ax = plt.subplots()\n\nxx = np.linspace(-xmax - 1, xmax + 1, 100)\nax.plot(xx, stats.cauchy.pdf(xx, loc=0, scale=1),'--', color='k', label=\"Loi théorique\", alpha=0.5)\n\nax.hist(vectCauchy[np.abs(vectCauchy) &lt; xmax], histtype='step', density=True, bins=30, label=\"Histogramme 10000\", fill=False, color=colors[0])\n# plot density\n\nax.set_xlim((-xmax - 1, xmax + 1))\n\nplt.title('Histogramme : tirage Cauchy tronquée...')\nplt.show()",
    "crumbs": [
      "TP",
      "TP2: Simulation de lois élémentaires"
    ]
  },
  {
    "objectID": "TP/TP2.html#exercice-2-fonction-de-répartition-de-la-loi-uniforme",
    "href": "TP/TP2.html#exercice-2-fonction-de-répartition-de-la-loi-uniforme",
    "title": "TP2: Simulation de lois élémentaires",
    "section": "Exercice 2: Fonction de répartition de la loi uniforme",
    "text": "Exercice 2: Fonction de répartition de la loi uniforme\nLa fonction de répartition de la loi uniforme est obtenue via la commande cdf du module scipy.stats.uniform. À l’aide de la commande plt.plot tracez en bleu la fonction de répartition de la loi uniforme sur [-1,1], [-0.7, 0.7] et [-0.5,0.5] et donnez un titre à votre graphique.\n\nOn contrôle avec lw (linewidth) l’épaisseur du trait.\nVous pouvez modifier le style et les marqueurs facilement en matplotlib. Une liste exhaustive est donnée ici: matplotlib.pyplot.plot.html\nEnfin pour les couleurs on pourra consulter l’aide en ligne ici: Color tutorial. La manière la plus simple est souvent d’ajouter l’option color=nom_couleur dans la fonction plot.\n\nManipulez les différentes options pour vous familiariser avec les graphes\n\n\n\n\n\n\n\n\n\n\n² :::{.callout-note}",
    "crumbs": [
      "TP",
      "TP2: Simulation de lois élémentaires"
    ]
  },
  {
    "objectID": "TP/TP2.html#pour-aller-plus-loin",
    "href": "TP/TP2.html#pour-aller-plus-loin",
    "title": "TP2: Simulation de lois élémentaires",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\nTenter de reproduire la figure suivante\n\n\n\n\n\n\n\n\n\n\n:::",
    "crumbs": [
      "TP",
      "TP2: Simulation de lois élémentaires"
    ]
  },
  {
    "objectID": "TP/TP2.html#exercice-3-étude-de-la-moyenne-empirique",
    "href": "TP/TP2.html#exercice-3-étude-de-la-moyenne-empirique",
    "title": "TP2: Simulation de lois élémentaires",
    "section": "Exercice 3: Étude de la moyenne empirique",
    "text": "Exercice 3: Étude de la moyenne empirique\nCréez un vecteur de taille 100 composé de réalisations i.i.d. de variables uniformes sur [0,1]. Calculez dans un vecteur la moyenne cumulée des valeurs générées. Représenter graphiquement l’évolution de ces moyennes. Vers quoi semble converger la moyenne quand la taille de l’échantillon augmente ?\nPour ajouter une droite à un graphe, on utilise la commande ax.axhline. Ajoutez en rouge la droite d’équation y=1/2 sur le graphe précédent. Refaites cet exercice avec un échantillon de taille n=1000 pour observer plus finement la convergence.",
    "crumbs": [
      "TP",
      "TP2: Simulation de lois élémentaires"
    ]
  },
  {
    "objectID": "TP/TP2.html#exercice-4-méthode-dinversion-loi-exponentielle-et-loi-de-cauchy",
    "href": "TP/TP2.html#exercice-4-méthode-dinversion-loi-exponentielle-et-loi-de-cauchy",
    "title": "TP2: Simulation de lois élémentaires",
    "section": "Exercice 4: Méthode d’inversion, loi exponentielle et loi de Cauchy",
    "text": "Exercice 4: Méthode d’inversion, loi exponentielle et loi de Cauchy\n\nReprésentez graphiquement la fonction de répartition d’une loi exponentielle de paramètre \\lambda=1.\nÉcrivez une fonction dzexpo qui prend en argument une taille d’échantillon n et un paramètre \\lambda &gt; 0 et qui donne en sortie un échantillon de taille n de loi \\mathcal{E}(\\lambda). On utilisera la méthode d’inversion vue en cours et seulement des tirages uniformes sur [0,1]. Attention, le mot clef lambda est un mot réservé en Python.\nReprésentez graphiquement l’histogramme cumulé (voir l’option cumulative de hist) d’un tel échantillon pour n=10^2, n=10^3, puis n=10^4, et pour \\lambda = 1, puis \\lambda = 4. Superposez à chaque fois le graphe de la densité de \\mathcal{E}(\\lambda).\nIllustrez graphiquement la loi des grands nombres avec \\lambda = 1, puis \\lambda = 4. On tracera en particulier la droite d’équation y=\\mathbb{E}[X], où X \\sim \\mathcal{E}(\\lambda).\nReprenez les questions précédentes avec la loi de Cauchy (mais représenter la densité plutôt que les fonctions de répartition). Commentez les résultats obtenus.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn reprend le tout avec la loi de Cauchy:",
    "crumbs": [
      "TP",
      "TP2: Simulation de lois élémentaires"
    ]
  },
  {
    "objectID": "TP/TP2.html#pour-aller-plus-loin-les-méthodes-à-noyaux-kde",
    "href": "TP/TP2.html#pour-aller-plus-loin-les-méthodes-à-noyaux-kde",
    "title": "TP2: Simulation de lois élémentaires",
    "section": "Pour aller plus loin: les méthodes à noyaux (KDE)",
    "text": "Pour aller plus loin: les méthodes à noyaux (KDE)\nLe phénomène qui apparaît avec la loi de Cauchy est les suivant: les queues de la loi de Cauchy sont tellement épaisses que la moyenne empirique que l’écart entre \\min_i(X_i) et le \\max_i(X_i) (les X_i étant les tirages effectués) est du même ordre de grandeur que le nombre de tirages, n. Comme la fonction hist discrétise l’intervalle [\\min(X_i), \\max(X_i)] en le nombre de boîtes (bins) on observe peu de points dans chaque boîte ce qui rend l’estimation de la densité trop petite.\nCe point n’est pas un problème pour les lois gaussiennes, car la largeur de l’intervalle [\\min(X_i), \\max(X_i)] est de l’ordre de \\sqrt{\\log(n)}, et comme on a n points à placer dans cet intervalle, il y a assez de points dans chaque boîte pour obtenir une bonne estimation.\nNotons que les méthodes à noyaux (KDE) ne souffrent pas de ce défaut, car les “boîtes” sont en fait fixé autour des données et non sur une grille discrétisée comme c’est le cas pour l’histogramme. Voir par exemple l’aide de scikit learn ou encore wikipedia, méthode à noyau.\n\nimport plotly.graph_objects as go\nfrom sklearn.neighbors import KernelDensity\nn_sample = 1000\nx = np.linspace(-2, 10, num=10000)\nX=dzcauchy(n_sample, 1)\n\nkde = KernelDensity(kernel=\"tophat\", bandwidth=0.1).fit(X.reshape(-1, 1))\nlog_dens = kde.score_samples(x.reshape(-1, 1))\nfig=go.Figure()\n\nfig.add_trace(go.Scatter(x=x, y=np.exp(log_dens), mode='lines', line=dict(color='blue', width=2), name=\"Estimation de la densité\"))\nfig.add_trace(go.Scatter(x=x, y=stats.cauchy.pdf(x, scale=1, loc=0), mode='lines', opacity=0.6, line=dict(color='black', width=2), name=\"Densité de Cauchy\"))\n\nfig.update_layout(\n    template=\"simple_white\",\n    showlegend=True,\n)\nprint(f\"Taille de l'échantillon: {n_sample}\")\nprint(f\"Étendue: {np.max(X)-np.min(X)}\")\n\nTaille de l'échantillon: 1000\nÉtendue: 821.8956937401883\n\n\nNotons qu’un phénomène similaire apparaît aussi avec la loi de Pareto, qui est une loi à queue lourde quand son paramètre \\alpha est plus petit que 1.\n\n\n\n\n\n\nTaille de l'échantillon: 1000\nÉtendue: 6767.926681527171\nTaille de l'échantillon: 1000\nÉtendue: 120.26958531004222",
    "crumbs": [
      "TP",
      "TP2: Simulation de lois élémentaires"
    ]
  },
  {
    "objectID": "TP/quarto.html",
    "href": "TP/quarto.html",
    "title": "Démarrage en Quarto",
    "section": "",
    "text": "Ce texte est principalement inspiré du travail d’Arthur Turrell et de son cours sur Quarto pour les économistes .",
    "crumbs": [
      "TP",
      "Démarrage en Quarto"
    ]
  },
  {
    "objectID": "TP/quarto.html#introduction",
    "href": "TP/quarto.html#introduction",
    "title": "Démarrage en Quarto",
    "section": "Introduction",
    "text": "Introduction\nQuarto est un cadre d’édition unifié pour la science des données, qui combine votre code, ses résultats et vos commentaires. Le markdown de Quarto est conçu pour être utilisé de trois manières :\n\nPour communiquer avec des collègues qui souhaitent se concentrer sur les conclusions, et non sur le code derrière l’analyse.\nPour collaborer avec d’autres collègues/scientifiques (y compris vous-même dans le futur !), qui s’intéressent à la fois à vos conclusions et à la manière dont vous les avez obtenues (c’est-à-dire le code).\nEn tant qu’environnement dans lequel faire de la science des données, comme un cahier de laboratoire moderne où vous pouvez capturer non seulement ce que vous avez fait, mais aussi ce que vous pensiez.\n\nEn combinant le code, les résultats et les commentaires, Quarto permet de créer des documents riches et interactifs qui peuvent être facilement partagés et mis à jour.\n\nExemple 1 (Exemple d’utilisation) L’écriture d’un rapport de TP ou d’un projet peut se faire facilement sous quarto, avec un export en .pdf (ou en .html). Vous pouvez décider de masquer ou d’afficher les parties de code dans les sorties finales. Plus en détail, les cas d’utilisation comprennent :\n\ndes rapports utilisant des données et/ou des graphiques et qui sont similaires à chaque fois qu’ils sont exécutés (par exemple, seules les données sont mises à jour)\ndes rapports techniques qui montrent ou utilisent les fonctionnalités d’une base de code existante\ndes présentations qui résument les données les plus récentes et qui sont produites à une fréquence régulière\nl’envoi d’analyses exploratoires ou de prototypes à des co-auteurs ou des collaborateurs\nla rédaction de blogs pour les services de blogging qui acceptent les fichiers .md (assurez-vous d’exporter vers markdown)\nla création de sites web mis à jour automatiquement de manière relativement simple voir.\n\n\n\nPrérequis\nInutile pour les machines de l’université!: Vous devez vous rendre sur le site web de Quarto (https://quarto.org/) et suivre les instructions d’installation (https://quarto.org/docs/getting-started/installation.html) avant de commencer. Vous pouvez vérifier que vous avez correctement installé Quarto en utilisant la commande quarto check install sur la ligne de commande.\nVous trouverez l’extension Quarto pour Visual Studio Code ici: (https://marketplace.visualstudio.com/items?itemName=quarto.quarto). Cette extension crée un bouton spécial dans Visual Studio Code appelé “render” qui vous montre à quoi ressemblera la sortie côte à côte avec l’entrée, ou encore “preview”.",
    "crumbs": [
      "TP",
      "Démarrage en Quarto"
    ]
  },
  {
    "objectID": "TP/quarto.html#rapports-automatisés-avec-quarto",
    "href": "TP/quarto.html#rapports-automatisés-avec-quarto",
    "title": "Démarrage en Quarto",
    "section": "Rapports automatisés avec Quarto",
    "text": "Rapports automatisés avec Quarto\nQuarto peut être utilisé pour créer des documents et des présentations de sortie dans une grande variété de formats, y compris HTML, PDF et bien d’autres.\nVous pouvez écrire les documents d’entrée y compris les extraits de code, de la manière suivante :\n\nCréer un fichier markdown spécial, avec l’extension de fichier .qmd. Pour en savoir plus sur markdown, voir {ref}wrkflow-markdown. Les blocs de code qui ont une syntaxe spéciale sont exécutés et leurs résultats sont inclus dans toutes les sorties.\n\nVous pouvez également ajouter du code (Python, R, JavaScript, etc.) aux documents pour créer dynamiquement des figures, des tableaux, etc., puis rendre les documents à leur format final à l’aide de Quarto.\n\nUn exemple minimal d’un rapport écrit avec du contenu markdown\nNous allons maintenant essayer un exemple plus minimaliste de la première approche, un fichier .qmd, qui inclut également du code et des sorties.\nIl y a des avantages et des inconvénients à écrire votre rapport au format .qmd. L’avantage est que c’est un simple fichier texte et donc n’importe qui peut l’ouvrir, le regarder et le modifier avec un éditeur de texte (et c’est également plus pratique pour le contrôle de version, par exemple avec git). Le gros, gros inconvénient est que vous ne pouvez pas voir comment le code évolue au fur et à mesure que vous l’écrivez (vous devez l’executer pour voir les sorties du code, comme nous le verrons dans un instant). Dans la sous-section suivante, nous verrons une façon d’obtenir un flux de travail plus efficace.\nCommençons par configurer notre exemple minimal. Le code et le markdown suivants forment le contenu d’un fichier appelé rapport_tp.qmd :\n---\ntitle: \"Exemple de rapport\"\nauthor: \"Capitaine Haddock\"\nformat: pdf\ntoc: true\nnumber-sections: true\njupyter: python3\n---\n\n## Histogramme\n\nPour une démonstration d'un tracé d'*histogramme* avec `matplotlib`, voir @fig-hist.\n\n```{python}\n#| label: fig-hist\n#| fig-cap: \"Un histogramme\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nrng = np.random.RandomState(44)\n\nuniform_data = rng.uniform(-1, 1, 100)\n\nfig, ax = plt.subplots()\nax.hist(uniform_data, bins=30)\nplt.show()\n```\net le rendu donne alors:\n\n\n\n\n\n\n\n\nFigure 1: Un histogramme\n\n\n\n\n\nCet exemple contient trois types de contenu importants :\n\nUn en-tête YAML entouré de ---.\nDes blocs de code Python entourés de ```.\nDu markdown mélangé avec une mise en forme de texte simple comme # heading et _italics_.\n\nDans ce fichier markdown .qmd “brut”, la commande {python} indique à Quarto qu’un bloc de code est en Python et doit être exécuté, et jupyter: python3 indique à Quarto quelle installation de Jupyter Notebooks utiliser. Si vous n’êtes pas sûr du nom de votre installation de Jupyter, vous pouvez voir une liste en exécutant jupyter kernelspec list sur la ligne de commande.\n\n\nRendu dans des documents de sortie\nPour convertir le rapport ci-dessus en un fichier PDF de sortie, enregistrez-le sous report.qmd et exécutez ensuite la commande suivante sur la ligne de commande et dans le même répertoire que le fichier :\nquarto render report.qmd\nN’oubliez pas que si vous utilisez l’extension Visual Studio Code quarto (recommandée), vous pouvez appuyer sur le bouton “render” à la place (mais vous devrez choisir PDF comme format de sortie), ou bien sur “preview”.\n\nExercice 1 Créer un PDF en enregistrant le markdown ci-dessus dans un fichier appelé rapport.qmd.\nAttention: si vous obtenez une erreur indiquant que le noyau Jupyter n’a pas été trouvé, vérifiez d’abord que vous avez installé Jupyter Lab, puis vérifiez le nom de votre noyau Jupyter en utilisant jupyter kernelspec list sur la ligne de commande. Vous devez spécifier correctement le nom de votre noyau Jupyter dans l’en-tête du document (dans l’exemple ci-dessus, il est appelé ‘python3’, qui est le noyau par défaut).\n\nMaintenant, puisque nous avons spécifié pdf dans l’en-tête de notre fichier, nous avons automatiquement obtenu un PDF. Cependant, une grande variété de formats de sortie sont disponibles. Par exemple, HTML :\nquarto render report.qmd --to html\nLa syntaxe de base consiste à écrire --to outputformat à la fin de la commande render.\n\nExercice 2 Réussissez à créer un rapport HTML en enregistrant le markdown ci-dessus dans un fichier appelé report.qmd, en modifiant l’entête et en exécutant ensuite la commande quarto render avec l’option --to html.\nQue se passe-t-il avec le menu sur le côté droit lorsque vous ajoutez des en-têtes supplémentaires en utilisant la syntaxe markdown ## ?\n\n\n\nOptions d’exécution de bloc de code\nIl existe différentes options pour l’exécution du bloc de code. Pour inclure un bloc de code qui ne sera pas exécuté, utilisez simplement la syntaxe markdown régulière (c’est-à-dire un bloc qui commence par ```python). Sinon, vous avez des options riches pour savoir si vous souhaitez afficher le code d’entrée, uniquement les résultats, les deux ou aucun des deux (tout en exécutant toujours le code).\nPour un exemple de sortie de code où l’entrée n’est pas affichée, le code ci-dessous n’affichera que la figure de sortie en utilisant l’option echo: false.\n```{python}\n#| echo: false\nimport numpy as np\nimport matplotlib.pyplot as plt\nrng = np.random.RandomState(44)\n\nuniform_data = rng.uniform(-1, 1, 100)\n\nfig, ax = plt.subplots()\nax.hist(uniform_data, bins=30)\nplt.show()\n```\nVoici quelques options pour les blocs de code:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nÉvaluer le bloc de code (si faux, affiche simplement le code dans la sortie).\n\n\necho\nInclure le code source dans la sortie.\n\n\noutput\nInclure les résultats de l’exécution du code dans la sortie (vrai, faux ou asis pour indiquer que la sortie est du markdown brut et ne doit pas avoir de markdown d’encadrement standard de Quarto).\n\n\nwarning\nInclure les avertissements dans la sortie.\n\n\nerror\nInclure les erreurs dans la sortie (notez que cela implique que les erreurs d’exécution du code ne bloqueront pas le traitement du document).\n\n\ninclude\nOption générale pour empêcher toute sortie (code ou résultats) d’être incluse (par exemple, include: false supprime toute sortie du bloc de code).",
    "crumbs": [
      "TP",
      "Démarrage en Quarto"
    ]
  },
  {
    "objectID": "TP/quarto.html#diapositives-automatisées-avec-quarto",
    "href": "TP/quarto.html#diapositives-automatisées-avec-quarto",
    "title": "Démarrage en Quarto",
    "section": "Diapositives automatisées avec Quarto",
    "text": "Diapositives automatisées avec Quarto\nCe ne sont pas seulement des rapports que vous pouvez créer, vous pouvez également réaliser des présentations. Vous avez trois principaux formats de sortie à choisir pour les diapositives :\n\nhtml, via quelque chose appelé ‘revealjs’ ; utilisez format: revealjs\npdf, via le package LaTeX beamer ; utilisez format: beamer\n\nTout le reste est identique à ce que nous avons vu précédemment. Voici un exemple minimal montrant à la fois du code et du texte. Il crée une présentation au format HTML.\n---\ntitle: \"Ma présentation\"\nauthor: \"Capitaine Haddock\"\nformat: revealjs\n---\n\n## Introduction\n\n- Voici du texte\n- Ainsi que ceci\n\n## Voici quelques sorties de code\n\n```{python}\n#| echo: false\nimport numpy as np\nimport matplotlib.pyplot as plt\nrng = np.random.RandomState(44)\n\nuniform_data = rng.uniform(-1, 1, 100)\n\nfig, ax = plt.subplots()\nax.hist(uniform_data, bins=30)\nplt.show()\n```\nNotez que cela n’affichera pas le code, mais seulement la figure, car nous avons défini #| echo: false pour le bloc de code. Vous pourriez également définir echo: false pour l’ensemble de la présentation dans l’en-tête.\n\nExercice 3 (Création de slides) Rendre cet exemple de diapositive dans les trois principaux formats",
    "crumbs": [
      "TP",
      "Démarrage en Quarto"
    ]
  }
]